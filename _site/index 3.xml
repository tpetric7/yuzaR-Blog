<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>yuzaR-Blog</title>
    <link>https://yuzar-blog.netlify.app/</link>
    <atom:link href="https://yuzar-blog.netlify.app/index.xml" rel="self" type="application/rss+xml"/>
    <description>Data Science with R
</description>
    <generator>Distill</generator>
    <lastBuildDate>Sat, 01 Oct 2022 00:00:00 +0000</lastBuildDate>
    <item>
      <title>4 Reasons Non-Parametric Bootstrapped Regression (with tidymodels) is Better then Ordinary Regression</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions</link>
      <description>


&lt;h1 id="this-post-as-a-video-in-making"&gt;This post as a video (in
making)&lt;/h1&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then ‚Ä¶ minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="the-problem-with-ordinary-linear-models"&gt;The problem with
ordinary linear models&lt;/h1&gt;
&lt;p&gt;If we want to compare salaries of people with different education, we
could create a simple linear model and plot the results. But we can not
trust these results, without checking the assumptions of our model,
because if assumptions are violated, the results might be wrong.
However, the problem with assumptions is that there are too many, and
most of the time we can‚Äôt satisfy them all.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidymodels)   # for everything good in R ;)
library(ISLR)         # for &amp;quot;Wage&amp;quot; dataset

set.seed(9999)        # makes sure we get the same 100 lines
salary &amp;lt;- Wage %&amp;gt;%
  sample_n(100)

m &amp;lt;- lm(wage ~ education, salary)

library(sjPlot)      # I have a video on &amp;quot;sjPlot&amp;quot; üì¶
theme_set(theme_test())
plot_model(m, type = &amp;quot;pred&amp;quot;, show.data = TRUE, jitter = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$education&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;For instance, our model has not-normally distributed residuals, the
variances between groups differ and we have heteroskedasticity. So, we
can‚Äôt trust our results, without fixing them, but when we start fixing
assumptions, we might (1) either lose data (if, for example, we remove
some influential points), (2) we might reduce interpretability (when we
log-transform data) or screw up other assumptions even more, because
data manipulation constantly changes the &lt;strong&gt;parameters&lt;/strong&gt; of
our - &lt;strong&gt;parametric&lt;/strong&gt; model. And here is where
&lt;strong&gt;non-parametric bootstraped regression&lt;/strong&gt; comes into
play.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(performance) # I have a video on &amp;quot;performance&amp;quot; üì¶ 

check_normality(m)          # Shapiro-Wilk normality test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Non-normality of residuals detected (p &amp;lt; .001).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_normality(m) %&amp;gt;% plot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-3-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_homogeneity(m)        # Bartlett test &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Variances differ between groups (Bartlett Test, p = 0.000).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_homogeneity(m) %&amp;gt;% plot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-3-2.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_heteroscedasticity(m) # Breusch-Pagan test&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Heteroscedasticity (non-constant error variance) detected (p &amp;lt; .001).&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_heteroscedasticity(m) %&amp;gt;% plot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-3-3.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;check_model(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-4-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="why-should-we-nonparametrically-bootstrap-regressions"&gt;Why
should we nonparametrically bootstrap regressions?&lt;/h1&gt;
&lt;p&gt;The 4 reasons a bootstrapped model is better then usual linear model,
is that bootstrapping:&lt;/p&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&lt;p&gt;does not have any distributional assumptions (such as normally
distributed residuals or equal variances among groups)&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;bootstrapped models provide more accurate inferences,
e.g.¬†confidence intervals &lt;a href="#fn1" class="footnote-ref"
id="fnref1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, which we‚Äôll soon prove on these two
examples, one with categorical and one with numeric predictors&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;bootstrapped models work better for small samples and
finally&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;it describes variation in the data much better than traditional
linear models&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Therefore, having bootstrapped models in your tool-box will
definitely make you a better data-scientist! So ‚Ä¶&lt;/p&gt;
&lt;h1 id="what-is---a-bootstrap"&gt;What is - a bootstrap?&lt;/h1&gt;
&lt;p&gt;In order to better understand how bootstrap models work, we need to
understand what the bootstrap itself actually is. A bootstrapp is the
little loop on the back of a boot to help you pool it on. And the phrase
‚Äúpulling oneself up by one‚Äôs bootstraps‚Äù means to succeed without any
external help. For data it simply means - resampling.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(ggstatsplot) # I made many videos on &amp;quot;ggstatsplot&amp;quot; üì¶
ggbetweenstats(data = salary, x = education, y = wage)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-5-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;So, lets (1) take a very small dataset, (2) resample it 1000 times,
(3) calculate bootstrapped coefficients &amp;amp; 95% CIs and (4) compare
them to the ordinary regression in order to find out whether
bootstrapping model is indeed better!&lt;/p&gt;
&lt;h1 id="steps-to-compute-bootstrapped-regression"&gt;4 steps to compute
bootstrapped regression&lt;/h1&gt;
&lt;p&gt;There are only 4 steps to conduct and visualize bootstrapped
regression.&lt;/p&gt;
&lt;h2 id="bootstrap-the-data-with-resampling"&gt;1. Bootstrap the data with
resampling&lt;/h2&gt;
&lt;p&gt;First, we bootstrap the data, which simply means we take 1000 samples
from our 100 data rows. Every of those 1000 samples is of the same size
as the original data set, namely 100 rows, but is made using
&lt;strong&gt;replacements&lt;/strong&gt;, which results into multiple replicates of
some of the original rows of the data. &lt;strong&gt;Replacements are
necessary, because we would otherwise simply reproduce the original
sample&lt;/strong&gt;. (The assessment set contains the rows of the original
data that were not included in the bootstrap sample.) In order to
distinguish bootstrapped samples from the original sample let‚Äôs call our
bootstrapped samples - splits.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;set.seed(123)
# 1000 samples are OK, but with 2000-10000 you are save!
boot_data &amp;lt;- bootstraps(salary, times = 1000) 
boot_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Bootstrap sampling 
# A tibble: 1,000 √ó 2
   splits           id           
   &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;        
 1 &amp;lt;split [100/41]&amp;gt; Bootstrap0001
 2 &amp;lt;split [100/38]&amp;gt; Bootstrap0002
 3 &amp;lt;split [100/42]&amp;gt; Bootstrap0003
 4 &amp;lt;split [100/40]&amp;gt; Bootstrap0004
 5 &amp;lt;split [100/30]&amp;gt; Bootstrap0005
 6 &amp;lt;split [100/30]&amp;gt; Bootstrap0006
 7 &amp;lt;split [100/36]&amp;gt; Bootstrap0007
 8 &amp;lt;split [100/35]&amp;gt; Bootstrap0008
 9 &amp;lt;split [100/32]&amp;gt; Bootstrap0009
10 &amp;lt;split [100/36]&amp;gt; Bootstrap0010
# ‚Ä¶ with 990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_data$splits[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;Analysis/Assess/Total&amp;gt;
&amp;lt;100/41/100&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="produce-1000-models"&gt;2. Produce 1000 models&lt;/h2&gt;
&lt;p&gt;Then we &lt;strong&gt;fit a linear model&lt;/strong&gt; to every
&lt;strong&gt;split&lt;/strong&gt; using the first &lt;code&gt;map()&lt;/code&gt; function and
tidy up model coefficients with the second &lt;code&gt;map()&lt;/code&gt; function.
Let‚Äôs use ‚Äú0 +‚Äù in the model formula to remove the Intercept, because we
are interested in estimates of the salary and not the slope of change
from that Intercept.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_models &amp;lt;- boot_data %&amp;gt;% 
  mutate(model = map(splits, ~lm(wage ~ 0 + education, data = .)), 
         coefs = map(model, tidy) ) # optional &amp;quot;conf.int = TRUE&amp;quot;

boot_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Bootstrap sampling 
# A tibble: 1,000 √ó 4
   splits           id            model  coefs           
   &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;         &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;          
 1 &amp;lt;split [100/41]&amp;gt; Bootstrap0001 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 2 &amp;lt;split [100/38]&amp;gt; Bootstrap0002 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 3 &amp;lt;split [100/42]&amp;gt; Bootstrap0003 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 4 &amp;lt;split [100/40]&amp;gt; Bootstrap0004 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 5 &amp;lt;split [100/30]&amp;gt; Bootstrap0005 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 6 &amp;lt;split [100/30]&amp;gt; Bootstrap0006 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 7 &amp;lt;split [100/36]&amp;gt; Bootstrap0007 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 8 &amp;lt;split [100/35]&amp;gt; Bootstrap0008 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
 9 &amp;lt;split [100/32]&amp;gt; Bootstrap0009 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
10 &amp;lt;split [100/36]&amp;gt; Bootstrap0010 &amp;lt;lm&amp;gt;   &amp;lt;tibble [5 √ó 5]&amp;gt;
# ‚Ä¶ with 990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="plot-estimates-distribution-of-1000-estimates"&gt;3. Plot estimates
distribution of 1000 estimates&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_coefs &amp;lt;- boot_models %&amp;gt;%
  unnest(coefs) %&amp;gt;% 
  select(term, estimate)

boot_coefs&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5,000 √ó 2
   term                        estimate
   &amp;lt;chr&amp;gt;                          &amp;lt;dbl&amp;gt;
 1 education1. &amp;lt; HS Grad           85.5
 2 education2. HS Grad             87.3
 3 education3. Some College       107. 
 4 education4. College Grad       127. 
 5 education5. Advanced Degree    174. 
 6 education1. &amp;lt; HS Grad           85.0
 7 education2. HS Grad             95.1
 8 education3. Some College       109. 
 9 education4. College Grad       150. 
10 education5. Advanced Degree    149. 
# ‚Ä¶ with 4,990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, we not only have 1000 models, which are nested in the column
‚Äúmodel‚Äù, but also the results of those models which are nested in the
column ‚Äúcoefficients‚Äù. And if we &lt;code&gt;unnest()&lt;/code&gt; the coefficients,
we‚Äôll see 5 estimates for every of our 1000 models. It‚Äôs like we have
done 1000 experiments, which we can immediately visualize as a
distribution.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_coefs %&amp;gt;%
  ggplot(aes(x = estimate)) +
  geom_histogram() +
  facet_wrap(~term, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-9-1.png" width="864" /&gt;
First of all, the distributions seem normal, or bell-shaped, which is
already amazing because we can use average estimates ;). But despite
normal distribution, I still would prefer median estimate for every
group instead of the mean. That makes our non-parametric estimates even
more robust, since median is estimated by another wonderful robust
technique - &lt;strong&gt;quantile-regression&lt;/strong&gt;, which is also used
when the assumptions of linear regression are not met. I find it really
cool! But the coolest thing about this distribution and
quantile-function is that we can easily get not only classic 95%
Confidence Intervals, &lt;strong&gt;but any intervals we want&lt;/strong&gt;. Which
is kind of hard to get out of the ordinary model. Thus, we actually have
more than 4 advantages ü•≥ of the bootstrapped model.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_meds &amp;lt;- boot_coefs %&amp;gt;% 
  group_by(term) %&amp;gt;% 
  # group by term here is useless, but you&amp;#39;ll need for &amp;gt;1 predictor
  summarise(
    med_est   = median(estimate),
    quantile  = quantile(estimate, 0.5  ),
    conf.low  = quantile(estimate, 0.025),
    conf.high = quantile(estimate, 0.975),
    conf.25   = quantile(estimate, 0.25 ),
    conf.75   = quantile(estimate, 0.75 ))

boot_meds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5 √ó 7
  term                 med_est quant‚Ä¶¬π conf.‚Ä¶¬≤ conf.‚Ä¶¬≥ conf.25 conf.75
  &amp;lt;chr&amp;gt;                  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
1 education1. &amp;lt; HS Gr‚Ä¶    91.4    91.4    75.9    108.    85.8    97.3
2 education2. HS Grad     94.4    94.4    86.9    103.    91.5    97.3
3 education3. Some Co‚Ä¶   106.    106.     99.5    114.   104.    109. 
4 education4. College‚Ä¶   134.    134.    110.     165.   126.    143. 
5 education5. Advance‚Ä¶   153.    153.    119.     191.   140.    164. 
# ‚Ä¶ with abbreviated variable names ¬π‚Äãquantile, ¬≤‚Äãconf.low, ¬≥‚Äãconf.high&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And when we plot our estimates we can clearly see that 50% of people
who did not finish a high school, will never reach a salary of 100
thousands, while 95% of folks with higher education will never earn
below 100 thousands bugs. Waw! So, education matters!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_coefs %&amp;gt;%
  ggplot(aes(x = estimate)) +
  geom_rect(aes(x = med_est, xmin = conf.low, xmax = conf.high, ymin = 0, ymax = Inf), data = boot_meds, alpha = 0.1, fill = &amp;quot;green&amp;quot;) +
  geom_rect(aes(x = med_est, xmin = conf.25, xmax = conf.75, ymin = 0, ymax = Inf), data = boot_meds, alpha = 0.3, fill = &amp;quot;green&amp;quot;) +
  geom_density() +
  geom_vline(data = boot_meds, aes(xintercept = med_est))+
  facet_wrap(~term, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-11-1.png" width="864" /&gt;&lt;/p&gt;
&lt;p&gt;But what blew my mind even more the first time I learned to bootstrap
regression estimates, is that I can even get a distribution of p-values
:). For that we just (1) remodel 1000 ‚Ä¶ ahhh, what a hell, let‚Äôs remodel
10.000 models with the Intercept, (2) unnest out coefficients again and
(3) visualize the distribution of our 10.000 p.values. Now you see why
it‚Äôs always better to take median instead of mean.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_models &amp;lt;- bootstraps(salary, times = 10000) %&amp;gt;% 
  mutate(model = map(splits, ~lm(wage ~ education, data = .)), 
         coefs = map(model, tidy) ) # optional &amp;quot;conf.int = TRUE&amp;quot;

boot_coefs &amp;lt;- boot_models %&amp;gt;%
  unnest(coefs) %&amp;gt;% 
  select(term, p.value)

boot_coefs %&amp;gt;%
  ggplot(aes(x = p.value)) +
  geom_histogram() +
  facet_wrap(~term, scales = &amp;quot;free&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-12-1.png" width="864" /&gt;&lt;/p&gt;
&lt;p&gt;And if we compare mean and median bootstrapped p.values to the
p.values from the ordinary models, we‚Äôll see that median bootstrapped
p.values are much closer to the the p.values of the ordinary model. And
despite the fact that median p.values and ordinary p.values are only
slightly different, I would still intuitively trust the bootstrapped
p.values more, because they were produced in a statistically robust
fashion, where no assumptions were violated.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_coefs %&amp;gt;% 
  group_by(term) %&amp;gt;% 
  summarise(
    mean_boot_p = mean(p.value),
    med_boot_p  = median(p.value)
    ) %&amp;gt;% 
  # remember? m &amp;lt;- lm(wage ~ education, salary)
  left_join(tidy(m) %&amp;gt;% select(term, p.value)) %&amp;gt;% 
  mutate_if(is.numeric, ~round(., 4))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5 √ó 4
  term                        mean_boot_p med_boot_p p.value
  &amp;lt;chr&amp;gt;                             &amp;lt;dbl&amp;gt;      &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
1 (Intercept)                      0.0003     0       0     
2 education2. HS Grad              0.652      0.686   0.862 
3 education3. Some College         0.417      0.374   0.384 
4 education4. College Grad         0.0632     0.0153  0.0145
5 education5. Advanced Degree      0.0238     0.0017  0.0015&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="get-and-visualize-predictions"&gt;4. Get and visualize
predictions&lt;/h2&gt;
&lt;p&gt;Finally, here is the moment we‚Äôve been waiting for:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;let‚Äôs use the &lt;code&gt;augment()&lt;/code&gt; command to produce predictions
for every of our 10.000 models,&lt;/li&gt;
&lt;li&gt;then calculate a median and 95% CIs from our predictions&lt;/li&gt;
&lt;li&gt;calculate predictions made by the ordinary linear regression&lt;/li&gt;
&lt;li&gt;combine two results into one dataset and&lt;/li&gt;
&lt;li&gt;compare them visually by
&lt;ul&gt;
&lt;li&gt;first plotting our original 100 observations and then&lt;/li&gt;
&lt;li&gt;display predictions of both models to see which describes the data
best&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get predictions
boot_aug &amp;lt;- boot_models %&amp;gt;% 
  mutate(augmented = map(model, augment)) %&amp;gt;% 
  unnest(augmented) %&amp;gt;% 
  select(-splits, -model)

# get median estimates, median 95% CIs
nonpar_med_boot_preds &amp;lt;- boot_aug %&amp;gt;% 
  group_by(education) %&amp;gt;% 
  summarise(
    predicted = median(.fitted ),
    conf.low  = quantile(.fitted, 0.025),
    conf.high = quantile(.fitted, 0.975)) %&amp;gt;% 
  mutate(model = &amp;quot;bootstrapped&amp;quot;) %&amp;gt;% 
  select(model, everything())

nonpar_med_boot_preds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5 √ó 5
  model        education          predicted conf.low conf.high
  &amp;lt;chr&amp;gt;        &amp;lt;fct&amp;gt;                  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 bootstrapped 1. &amp;lt; HS Grad            91.6     75.9      108.
2 bootstrapped 2. HS Grad              94.4     86.1      103.
3 bootstrapped 3. Some College        106.      99.4      114.
4 bootstrapped 4. College Grad        134.     110.       163.
5 bootstrapped 5. Advanced Degree     152.     122.       189.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get mean estimates from the classic model
m &amp;lt;- lm(wage ~ education, salary)  # just a reminder
par_avg_preds &amp;lt;- ggeffects::ggeffect(m, terms = &amp;quot;education&amp;quot;) %&amp;gt;% 
  tibble() %&amp;gt;% 
  mutate(model = &amp;quot;linear&amp;quot;) %&amp;gt;% 
  select(model, education = x, predicted, conf.low, conf.high)

par_avg_preds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5 √ó 5
  model  education          predicted conf.low conf.high
  &amp;lt;chr&amp;gt;  &amp;lt;fct&amp;gt;                  &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 linear 1. &amp;lt; HS Grad            91.6     62.2      121.
2 linear 2. HS Grad              94.5     79.8      109.
3 linear 3. Some College        106.      89.8      123.
4 linear 4. College Grad        135.     117.       152.
5 linear 5. Advanced Degree     153.     130.       176.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# combine two datasets
preds &amp;lt;- rbind(nonpar_med_boot_preds, par_avg_preds)

# plot row data and predicted CIs from both models
ggplot() +
  geom_jitter(data = salary, aes(education, wage), 
              width = .2, alpha = 0.2, size = 2)+
  geom_pointrange(data = preds, aes(x = education, y = predicted, 
                  ymin = conf.low, ymax = conf.high, color = model),
                  position=position_dodge(width=.6), size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-14-1.png" width="672" /&gt;&lt;/p&gt;
&lt;!-- Interestingly, the center of the bootstrap distribution is identical to the mean of the sample, because the bootstrap distributions are centered around statistics calculated from the data (e.g., a regression slope). However,  --&gt;
&lt;p&gt;Interestingly, the bootstrapped confidence intervals are slimmer
where the variance is low and wider, where the variance is high. So, as
mentioned in the beginning, &lt;strong&gt;bootstrapped models describe the
variation in the data better and produce therefore more accurate and
realistic inferences without violating any assumptions, especially for
small samples.&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id="bootstrapping-numeric-predictors"&gt;Bootstrapping numeric
predictors&lt;/h1&gt;
&lt;p&gt;Bootstrapping with numeric predictors works in the same way, so,
let‚Äôs summarise all we have learned so far, namely:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we first create 1000 resamples of our data,&lt;/li&gt;
&lt;li&gt;then &lt;code&gt;map()&lt;/code&gt; over it to fit new 1000 models, with the
numeric predictor ‚Äúage‚Äù&lt;/li&gt;
&lt;li&gt;we then &lt;code&gt;map()&lt;/code&gt; over every model and use
&lt;code&gt;augment()&lt;/code&gt; function to extract fitted data for every model
in an new nested column, with 100 fitted values for every model, because
every resample in boot_data has 100 observations.&lt;/li&gt;
&lt;li&gt;1000 models with 100 fitted values each result in 100.000 fitted
values, which we see when we unnest them for plotting, and visualize as
1000 lines on the plot&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# produce 1000 resamples
set.seed(123)
boot_data &amp;lt;- bootstraps(salary, times = 1000) 

# bootstrap new regressions and unnest all fits
boot_models &amp;lt;- boot_data %&amp;gt;% 
  mutate(model     = map(splits, ~lm(wage ~ age, data = .)), 
         augmented = map(model, augment) )

boot_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Bootstrap sampling 
# A tibble: 1,000 √ó 4
   splits           id            model  augmented         
   &amp;lt;list&amp;gt;           &amp;lt;chr&amp;gt;         &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;            
 1 &amp;lt;split [100/41]&amp;gt; Bootstrap0001 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 2 &amp;lt;split [100/38]&amp;gt; Bootstrap0002 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 3 &amp;lt;split [100/42]&amp;gt; Bootstrap0003 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 4 &amp;lt;split [100/40]&amp;gt; Bootstrap0004 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 5 &amp;lt;split [100/30]&amp;gt; Bootstrap0005 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 6 &amp;lt;split [100/30]&amp;gt; Bootstrap0006 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 7 &amp;lt;split [100/36]&amp;gt; Bootstrap0007 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 8 &amp;lt;split [100/35]&amp;gt; Bootstrap0008 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
 9 &amp;lt;split [100/32]&amp;gt; Bootstrap0009 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
10 &amp;lt;split [100/36]&amp;gt; Bootstrap0010 &amp;lt;lm&amp;gt;   &amp;lt;tibble [100 √ó 9]&amp;gt;
# ‚Ä¶ with 990 more rows&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;boot_aug &amp;lt;- boot_models %&amp;gt;% 
  unnest(augmented) %&amp;gt;% 
  select(-splits, -model)

boot_aug&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 100,000 √ó 10
   id         .rown‚Ä¶¬π  wage   age .fitted .resid   .hat .sigma .cooksd
   &amp;lt;chr&amp;gt;      &amp;lt;chr&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;
 1 Bootstrap‚Ä¶ 31       61.2    25    95.7 -34.5  0.0256   47.7 7.09e-3
 2 Bootstrap‚Ä¶ 79      112.     48   126.  -14.6  0.0149   47.8 7.20e-4
 3 Bootstrap‚Ä¶ 51      110.     40   116.   -5.83 0.0100   47.8 7.66e-5
 4 Bootstrap‚Ä¶ 14       79.9    52   132.  -51.8  0.0207   47.5 1.28e-2
 5 Bootstrap‚Ä¶ 67       82.7    40   116.  -33.0  0.0100   47.7 2.45e-3
 6 Bootstrap‚Ä¶ 42       95.2    30   102.   -7.12 0.0168   47.8 1.95e-4
 7 Bootstrap‚Ä¶ 50       99.7    25    95.7   3.99 0.0256   47.8 9.47e-5
 8 Bootstrap‚Ä¶ 43       70.5    24    94.4 -23.9  0.0278   47.8 3.70e-3
 9 Bootstrap‚Ä¶ 14.1     79.9    52   132.  -51.8  0.0207   47.5 1.28e-2
10 Bootstrap‚Ä¶ 25      121.     47   125.   -3.55 0.0138   47.8 3.94e-5
# ‚Ä¶ with 99,990 more rows, 1 more variable: .std.resid &amp;lt;dbl&amp;gt;, and
#   abbreviated variable name ¬π‚Äã.rownames&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(data = boot_aug, aes(x = age, y = wage)) +
  geom_line(aes(y = .fitted, group = id), col = &amp;quot;grey&amp;quot;,  size = 0.25) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-15-1.png" width="672" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we then create &lt;strong&gt;new age&lt;/strong&gt; data (picture of new age
movement) ‚Ä¶ ups, sorry, not that &lt;strong&gt;new age&lt;/strong&gt;, just data of
age from 20 to 75 years old, and call them new in order to evaluate our
predictions&lt;/li&gt;
&lt;li&gt;use &lt;code&gt;map()&lt;/code&gt; function to predict salaries for the new age
data by every model&lt;/li&gt;
&lt;li&gt;then summarize all 1000 predictions by the median and calculate 95
and 50% confidence intervals (CIs),&lt;/li&gt;
&lt;li&gt;and finally plot them on top our our 1000 fitted models&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get new data for predictions
new &amp;lt;- data.frame(age = seq(20, by = 3, 75))
new %&amp;gt;% t()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;    [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]
age   20   23   26   29   32   35   38   41   44    47    50    53
    [,13] [,14] [,15] [,16] [,17] [,18] [,19]
age    56    59    62    65    68    71    74&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;few_preds &amp;lt;- boot_models %&amp;gt;% 
  mutate(few_preds = map(model, predict, new)) %&amp;gt;% 
  unnest(few_preds) %&amp;gt;% 
  select(-splits, -model) %&amp;gt;% 
  mutate(age = rep( seq(20, by = 3, 75) , 1000)) %&amp;gt;% 
  group_by(age) %&amp;gt;% 
  summarise(wage   = median(few_preds),
            LCL_50 = quantile(few_preds, 0.25),
            UCL_50 = quantile(few_preds, 0.775),
            LCL    = quantile(few_preds, 0.025),
            UCL    = quantile(few_preds, 0.975),
  )

few_preds&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 19 √ó 6
     age  wage LCL_50 UCL_50   LCL   UCL
   &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
 1    20  93.4   89.9   97.5  83.4  104.
 2    23  96.2   93.3   99.8  87.9  106.
 3    26  99.1   96.6  102.   91.7  107.
 4    29 102.    99.8  105.   95.5  109.
 5    32 105.   103.   108.   98.8  112.
 6    35 108.   106.   111.  101.   115.
 7    38 111.   108.   114.  104.   119.
 8    41 114.   110.   117.  106.   123.
 9    44 117.   113.   121.  107.   128.
10    47 120.   115.   124.  109.   132.
11    50 122.   118.   128.  110.   137.
12    53 125.   120.   131.  112.   142.
13    56 128.   122.   134.  113.   147.
14    59 131.   125.   138.  114.   152.
15    62 134.   127.   142.  115.   156.
16    65 137.   129.   145.  117.   161.
17    68 139.   131.   149.  118.   166.
18    71 142.   134.   153.  119.   171.
19    74 145.   136.   157.  121.   176.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(data = boot_aug, aes(x = age, y = wage)) +
  geom_line(aes(y = .fitted, group = id), col = &amp;quot;grey&amp;quot;,  size = 0.25) +
  geom_point(data = few_preds, aes(age, wage))+
  geom_errorbar(data = few_preds, aes(ymin = LCL, ymax = UCL), width = 1)+
  geom_errorbar(data = few_preds, aes(ymin = LCL_50, ymax = UCL_50))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-16-1.png" width="672" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;then we‚Äôll plot the original 100 data points in green and&lt;/li&gt;
&lt;li&gt;the results of an ordinary linear regression in blue with their 95%
CIs in red&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(data = boot_aug, aes(x = age, y = wage)) +
  geom_point(data = salary, aes(age, wage), colour = &amp;quot;green&amp;quot;, shape = 1) +
  geom_line(aes(y = .fitted, group = id), col = &amp;quot;grey&amp;quot;,  size = 0.25) +
  geom_point(data = few_preds, aes(age, wage))+
  geom_errorbar(data = few_preds, aes(ymin = LCL, ymax = UCL), width = 1)+
  geom_errorbar(data = few_preds, aes(ymin = LCL_50, ymax = UCL_50))+
  geom_smooth(aes(x = age, y = wage), data = salary, method = &amp;quot;lm&amp;quot;,
              colour = &amp;quot;blue&amp;quot;, fill = &amp;quot;red&amp;quot;, alpha = 0.25)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-17-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;And as we can see again,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;low variance in salaries in the beginning of professional life is
described with narrower CIs by the bootstrapped predictions as compared
to the ordinary linear regression, while&lt;/li&gt;
&lt;li&gt;larger variance in salaries after age of 45 is described by the
bootstrapped predictions with wider CIs as compared to the ordinary
linear regression&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thus, similarly to the categorical predictor, we see that
&lt;strong&gt;bootstrapped results better describe the variation in the data
and produce therefore more accurate and realistic
inferences.&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id="problems"&gt;Problems&lt;/h1&gt;
&lt;p&gt;So, is bootstrap method perfect? Of coarse no! While bootstrap more
accurately describes the variance of a sample, for example here I really
want to include high salaries into my variance, to see what is actually
possible to earn with this education, if you have real outliers or very
influential observations in your data, they will be given more weight
then needed. In this case you would use a &lt;strong&gt;robust
regression&lt;/strong&gt;, and if you wanna become a more complete data
scientist in the next five minutes, watch &lt;a
href="https://youtu.be/M_7MOkAm9WU"&gt;this video&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(robustbase)
rm &amp;lt;- lmrob(wage ~ education, salary)
rob_avg_preds &amp;lt;- ggeffects::ggeffect(rm, terms = &amp;quot;education&amp;quot;) %&amp;gt;% 
  tibble() %&amp;gt;% 
  mutate(model = &amp;quot;robust2&amp;quot;) %&amp;gt;% 
  select(model, education = x, predicted, conf.low, conf.high)

# combine two datasets
preds &amp;lt;- rbind(nonpar_med_boot_preds, par_avg_preds, rob_avg_preds)

ggplot() +
  geom_jitter(data = salary, aes(education, wage), width = .2, alpha = 0.2, size = 2)+
  geom_pointrange(data = preds, aes(x=education, y=predicted, 
                                    ymin=conf.low, ymax=conf.high, color = model),  
                  position=position_dodge(width=.6), size = 1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29cf41f290_files/figure-html/unnamed-chunk-18-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="further-readings-and-references"&gt;Further readings and
references&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a
href="https://www.datawim.com/post/bootstrapping-regression-coefficients-in-r/"
class="uri"&gt;https://www.datawim.com/post/bootstrapping-regression-coefficients-in-r/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a
href="https://padpadpadpad.github.io/post/bootstrapping-non-linear-regressions-with-purrr/"
class="uri"&gt;https://padpadpadpad.github.io/post/bootstrapping-non-linear-regressions-with-purrr/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;div class="footnotes footnotes-end-of-document"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn1"&gt;&lt;p&gt;Tim Hesterberg (2015), What Teachers Should Know about
the Bootstrap: Resampling in the Undergraduate Statistics Curriculum,
The American Statistician 69(4) 371-386, DOI:
10.1080/00031305.2015.1089789&lt;a href="#fnref1"
class="footnote-back"&gt;‚Ü©Ô∏é&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description>
      <distill:md5>f032e778ccd0b8fa6a176329efe7070b</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions</guid>
      <pubDate>Sat, 01 Oct 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions/bootstrappingregressions_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>R demo | Robust Regression (don't depend on influential data!)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression</link>
      <description>


&lt;h1 id="this-post-as-a-video"&gt;This post as a video&lt;/h1&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then 5 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/M_7MOkAm9WU" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="make-sure-you-have-unusual-data"&gt;Make sure you have unusual
data&lt;/h1&gt;
&lt;p&gt;For the sake of simplicity let‚Äôs take only 5 observations with one
obvious outlier.&lt;/p&gt;
&lt;p&gt;First of all, how do we know that we have influential observations?
Well, plotting the raw data sometimes helps, but if you have a lot of
data and many predictors, &lt;strong&gt;the best way to find unusual data
is&lt;/strong&gt; to conduct a linear regression and to run &lt;strong&gt;residuals
diagnostics&lt;/strong&gt;. &lt;code&gt;ols_plot_resid_lev()&lt;/code&gt; function from
{olsrr} package displays all contaminations of data on a single plot. In
our case it finds observation 4 to be an obvious outlier.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# 1. create data
library(tidyverse)
d &amp;lt;- tibble(
  predictor = c(  1,   2,   3,  4,   5),
  outcome   = c(0.8, 2.3, 2.8,  0, 5.3)
)

plot(d)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/unnamed-chunk-3-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# 2. run ordinary least squares regression
m &amp;lt;- lm(outcome ~ predictor, data= d)

# 3.make residual diagnostics
library(olsrr)
ols_plot_resid_lev(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/unnamed-chunk-3-2.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="perform-robust-regression"&gt;Perform robust regression&lt;/h1&gt;
&lt;p&gt;Now, we‚Äôll use &lt;code&gt;lmrob()&lt;/code&gt; function form {robustbase}
package to conduct the robust regression and have a look at the
&lt;code&gt;summary()&lt;/code&gt; and residuals plot of the model, because they
explain how robust regression actually works.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# 4. conduct robust regression
library(robustbase)
rm &amp;lt;- lmrob(outcome ~ predictor, data = d)

summary(rm)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lmrob(formula = outcome ~ predictor, data = d)
 \--&amp;gt; method = &amp;quot;MM&amp;quot;
Residuals:
       1        2        3        4        5 
-0.09832  0.31533 -0.27102 -4.15738  0.05627 

Coefficients:
            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept) -0.18804    0.18312  -1.027     0.38    
predictor    1.08635    0.03763  28.873 9.12e-05 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Robust residual standard error: 0.6541 
Multiple R-squared:  0.9791,    Adjusted R-squared:  0.9721 
Convergence in 5 IRWLS iterations

Robustness weights: 
     1      2      3      4      5 
0.9979 0.9789 0.9844 0.0000 0.9993 
Algorithmic parameters: 
       tuning.chi                bb        tuning.psi 
        1.548e+00         5.000e-01         4.685e+00 
       refine.tol           rel.tol         scale.tol 
        1.000e-07         1.000e-07         1.000e-10 
        solve.tol       eps.outlier             eps.x 
        1.000e-07         2.000e-02         9.095e-12 
warn.limit.reject warn.limit.meanrw 
        5.000e-01         5.000e-01 
     nResample         max.it       best.r.s       k.fast.s 
           500             50              2              1 
         k.max    maxit.scale      trace.lev            mts 
           200            200              0           1000 
    compute.rd fast.s.large.n 
             0           2000 
                  psi           subsampling                   cov 
           &amp;quot;bisquare&amp;quot;         &amp;quot;nonsingular&amp;quot;         &amp;quot;.vcov.avar1&amp;quot; 
compute.outlier.stats 
                 &amp;quot;SM&amp;quot; 
seed : int(0) &lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(sjPlot)
plot_residuals(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/unnamed-chunk-4-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="how-and-why-does-robust-regression-works"&gt;How and why does
robust regression works?&lt;/h1&gt;
&lt;p&gt;Namely, a robust regression gives different &lt;strong&gt;robustness
weights&lt;/strong&gt;, from 0 to 1, to every observation based on it‚Äôs
residual. Where a residual is simply the differences between observed
and predicted values of data. So, the smaller the residual, the larger
the weight. For example, observations 1 and 3 have the smallest
residuals and therefore the highest weight, which means - they have the
strongest influence on our model. And while all observations with a
non-zero residual get down-weighted at least a little, our outlier gets
down-weighting the most ‚Ä¶ to ‚Ä¶ actually zero, so that our outlier has
zero influence on our model, which in fact makes our model ROBUST.&lt;/p&gt;
&lt;p&gt;The assignment of weight happens by &lt;strong&gt;Iteratively ReWeighting
Least Squares (IRWLS)&lt;/strong&gt;, thus we have to make sure, robust
regression algorithm converged. In our case, the model converged in only
a few iterations.&lt;/p&gt;
&lt;p&gt;But why don‚Äôt we just remove outliers and run a normal linear model,
right? Well, in most of the cases it‚Äôs a bad idea, because we‚Äôll loose
information. For example in our case of 5 observations, we‚Äôd loose 20%
of data. In contrast, robust regression still squizzes some knowledge
out of unusual data, but lowers their weight which does not let unusual
data to influence our regression to much. Now lets ‚Ä¶&lt;/p&gt;
&lt;h1 id="compare-both-models-and-choose-the-best"&gt;Compare both models and
choose the best&lt;/h1&gt;
&lt;p&gt;First, &lt;code&gt;plot_model()&lt;/code&gt; command from {sjPlot} package easily
visualizes predictions of both models.&lt;/p&gt;
&lt;p&gt;The ordinary linear model shows no trend. However, the absence of a
trend may only be caused by the outlier N¬∞4, which drags the line down
and widens the confidence intervals, making us less confident in our
results. In contrast, a robust regression ignores the outlier and shows
a clear trend with a narrow confidence intervals.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# 5. visualize both models
plot_model(m,  type = &amp;quot;pred&amp;quot;, show.data = T)
plot_model(rm, type = &amp;quot;pred&amp;quot;, show.data = T)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Moreover, &lt;code&gt;tab_model()&lt;/code&gt; command from {sjPlot} package
shows that a robust model has much higher coefficient of determination
&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;, which means that robust model
fits the data much better then the ordinary model. And finally, we can
see that the results can be dramatically different. Namely, a slope is
significant in a robust regression, while not significant in the
ordinary linear model, indicating that ordinary model (1) was soo
heavily biased by the outlier, (2) that it produced a wrong result, (3)
which made me miss an important discovery (4) and never win a Nobel
Price ;)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$predictor&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$predictor&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/figures-side2-1.png" width="50%" /&gt;&lt;img src="filef29c59648658_files/figure-html/figures-side2-2.png" width="50%" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# 6. compare coefficients and goodness of fit of both models
tab_model(m)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
outcome
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
CI
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.23
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-6.52¬†‚Äì¬†6.98
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.921
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
predictor
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.67
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-1.37¬†‚Äì¬†2.71
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.372
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;
0.268 / 0.024
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_model(rm)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
outcome
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
CI
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-0.19
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-0.77¬†‚Äì¬†0.39
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.380
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
predictor
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
1.09
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.97¬†‚Äì¬†1.21
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;
5
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;
0.979 / 0.972
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;So, having robust regression in your statistical toolbox will already
step up your data-science game, but robust regression does not save you
from violations of other model assumptions, which you definitely need to
check, otherwise you might again get a completely wrong result.
Fortunately, there is only &lt;strong&gt;one function&lt;/strong&gt; which
&lt;strong&gt;checks and visualizes all the assumptions of any model at
once&lt;/strong&gt; which you can learn more about from &lt;a
href="https://youtu.be/EPIxQ5i5oxs"&gt;this video&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id="works-also-in-a-complicated-model"&gt;Works also in a complicated
model&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(carData)
cm &amp;lt;- lm(prestige ~ income * education, data = Duncan)
ols_plot_resid_lev(cm)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/unnamed-chunk-5-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;crm &amp;lt;- lmrob(prestige ~ income * education, data = Duncan)

library(performance)
compare_performance(cm, crm, rank = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Comparison of Model Performance Indices

Name | Model |    R2 | R2 (adj.) |   RMSE |  Sigma | Performance-Score
----------------------------------------------------------------------
crm  | lmrob | 0.885 |     0.876 | 13.506 | 10.170 |            75.00%
cm   |    lm | 0.829 |     0.816 | 12.895 | 13.509 |            25.00%&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="there-are-further-packages-for-robust-regression-but"&gt;There are
further packages for robust regression, but‚Ä¶&lt;/h1&gt;
&lt;p&gt;MASS::rlm() does not provide &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;
while robust::lmRob() does not provide info on outliers and has a
smaller &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;. There are also other
options to conduct a non-parametric regression, like least trimmed
squares, quantile regression or bootstrapped regression. But, while all
of them have merits, I personally decided to always use
robustbase::lmrob() if I have unsual data.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;rm2 &amp;lt;- MASS::rlm(outcome ~ predictor, data= d)
rm3 &amp;lt;- robust::lmRob(outcome ~ predictor, data= d)

plot_model(rm2, type = &amp;quot;pred&amp;quot;, show.data = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$predictor&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(rm3, type = &amp;quot;pred&amp;quot;, show.data = T)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$predictor&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c59648658_files/figure-html/figures-side4-1.png" width="50%" /&gt;&lt;img src="filef29c59648658_files/figure-html/figures-side4-2.png" width="50%" /&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>eac1c282851219989ca8486736109c62</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression</guid>
      <pubDate>Wed, 28 Sep 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression/thumbnail_robust.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo| Many Models with Nested (Grouped) Data Easily</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels</link>
      <description>


&lt;h1 id="this-post-as-a-video"&gt;This post as a video&lt;/h1&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs ca. 7 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/tQ8dC0oLTnA" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="why-do-we-need-many-models"&gt;Why do we need many models?&lt;/h1&gt;
&lt;p&gt;Have a close look at this linear model. It tells you that &lt;strong&gt;the
only thing&lt;/strong&gt; you need to do in order to earn significantly more
money - is to get older. But why does one group of people earn so much
more, than the others? And is a single model able to catch that
groups?&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(ggpubr) # for stat_cor() function
ggplot(Wage, aes(age, wage))+
  geom_point(alpha = 0.2)+
  geom_smooth(method = lm)+
  stat_cor()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;one_model.jpg&amp;quot;, plot = last_plot())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Well, when look at education of these 3000 people, we‚Äôll see that
most of the richest people have an advanced degree, while most of the
poorest people have just a high school or below. And if we create 5
models instead of one, we‚Äôll see &lt;strong&gt;a much more useful
story&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(age, wage))+
    geom_point(alpha = 0.7, aes(color = education))+
    geom_smooth(method = lm)+
    stat_cor()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-3-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;one_model_data.jpg&amp;quot;, plot = last_plot())&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For instance, the increase of salary with age is much higher when you
have at least some college degree as compared to no education. So that
at the end of life we‚Äôll end up with an impressive salary of 150
thousand dollars, while without any education we‚Äôll never cross 100
thousand mark. So, it seems like education matters, and the slope
clearly tells us that! However, despite the fact that the slope of the
advanced degree is much smaller, which &lt;strong&gt;could&lt;/strong&gt; suggest
that education is not worth the effort, the intercept tells a different
story. Namely, that folks who invested into education upfront start
their life with the same salary, ‚Äúsome-college‚Äù guys reach only at the
end of their life.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(age, wage))+
  geom_point(alpha = 0.2)+
  geom_smooth(method = lm)+
  facet_grid(. ~ education)+
  stat_cor()+
  stat_regline_equation(label.y = 240)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-4-1.png" width="960" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;five_models.jpg&amp;quot;, plot = last_plot(), width = 8.1, height = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, you see how much more useful 5 models are compared to one! But
what about 10 model, for example when we group our data for health
insurance? What about 20 models when we account for different
jobclasses? The more models you create, the more useful insights you‚Äôll
get! Then what about 1000 models? ‚Ä¶ ok, ok, we don‚Äôt have to exaggerate.
Let‚Äôs stick to only 10 models and learn how to easily compute them and
get all useful information, like slopes, measures of fit and p-values,
out of them.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(x = age, y = wage, color = health_ins)) +
   geom_point(alpha = 0.1, shape = 1) +
   geom_smooth(method = &amp;quot;lm&amp;quot;) +
   facet_grid(. ~ education, scales = &amp;quot;free&amp;quot;)+
    stat_cor()+
  theme(legend.position = &amp;quot;none&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-5-1.png" width="960" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;10_models.jpg&amp;quot;, plot = last_plot(), width = 8.5, height = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(age, wage, color = health_ins))+
    geom_point(alpha = 0.1)+
    geom_smooth(method = lm)+
    facet_grid(jobclass ~ education)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-6-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;20_models.jpg&amp;quot;, plot = last_plot(), width = 8.1, height = 5)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="nested-grouped-data"&gt;Nested (grouped) data&lt;/h1&gt;
&lt;p&gt;The Wage data you have seen on the plot is part of the ISLR package.
If we have a glimpse at it, we‚Äôll see categorical variables ‚Äúeducation‚Äù
and ‚Äúhealth insurance‚Äù. A simple cross table reveals how many
observations we‚Äôll have in every of our 10 models.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse) # for everything good in R ;)
library(ISLR)      # for Wage dataset

Wage %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Rows: 3,000
Columns: 11
$ year       &amp;lt;int&amp;gt; 2006, 2004, 2003, 2003, 2005, 2008, 2009, 2008, 2‚Ä¶
$ age        &amp;lt;int&amp;gt; 18, 24, 45, 43, 50, 54, 44, 30, 41, 52, 45, 34, 3‚Ä¶
$ maritl     &amp;lt;fct&amp;gt; 1. Never Married, 1. Never Married, 2. Married, 2‚Ä¶
$ race       &amp;lt;fct&amp;gt; 1. White, 1. White, 1. White, 3. Asian, 1. White,‚Ä¶
$ education  &amp;lt;fct&amp;gt; 1. &amp;lt; HS Grad, 4. College Grad, 3. Some College, 4‚Ä¶
$ region     &amp;lt;fct&amp;gt; 2. Middle Atlantic, 2. Middle Atlantic, 2. Middle‚Ä¶
$ jobclass   &amp;lt;fct&amp;gt; 1. Industrial, 2. Information, 1. Industrial, 2. ‚Ä¶
$ health     &amp;lt;fct&amp;gt; 1. &amp;lt;=Good, 2. &amp;gt;=Very Good, 1. &amp;lt;=Good, 2. &amp;gt;=Very G‚Ä¶
$ health_ins &amp;lt;fct&amp;gt; 2. No, 2. No, 1. Yes, 1. Yes, 1. Yes, 1. Yes, 1. ‚Ä¶
$ logwage    &amp;lt;dbl&amp;gt; 4.318063, 4.255273, 4.875061, 5.041393, 4.318063,‚Ä¶
$ wage       &amp;lt;dbl&amp;gt; 75.04315, 70.47602, 130.98218, 154.68529, 75.0431‚Ä¶&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;table(Wage$education, Wage$health_ins)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;                    
                     1. Yes 2. No
  1. &amp;lt; HS Grad          124   144
  2. HS Grad            612   359
  3. Some College       467   183
  4. College Grad       529   156
  5. Advanced Degree    351    75&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But before we can model, we need to split our data into 10 groups
using ‚Äúgroup_by()‚Äù function and then lock these 10 groups into 10
different data-sets using ‚Äúnest()‚Äù function.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_data &amp;lt;- Wage %&amp;gt;% 
  group_by(education, health_ins) %&amp;gt;% 
  nest() 

nested_data&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 10 √ó 3
# Groups:   education, health_ins [10]
   education          health_ins data              
   &amp;lt;fct&amp;gt;              &amp;lt;fct&amp;gt;      &amp;lt;list&amp;gt;            
 1 1. &amp;lt; HS Grad       2. No      &amp;lt;tibble [144 √ó 9]&amp;gt;
 2 4. College Grad    2. No      &amp;lt;tibble [156 √ó 9]&amp;gt;
 3 3. Some College    1. Yes     &amp;lt;tibble [467 √ó 9]&amp;gt;
 4 4. College Grad    1. Yes     &amp;lt;tibble [529 √ó 9]&amp;gt;
 5 2. HS Grad         1. Yes     &amp;lt;tibble [612 √ó 9]&amp;gt;
 6 2. HS Grad         2. No      &amp;lt;tibble [359 √ó 9]&amp;gt;
 7 5. Advanced Degree 2. No      &amp;lt;tibble [75 √ó 9]&amp;gt; 
 8 5. Advanced Degree 1. Yes     &amp;lt;tibble [351 √ó 9]&amp;gt;
 9 3. Some College    2. No      &amp;lt;tibble [183 √ó 9]&amp;gt;
10 1. &amp;lt; HS Grad       1. Yes     &amp;lt;tibble [124 √ó 9]&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In a &lt;strong&gt;nested data frame&lt;/strong&gt; each row is a
meta-observation (‚àû üòÇ) where categorical variables ‚Äúeducation and
health insurance‚Äù define our 10 groups, while the list-column of 10
data-sets could be seen as 10 lockers which contain individual
observations belonging only to a particular combination of education and
health insurance. In the first case, 144 people have no education (‚Äú1.
&amp;lt; HS Grad‚Äù) and no health-insurance (‚Äú2. No‚Äù). And if you think, that
a list-column of data-sets is a crazy idea, wait a second, and you‚Äôll
see how useful it is.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_data$data[[1]] %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Rows: 144
Columns: 9
$ year     &amp;lt;int&amp;gt; 2006, 2003, 2004, 2006, 2008, 2003, 2009, 2007, 200‚Ä¶
$ age      &amp;lt;int&amp;gt; 18, 27, 43, 25, 44, 24, 53, 41, 43, 35, 27, 25, 38,‚Ä¶
$ maritl   &amp;lt;fct&amp;gt; 1. Never Married, 2. Married, 1. Never Married, 1. ‚Ä¶
$ race     &amp;lt;fct&amp;gt; 1. White, 1. White, 1. White, 1. White, 1. White, 1‚Ä¶
$ region   &amp;lt;fct&amp;gt; 2. Middle Atlantic, 2. Middle Atlantic, 2. Middle A‚Ä¶
$ jobclass &amp;lt;fct&amp;gt; 1. Industrial, 1. Industrial, 1. Industrial, 1. Ind‚Ä¶
$ health   &amp;lt;fct&amp;gt; 1. &amp;lt;=Good, 2. &amp;gt;=Very Good, 1. &amp;lt;=Good, 2. &amp;gt;=Very Goo‚Ä¶
$ logwage  &amp;lt;dbl&amp;gt; 4.318063, 4.193125, 3.812913, 4.193125, 4.477121, 3‚Ä¶
$ wage     &amp;lt;dbl&amp;gt; 75.04315, 66.22941, 45.28217, 66.22941, 87.98103, 5‚Ä¶&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="how-does-this-work-amd-why-it-is-so-useful"&gt;How does this work
amd why it is so useful?&lt;/h1&gt;
&lt;p&gt;Imagine you‚Äôd need to write a code for 10 different models. That is
not only a lot of work, but is also prone to mistakes. Moreover, you‚Äôd
need to store and organize 10 different model objects somehow, because
they contain information you need. And while it kind of works for 10
models, what if you really need 1000 or more?&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m1 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;1. &amp;lt; HS Grad&amp;quot;, health_ins == &amp;quot;2. No&amp;quot;))
m2 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;4. College Grad&amp;quot;, health_ins == &amp;quot;2. No&amp;quot;))
m3 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;3. Some College&amp;quot;, health_ins == &amp;quot;1. Yes&amp;quot;))
m4 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;4. College Grad&amp;quot;, health_ins == &amp;quot;1. Yes&amp;quot;))
m5 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;2. HS Grad&amp;quot;, health_ins == &amp;quot;1. Yes&amp;quot;))
m6 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;2. HS Grad&amp;quot;, health_ins == &amp;quot;2. No&amp;quot;))
m7 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;5. Advanced Degree&amp;quot;, health_ins == &amp;quot;2. No&amp;quot;))
m8 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;5. Advanced Degree&amp;quot;, health_ins == &amp;quot;1. Yes&amp;quot;))
m9 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;3. Some College&amp;quot;, health_ins == &amp;quot;2. No&amp;quot;))
m10 &amp;lt;- lm(wage ~ age, 
         data = Wage %&amp;gt;% filter(education == &amp;quot;1. &amp;lt; HS Grad&amp;quot;, health_ins == &amp;quot;1. Yes&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="map-function-rocks"&gt;&lt;code&gt;map()&lt;/code&gt; function rocks!&lt;/h2&gt;
&lt;p&gt;Well, &lt;code&gt;map()&lt;/code&gt; function from {purrr} package provides a
much better way! Because it applies a function of your choice to each
element of a list. For example, if we want to multiply every element of
our list by 10, we ‚Äúmap()‚Äù over every element of this list, where every
element is represented by the DOT - ‚Äú.‚Äù&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;data &amp;lt;- list(1, 2, 3)

map(data, ~ . * 10) %&amp;gt;% 
  t()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;     [,1] [,2] [,3]
[1,] 10   20   30  &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Similarly, we can ‚Äúmap()‚Äù over every meta-observation (‚àû üòÇ) of our
nested data-frame and apply a linear regression to every of the 10
data-frames which are stored in the list-column we called ‚Äúdata‚Äù.
Moreover, rather than leaving the list of models as a free-floating
objects (flies flying around trash, or free floating things in space),
it‚Äôs much better to store all our models in the next list-column, let‚Äôs
call this list-column ‚Äúmodels‚Äù. On top of that let‚Äôs now ‚Äúmap()‚Äù over
our models in order to extract the coefficients with 95% CIs, model
quality indicators and even predictions and store them all in separate
list-columns.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(broom)   # for tidy(), glance() &amp;amp; augment() functions
nested_models &amp;lt;- nested_data %&amp;gt;%
  mutate(models  = map(data, ~ lm(wage ~ age, data = .)), 
         coefs   = map(models, tidy, conf.int = TRUE),
         quality = map(models, glance),
         preds   = map(models, augment)) 

nested_models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 10 √ó 7
# Groups:   education, health_ins [10]
   education        healt‚Ä¶¬π data     models coefs    quality  preds   
   &amp;lt;fct&amp;gt;            &amp;lt;fct&amp;gt;   &amp;lt;list&amp;gt;   &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;   &amp;lt;list&amp;gt;   &amp;lt;list&amp;gt;  
 1 1. &amp;lt; HS Grad     2. No   &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 2 4. College Grad  2. No   &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 3 3. Some College  1. Yes  &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 4 4. College Grad  1. Yes  &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 5 2. HS Grad       1. Yes  &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 6 2. HS Grad       2. No   &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 7 5. Advanced Deg‚Ä¶ 2. No   &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 8 5. Advanced Deg‚Ä¶ 1. Yes  &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
 9 3. Some College  2. No   &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
10 1. &amp;lt; HS Grad     1. Yes  &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;
# ‚Ä¶ with abbreviated variable name ¬π‚Äãhealth_ins&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, with a &lt;strong&gt;minimum of code&lt;/strong&gt;, where it is difficult
to make any mistake, we have created a &lt;strong&gt;small and clean nested
data-frame&lt;/strong&gt; with &lt;strong&gt;5 list-columns&lt;/strong&gt;, where
&lt;strong&gt;all the related objects are stored together&lt;/strong&gt;.
Hallelujah! ;) Such nested data-frame could be seen as a well organized
cabinet with 50 lockers containing &lt;strong&gt;all important information we
need&lt;/strong&gt;, which is &lt;strong&gt;easily accessible anytime we
want&lt;/strong&gt;. For example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we can have a look at the first model or it‚Äôs coeffitients,&lt;/li&gt;
&lt;li&gt;we can check all assumptions of the second model at once using
check_model() function from the {performance} package, which I already
reviewed on this channel,&lt;/li&gt;
&lt;li&gt;we can look at the model quality of, let‚Äôs say, a model N¬∞4 or&lt;/li&gt;
&lt;li&gt;we can plot predictions of a model N¬∞9 using plot_model() function
from another amazing package {sjPlot} I also have an extra video
about&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models$models[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lm(formula = wage ~ age, data = .)

Coefficients:
(Intercept)          age  
    69.8032       0.1572  &lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models$coefs[[1]]&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 √ó 7
  term        estimate std.error statistic  p.value conf.low conf.high
  &amp;lt;chr&amp;gt;          &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;    &amp;lt;dbl&amp;gt;     &amp;lt;dbl&amp;gt;
1 (Intercept)   69.8       5.36      13.0  5.00e-26   59.2      80.4  
2 age            0.157     0.131      1.20 2.30e- 1   -0.101     0.415&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models$models[[2]] %&amp;gt;% performance::check_model()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-14-1.png" width="864" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models$quality[[4]] %&amp;gt;% glimpse()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Rows: 1
Columns: 12
$ r.squared     &amp;lt;dbl&amp;gt; 0.01700412
$ adj.r.squared &amp;lt;dbl&amp;gt; 0.01513886
$ sigma         &amp;lt;dbl&amp;gt; 40.33913
$ statistic     &amp;lt;dbl&amp;gt; 9.116186
$ p.value       &amp;lt;dbl&amp;gt; 0.002656313
$ df            &amp;lt;dbl&amp;gt; 1
$ logLik        &amp;lt;dbl&amp;gt; -2705.5
$ AIC           &amp;lt;dbl&amp;gt; 5417
$ BIC           &amp;lt;dbl&amp;gt; 5429.813
$ deviance      &amp;lt;dbl&amp;gt; 857558.2
$ df.residual   &amp;lt;int&amp;gt; 527
$ nobs          &amp;lt;int&amp;gt; 529&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models$models[[9]] %&amp;gt;% sjPlot::plot_model(type =  &amp;quot;pred&amp;quot;, show.data = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$age&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-16-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="unnest-results"&gt;Unnest results&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;map(nested_models$models, sjPlot::plot_model, type = &amp;quot;pred&amp;quot;, show.data = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And despite the fact, that we could easily plot all 10 models by
‚Äúmapping‚Äù through the whole list of models, it is sometimes better to
simply ‚Äúunnest()‚Äù the list-column back into a regular data frame. This
is useful, when we want to put all the results below each other to see
the big picture, be able to sort, compare or plot all 10 models
simultaneously.&lt;/p&gt;
&lt;h2 id="unnest-coefficients"&gt;Unnest coefficients&lt;/h2&gt;
&lt;p&gt;For example, we can unnest() the coefficients and see all 10 models
below each other.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(flextable) # for a good looking table
nested_models %&amp;gt;%
  unnest(coefs) %&amp;gt;% 
  select(-data, -models, -quality, -preds) %&amp;gt;% 
  mutate_if(is.numeric, ~ round(., 2)) %&amp;gt;% 
  regulartable() %&amp;gt;% 
  autofit()&lt;/code&gt;&lt;/pre&gt;
&lt;template id="88319b60-5595-4846-becc-e0e95a3bd981"&gt;&lt;style&gt;
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  border-color: transparent;
  caption-side: top;
}
.tabwid-caption-bottom table{
  caption-side: bottom;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
.katex-display {
    margin: 0 0 !important;
}
&lt;/style&gt;&lt;div class="tabwid"&gt;&lt;style&gt;.cl-49d3adf2{}.cl-49ca2c00{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-49cdd832{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49cdd846{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-49cdf4ca{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4d4{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4d5{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4de{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4df{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4e0{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4e8{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4e9{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4ea{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4f2{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4f3{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4f4{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4fc{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf4fd{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf506{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf507{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf508{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf510{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf51a{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf51b{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf524{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf525{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf52e{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf52f{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf530{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf538{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf539{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf542{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf543{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf544{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf54c{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf54d{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf556{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf557{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf560{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf561{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf562{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf56a{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf56b{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf56c{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf574{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf575{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf57e{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf57f{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf588{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf589{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf58a{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf592{width:0.981in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf593{width:0.863in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf594{width:0.854in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf59c{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf59d{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf59e{width:0.846in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-49cdf5a6{width:0.905in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}&lt;/style&gt;&lt;table class='cl-49d3adf2'&gt;&lt;thead&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf4ca"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;education&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4d4"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;health_ins&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4d5"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;term&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4de"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;estimate&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4df"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;std.error&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4e0"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;statistic&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4e8"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;p.value&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4e9"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;conf.low&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4ea"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;conf.high&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf4f2"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f3"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f4"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fc"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;69.80&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fd"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;5.36&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf506"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;13.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf507"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf508"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;59.21&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf510"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;80.39&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf51a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf51b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf524"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf525"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.16&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.13&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.20&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf530"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.23&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf538"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;-0.10&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf539"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.42&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;91.84&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;10.48&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;8.76&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;71.13&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;112.55&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.27&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.24&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.15&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.25&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;-0.20&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.74&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;86.14&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;4.93&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;17.48&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;76.46&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;95.83&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.63&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.11&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;5.57&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.41&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.85&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;109.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;7.36&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;14.83&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;94.61&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;123.51&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.50&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.17&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;3.02&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.18&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.83&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf4f2"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f3"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f4"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fc"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;90.59&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fd"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;4.47&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf506"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;20.25&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf507"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf508"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;81.80&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf510"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;99.37&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf51a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf51b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf524"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf525"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.27&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.10&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;2.74&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf530"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf538"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.08&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf539"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.46&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf4f2"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f3"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f4"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fc"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;66.75&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fd"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;4.49&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf506"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;14.86&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf507"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf508"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;57.92&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf510"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;75.58&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf51a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf51b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf524"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf525"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.45&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.11&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf52f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;4.12&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf530"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf538"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.24&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf539"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.67&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf562"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;97.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf574"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;25.91&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf575"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;3.75&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;45.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf588"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;148.70&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf562"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.73&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf574"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.53&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf575"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.38&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.17&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;-0.33&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf588"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.80&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf562"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;131.15&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf574"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;13.02&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf575"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;10.08&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;105.55&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf588"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;156.75&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf562"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56b"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf56c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.54&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf574"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.29&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf575"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.88&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf57f"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;-0.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf588"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.10&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;44.84&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;8.74&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;5.13&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;27.59&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;62.08&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf542"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf543"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf544"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.34&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf54d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.22&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf556"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;6.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf557"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf560"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.90&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf561"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;1.77&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf4f2"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f3"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4f4"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;(Intercept)&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fc"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;78.74&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf4fd"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;6.91&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf506"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;11.39&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf507"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf508"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;65.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf510"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;92.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-49cdf589"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf58a"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf592"&gt;&lt;p class="cl-49cdd832"&gt;&lt;span class="cl-49ca2c00"&gt;age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf593"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.33&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf594"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.15&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf59c"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;2.22&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf59d"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf59e"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-49cdf5a6"&gt;&lt;p class="cl-49cdd846"&gt;&lt;span class="cl-49ca2c00"&gt;0.62&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/template&gt;
&lt;div class="flextable-shadow-host" id="37784a27-39f9-47d8-8181-d3f16d9e3154"&gt;&lt;/div&gt;
&lt;script&gt;
var dest = document.getElementById("37784a27-39f9-47d8-8181-d3f16d9e3154");
var template = document.getElementById("88319b60-5595-4846-becc-e0e95a3bd981");
var caption = template.content.querySelector("caption");
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
&lt;/script&gt;

&lt;h2 id="unnest-model-quality"&gt;Unnest model quality&lt;/h2&gt;
&lt;p&gt;We could:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unnest() list-column ‚Äúquality‚Äù to extract some model quality
indicators,&lt;br /&gt;
&lt;/li&gt;
&lt;li&gt;easily remove some unnecessary columns and&lt;/li&gt;
&lt;li&gt;sort the data-frame for ‚Äúr.squared‚Äù in order to rank the goodness of
fit of our model and see models that don‚Äôt fit well first.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The worst model appears to be for College Graduates with no health
insurance ‚Ä¶ how could they?&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;nested_models %&amp;gt;% 
  unnest(quality) %&amp;gt;% 
  select(-data, -models, -coefs, -df, -df.residual, -deviance, -preds) %&amp;gt;%
  arrange(adj.r.squared) %&amp;gt;% 
  mutate_if(is.numeric, ~ round(., 2)) %&amp;gt;% 
  regulartable() %&amp;gt;% 
  autofit()&lt;/code&gt;&lt;/pre&gt;
&lt;template id="c509070b-4776-4628-bdfd-a35154c65cae"&gt;&lt;style&gt;
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  border-color: transparent;
  caption-side: top;
}
.tabwid-caption-bottom table{
  caption-side: bottom;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
.katex-display {
    margin: 0 0 !important;
}
&lt;/style&gt;&lt;div class="tabwid"&gt;&lt;style&gt;.cl-4a07e482{}.cl-49ff975a{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-4a02ec8e{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a02ec98{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-4a030106{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030110{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030111{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03011a{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03011b{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030124{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030125{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03012e{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03012f{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030130{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030138{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030139{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03013a{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030142{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03014c{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03014d{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030156{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030157{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030160{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030161{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03016a{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03016b{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03016c{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030174{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030175{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03017e{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03017f{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030180{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030188{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030189{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03018a{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030192{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030193{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03019c{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03019d{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03019e{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301a6{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301a7{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301a8{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301b0{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301b1{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301ba{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301bb{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301bc{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301c4{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301c5{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301c6{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301c7{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301ce{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301cf{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301d8{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301d9{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301e2{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301e3{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301e4{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301ec{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301ed{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a0301f6{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030200{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030201{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030202{width:1.678in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03020a{width:0.982in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03020b{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030214{width:1.177in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030215{width:0.693in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030216{width:0.795in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030217{width:0.778in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03021e{width:0.931in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a03021f{width:0.88in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-4a030228{width:0.616in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}&lt;/style&gt;&lt;table class='cl-4a07e482'&gt;&lt;thead&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a030106"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;education&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030110"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;health_ins&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030111"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;r.squared&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03011a"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;adj.r.squared&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03011b"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;sigma&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030124"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;statistic&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030125"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;p.value&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03012e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;logLik&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03012f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;AIC&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03012f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;BIC&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030130"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;nobs&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a030138"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030139"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03013a"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030142"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;35.77&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014d"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1.31&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030156"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.25&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030157"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-778.39&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,562.77&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,571.92&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030161"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;156&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a03016a"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03016b"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03016c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030174"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030175"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;20.14&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03017e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1.45&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03017f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.23&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030180"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-635.69&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030188"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,277.38&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030188"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,286.29&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030189"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;144&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a03018a"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030192"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030193"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019d"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;53.33&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;3.53&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a6"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a7"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-1,892.83&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a8"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;3,791.66&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a8"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;3,803.24&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301b0"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;351&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a0301b1"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301ba"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301bb"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301bc"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301c4"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;27.56&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301c5"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;7.51&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301c6"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301c7"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-2,897.11&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301ce"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;5,800.22&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301ce"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;5,813.47&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301cf"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;612&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a03018a"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;5. Advanced Degree&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030192"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030193"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.01&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019d"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;51.51&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03019e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1.89&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a6"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.17&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a7"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-401.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a8"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;808.08&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301a8"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;815.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301b0"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;75&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a030138"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;4. College Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030139"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03013a"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.02&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030142"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.02&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;40.34&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014d"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;9.12&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030156"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030157"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-2,705.50&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;5,417.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;5,429.81&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030161"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;529&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a0301d8"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. &amp;lt; HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301d9"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301e2"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301e3"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301e4"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;18.90&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301ec"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;4.92&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301ed"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.03&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a0301f6"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-539.42&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030200"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,084.83&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030200"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,093.30&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030201"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;124&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a03016a"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. HS Grad&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03016b"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03016c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.05&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030174"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030175"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;25.78&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03017e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;17.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03017f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030180"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-1,674.98&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030188"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;3,355.96&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030188"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;3,367.61&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030189"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;359&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a030138"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030139"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;1. Yes&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03013a"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030142"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.06&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014c"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;26.99&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03014d"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;31.02&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030156"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030157"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-2,200.62&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;4,407.24&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030160"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;4,419.68&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030161"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;467&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-4a030202"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;3. Some College&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03020a"&gt;&lt;p class="cl-4a02ec8e"&gt;&lt;span class="cl-49ff975a"&gt;2. No&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03020b"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.17&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030214"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.16&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030215"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;36.04&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030216"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;36.51&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030217"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;0.00&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03021e"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;-914.66&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03021f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,835.31&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a03021f"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;1,844.94&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-4a030228"&gt;&lt;p class="cl-4a02ec98"&gt;&lt;span class="cl-49ff975a"&gt;183&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/template&gt;
&lt;div class="flextable-shadow-host" id="fc5cbfa1-bcf7-44a3-87d7-153b8fcaa4d3"&gt;&lt;/div&gt;
&lt;script&gt;
var dest = document.getElementById("fc5cbfa1-bcf7-44a3-87d7-153b8fcaa4d3");
var template = document.getElementById("c509070b-4776-4628-bdfd-a35154c65cae");
var caption = template.content.querySelector("caption");
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
&lt;/script&gt;

&lt;h2 id="unnest-predictions"&gt;Unnest predictions&lt;/h2&gt;
&lt;p&gt;And lastly,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;we could easily unnest() our predictions in a separate data-frame,
then&lt;/li&gt;
&lt;li&gt;plot() original data and linear models which are already build into
the classic ggplot() commands, by intentionally living same blue color
for different insurances and making them a little bigger, and
finally&lt;/li&gt;
&lt;li&gt;plot &lt;strong&gt;our predictions on top of them with different
colors&lt;/strong&gt; in order to see whether our predictions worked well, and
voil√†, our predictions perfectly fitted the blue lines!&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;unnested_preds &amp;lt;- 
  nested_models %&amp;gt;% 
  unnest(preds)

unnested_preds &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 3,000 √ó 14
# Groups:   education, health_ins [10]
   education    health‚Ä¶¬π data     models coefs    quality   wage   age
   &amp;lt;fct&amp;gt;        &amp;lt;fct&amp;gt;    &amp;lt;list&amp;gt;   &amp;lt;list&amp;gt; &amp;lt;list&amp;gt;   &amp;lt;list&amp;gt;   &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
 1 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  75.0    18
 2 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  66.2    27
 3 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  45.3    43
 4 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  66.2    25
 5 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  88.0    44
 6 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  51.5    24
 7 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  68.1    53
 8 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  88.0    41
 9 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  86.7    43
10 1. &amp;lt; HS Grad 2. No    &amp;lt;tibble&amp;gt; &amp;lt;lm&amp;gt;   &amp;lt;tibble&amp;gt; &amp;lt;tibble&amp;gt;  59.1    35
# ‚Ä¶ with 2,990 more rows, 6 more variables: .fitted &amp;lt;dbl&amp;gt;,
#   .resid &amp;lt;dbl&amp;gt;, .hat &amp;lt;dbl&amp;gt;, .sigma &amp;lt;dbl&amp;gt;, .cooksd &amp;lt;dbl&amp;gt;,
#   .std.resid &amp;lt;dbl&amp;gt;, and abbreviated variable name ¬π‚Äãhealth_ins&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(x = age, y = wage, group = health_ins)) +
   geom_point(aes(color = health_ins), alpha = 0.2, shape = 1) +
   geom_smooth(method = &amp;quot;lm&amp;quot;, size = 2) +
   facet_grid(. ~ education, scales = &amp;quot;free&amp;quot;) +
   geom_line(data = unnested_preds, aes(y = .fitted, age, color = health_ins)) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c7cabe75e_files/figure-html/unnamed-chunk-21-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This beautiful picture is worth a thousand words, but if you need
words and want to learn how to easily and correctly report statistical
results with text, you need to watch &lt;a
href="https://youtu.be/iMh9tPsuiik"&gt;this video&lt;/a&gt;!&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>774a85639298d58926c6733091306a27</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels</guid>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels/thumbnail_many_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {sjPlot} How to Easily Visualize Data And Model Results</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot</link>
      <description>


&lt;h1 id="this-post-as-a-video"&gt;This post as a video&lt;/h1&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then 9 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/r3uKkmU4VQE" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="all-the-functions-youll-learn-from-this-article"&gt;All the
functions you‚Äôll learn from this article&lt;/h1&gt;
&lt;p&gt;&lt;code&gt;view_df()&lt;/code&gt;, &lt;code&gt;plot_frq()&lt;/code&gt;,
&lt;code&gt;save_plot()&lt;/code&gt;, &lt;code&gt;plot_grpfrq()&lt;/code&gt;,
&lt;code&gt;plot_grid()&lt;/code&gt;, &lt;code&gt;plot_xtab()&lt;/code&gt;,
&lt;code&gt;tab_xtab()&lt;/code&gt;, &lt;code&gt;plot_gpt()&lt;/code&gt;,
&lt;code&gt;plot_likert()&lt;/code&gt;, &lt;code&gt;plot_model()&lt;/code&gt;,
&lt;code&gt;tab_model()&lt;/code&gt;, &lt;code&gt;plot_models()&lt;/code&gt;&lt;/p&gt;
&lt;h1 id="load-all-packages-at-once-to-avoid-interruptions"&gt;Load all
packages at once to avoid interruptions&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse)   # for everything useful in R ;) 
library(ISLR)        # for &amp;quot;Wage&amp;quot; dataset about salaries
library(sjPlot)      # for easy visualization
library(likert)      # for &amp;quot;pisaitems&amp;quot; dataset with likert data
library(lme4)        # for mixed-effects models
library(lmerTest)    # for p-values in mixed-effects models&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="plot-data"&gt;Plot data&lt;/h1&gt;
&lt;h2 id="view-dataframe-with-view_df"&gt;View dataframe with
&lt;code&gt;view_df&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;View data-frame (&lt;code&gt;view_df&lt;/code&gt;) function with only 4
arguments, (1) your data, (2) show frequencies, (3) show percentages and
(4) show missing values, displays a range of numeric variables and the
counts + percentages of missing values and categorical variables, giving
you a nice big picture of your data.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;view_df(Wage, show.frq = T, show.prc = T, show.na = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;caption&gt;
Data frame: Wage
&lt;/caption&gt;
&lt;tr&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
ID
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Name
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Label
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
missings
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Values
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Value Labels
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Freq.
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
%
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
1
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
year
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;" colspan="2"&gt;
&lt;em&gt;range: 2003-2009&lt;/em&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
2
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
age
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee" colspan="2"&gt;
&lt;em&gt;range: 18-80&lt;/em&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
3
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
maritl
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Never Married&lt;br&gt;2. Married&lt;br&gt;3. Widowed&lt;br&gt;4. Divorced&lt;br&gt;5.
Separated
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
648&lt;br&gt;2074&lt;br&gt;19&lt;br&gt;204&lt;br&gt;55
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
21.60&lt;br&gt;69.13&lt;br&gt;0.63&lt;br&gt;6.80&lt;br&gt;1.83
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
4
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
race
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;White&lt;br&gt;2. Black&lt;br&gt;3. Asian&lt;br&gt;4. Other
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
2480&lt;br&gt;293&lt;br&gt;190&lt;br&gt;37
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
82.67&lt;br&gt;9.77&lt;br&gt;6.33&lt;br&gt;1.23
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
5
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
education
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&amp;lt; HS Grad&lt;br&gt;2. HS Grad&lt;br&gt;3. Some College&lt;br&gt;4. College
Grad&lt;br&gt;5. Advanced Degree
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
268&lt;br&gt;971&lt;br&gt;650&lt;br&gt;685&lt;br&gt;426
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
8.93&lt;br&gt;32.37&lt;br&gt;21.67&lt;br&gt;22.83&lt;br&gt;14.20
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
6
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
region
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;New England&lt;br&gt;2. Middle Atlantic&lt;br&gt;3. East North Central&lt;br&gt;4.
West North Central&lt;br&gt;5. South Atlantic&lt;br&gt;6. East South Central&lt;br&gt;7.
West South Central&lt;br&gt;8. Mountain&lt;br&gt;9. Pacific
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0&lt;br&gt;3000&lt;br&gt;0&lt;br&gt;0&lt;br&gt;0&lt;br&gt;0&lt;br&gt;0&lt;br&gt;0&lt;br&gt;0
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0.00&lt;br&gt;100.00&lt;br&gt;0.00&lt;br&gt;0.00&lt;br&gt;0.00&lt;br&gt;0.00&lt;br&gt;0.00&lt;br&gt;0.00&lt;br&gt;0.00
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
7
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
jobclass
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Industrial&lt;br&gt;2. Information
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
1544&lt;br&gt;1456
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
51.47&lt;br&gt;48.53
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
8
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
health
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&amp;lt;=Good&lt;br&gt;2. &amp;gt;=Very Good
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
858&lt;br&gt;2142
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
28.60&lt;br&gt;71.40
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
9
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
health_ins
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Yes&lt;br&gt;2. No
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
2083&lt;br&gt;917
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
69.43&lt;br&gt;30.57
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
10
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
logwage
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee" colspan="2"&gt;
&lt;em&gt;range: 3.0-5.8&lt;/em&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
11
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
wage
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
0 (0.00%)
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;" colspan="2"&gt;
&lt;em&gt;range: 20.1-318.3&lt;/em&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/table&gt;
&lt;h2 id="plot-frequencies-with-plot_frq-plot_grpfrq-and-plot_grid"&gt;Plot
frequencies with &lt;code&gt;plot_frq&lt;/code&gt;, &lt;code&gt;plot_grpfrq&lt;/code&gt; and
&lt;code&gt;plot_grid&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;However, we often want to see an actual picture, for example, display
frequencies and percentages of categorical variables on a bar plot. For
that {sjPlot} package provides a convenient plot-frequencies
(&lt;code&gt;plot_frq&lt;/code&gt;) function, which does just that. For instance,
plotting &lt;em&gt;education&lt;/em&gt; shows that around 9% of people in our data
did not finish a high school, while around 14% have a PhD.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;Wage %&amp;gt;% 
  plot_frq(education)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-4-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Since {sjPlot} package works with tidyverse ü•≥, we can easily group
the data by any other categorical variable, let‚Äôs take &lt;em&gt;race&lt;/em&gt;,
and get frequencies and percentages for every group.
&lt;code&gt;plot_grid()&lt;/code&gt; function puts several subplots in a single plot
and even names the subplots. For instance, a subplot &lt;em&gt;C&lt;/em&gt; shows
that most of Afro-Americans in our dataset ARE highly educated. And of
coarse you can save this publication-ready plot with ‚Ä¶ surprise
surpriiise ‚Ä¶ &lt;code&gt;save_plot&lt;/code&gt; command.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;p &amp;lt;- Wage %&amp;gt;% 
  group_by(race) %&amp;gt;% 
  plot_frq(education) %&amp;gt;%
    plot_grid()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-5-1.png" width="1344" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;save_plot(filename = &amp;quot;race_vs_education.jpg&amp;quot;, fig = p, width = 30, height = 19)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;quartz_off_screen 
                2 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While seeing counts and percentages of separate groups is cool, we
sometimes want to put groups directly near each other. And that‚Äôs
exactly what plot-grouped-frequencies (&lt;code&gt;plot_grpfrq&lt;/code&gt;)
function does. For instance, it clearly shows that most of the people
with lower &lt;em&gt;education&lt;/em&gt; degrees work in &lt;em&gt;factories&lt;/em&gt;, while
folks with higher &lt;em&gt;education&lt;/em&gt; degrees work with
&lt;em&gt;information&lt;/em&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_grpfrq(
  var.cnt = Wage$education, 
  var.grp = Wage$jobclass)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-7-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="plot-or-display-cross-pivot-tables"&gt;Plot or display cross
(pivot) tables&lt;/h2&gt;
&lt;p&gt;This IS already useful, however, &lt;code&gt;plot_xtab&lt;/code&gt; function goes
one step further and displays percentages of &lt;em&gt;jobclasses&lt;/em&gt; inside
of every &lt;em&gt;educational&lt;/em&gt; degree as &lt;strong&gt;stacked-bars&lt;/strong&gt;,
where counts are identical to the previous plot, but every
&lt;em&gt;educational&lt;/em&gt; category as one 100 percent. Such display only
reinforces our hypothesis that highly educated folks usually work in the
IT and shows a clear association between &lt;em&gt;jobclass&lt;/em&gt; and
&lt;em&gt;education&lt;/em&gt;. As if that were not enough, &lt;code&gt;plot_xtab&lt;/code&gt;
even tests this hypothesis with the &lt;strong&gt;Chi-Squared test of
association&lt;/strong&gt; and displays a significant p-value and a large
effect size.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# as stacked proportional bars
plot_xtab(
  x   = Wage$education, 
  grp = Wage$jobclass, 
  margin  = &amp;quot;row&amp;quot;, 
  bar.pos = &amp;quot;stack&amp;quot;,
  show.summary = TRUE,
  coord.flip   = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-8-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;So, &lt;code&gt;plot_xtab&lt;/code&gt; essentially visualizes &lt;strong&gt;cross
tables&lt;/strong&gt;, also known as &lt;strong&gt;pivot tables&lt;/strong&gt;. And if for
some reason you want an actual table with the results of a statistical
test, you can use &lt;code&gt;tab_xtab&lt;/code&gt; function instead.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_xtab(
  var.row = Wage$education, 
  var.col = Wage$jobclass, 
  show.row.prc = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top:double; text-align:center; font-style:italic; font-weight:normal; border-bottom:1px solid;" rowspan="2"&gt;
education
&lt;/th&gt;
&lt;th style="border-top:double; text-align:center; font-style:italic; font-weight:normal;" colspan="2"&gt;
jobclass
&lt;/th&gt;
&lt;th style="border-top:double; text-align:center; font-style:italic; font-weight:normal; font-weight:bolder; font-style:italic; border-bottom:1px solid; " rowspan="2"&gt;
Total
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="border-bottom:1px solid; text-align:center; padding:0.2cm;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;Industrial
&lt;/td&gt;
&lt;td style="border-bottom:1px solid; text-align:center; padding:0.2cm;"&gt;
&lt;ol start="2" style="list-style-type: decimal"&gt;
&lt;li&gt;Information
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  text-align:left; vertical-align:middle;"&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&amp;lt; HS Grad
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;190&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;70.9¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;78&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;29.1¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;  "&gt;
&lt;span style="color:black;"&gt;268&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  text-align:left; vertical-align:middle;"&gt;
&lt;ol start="2" style="list-style-type: decimal"&gt;
&lt;li&gt;HS Grad
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;636&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;65.5¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;335&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;34.5¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;  "&gt;
&lt;span style="color:black;"&gt;971&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  text-align:left; vertical-align:middle;"&gt;
&lt;ol start="3" style="list-style-type: decimal"&gt;
&lt;li&gt;Some College
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;342&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;52.6¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;308&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;47.4¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;  "&gt;
&lt;span style="color:black;"&gt;650&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  text-align:left; vertical-align:middle;"&gt;
&lt;ol start="4" style="list-style-type: decimal"&gt;
&lt;li&gt;College Grad
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;274&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;40¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;411&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;60¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;  "&gt;
&lt;span style="color:black;"&gt;685&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  text-align:left; vertical-align:middle;"&gt;
&lt;ol start="5" style="list-style-type: decimal"&gt;
&lt;li&gt;Advanced Degree
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;102&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;23.9¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center; "&gt;
&lt;span style="color:black;"&gt;324&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;76.1¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;  "&gt;
&lt;span style="color:black;"&gt;426&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm;  border-bottom:double; font-weight:bolder; font-style:italic; text-align:left; vertical-align:middle;"&gt;
Total
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;   border-bottom:double;"&gt;
&lt;span style="color:black;"&gt;1544&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;51.5¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;   border-bottom:double;"&gt;
&lt;span style="color:black;"&gt;1456&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;48.5¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:center;   border-bottom:double;"&gt;
&lt;span style="color:black;"&gt;3000&lt;/span&gt;&lt;br&gt;&lt;span
style="color:#333399;"&gt;100¬†%&lt;/span&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;td style="text-align:right; font-size:0.9em; font-style:italic; padding:0.2cm;" colspan="4"&gt;
œá&lt;sup&gt;2&lt;/sup&gt;=282.643 ¬∑ df=4 ¬∑ Cramer‚Äôs V=0.307 ¬∑ p=0.000
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;(not part of the video) By the way, we can decide what kind of
percentages are calculated, rows or columns or even single cells,
whether we want to stack the bars and many more. It will automatically
conduct Fisher‚Äôs test of association if samples are small (&amp;lt;5).&lt;/p&gt;
&lt;h2
id="not-in-the-video-plot-grouped-proportional-tables-i-am-not-sure-its-very-intuitive"&gt;(not
in the video) Plot grouped proportional tables (I am not sure it‚Äôs very
intuitive)&lt;/h2&gt;
&lt;p&gt;The p-values are based on chisq.test of x and y for each grp.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;Wage %&amp;gt;% 
  plot_gpt(x = health_ins, y = jobclass, grp = education) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-10-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="plot-histograms-of-salaries-and-display-averages-sd"&gt;Plot
histograms of salaries and display averages + SD&lt;/h2&gt;
&lt;p&gt;But enough about counting, since our dataset is about salaries, let‚Äôs
figure our who earns more, industrial or information workers? Plot
frequencies function, which we used for counting, can also easily answer
this question if we give it a (1) &lt;code&gt;wage&lt;/code&gt; variable, (2) tell
it to plot a &lt;code&gt;histogram&lt;/code&gt;, (3) to show an average with
standard deviation and (4) to display a normal curve to see whether our
salaries are normally distributed. This visualization reveals that
industrial workers get 103 thousand dollars on average, while IT crowd
gets 17 thousand more.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;Wage %&amp;gt;% 
  group_by(jobclass) %&amp;gt;% 
  plot_frq(wage, type = &amp;quot;histogram&amp;quot;, show.mean = TRUE, normal.curve = TRUE) %&amp;gt;% 
  plot_grid()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-11-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="plot-likert-scales-as-centered-stacked-bars"&gt;Plot likert scales
as centered stacked bars&lt;/h2&gt;
&lt;p&gt;The last thing I‚Äôd like to share with you before we visualize models,
is a visualization of likert scale data. If you have same scales or
categories across different variables, &lt;code&gt;plot_likert&lt;/code&gt; function
nicely compares percentages of scales or categories across those
variables.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;data(pisaitems)

d &amp;lt;- pisaitems %&amp;gt;% 
  dplyr::select(starts_with(&amp;quot;ST25Q&amp;quot;))

view_df(d, show.frq = T, show.prc = T)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;caption&gt;
Data frame: d
&lt;/caption&gt;
&lt;tr&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
ID
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Name
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Label
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Values
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Value Labels
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Freq.
&lt;/th&gt;
&lt;th style="border-bottom:double; font-style:italic; font-weight:normal; padding:0.2cm; text-align:left; vertical-align:top;"&gt;
%
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
1
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
ST25Q01
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Never or almost never&lt;br&gt;A few times a year&lt;br&gt;About once a
month&lt;br&gt;Several times a month&lt;br&gt;Several times a week
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
6682&lt;br&gt;13143&lt;br&gt;13995&lt;br&gt;20353&lt;br&gt;11436
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
10.18&lt;br&gt;20.03&lt;br&gt;21.33&lt;br&gt;31.02&lt;br&gt;17.43
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
2
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
ST25Q02
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
Never or almost never&lt;br&gt;A few times a year&lt;br&gt;About once a
month&lt;br&gt;Several times a month&lt;br&gt;Several times a week
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
24019&lt;br&gt;16789&lt;br&gt;10317&lt;br&gt;9489&lt;br&gt;4751
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
36.75&lt;br&gt;25.68&lt;br&gt;15.78&lt;br&gt;14.52&lt;br&gt;7.27
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
3
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
ST25Q03
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Never or almost never&lt;br&gt;A few times a year&lt;br&gt;About once a
month&lt;br&gt;Several times a month&lt;br&gt;Several times a week
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
11131&lt;br&gt;16164&lt;br&gt;12818&lt;br&gt;14569&lt;br&gt;10658
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
17.04&lt;br&gt;24.74&lt;br&gt;19.62&lt;br&gt;22.30&lt;br&gt;16.31
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
4
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
ST25Q04
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
Never or almost never&lt;br&gt;A few times a year&lt;br&gt;About once a
month&lt;br&gt;Several times a month&lt;br&gt;Several times a week
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
20145&lt;br&gt;19961&lt;br&gt;12768&lt;br&gt;8797&lt;br&gt;3622
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top; background-color:#eeeeee"&gt;
30.85&lt;br&gt;30.57&lt;br&gt;19.55&lt;br&gt;13.47&lt;br&gt;5.55
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
5
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
ST25Q05
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
Never or almost never&lt;br&gt;A few times a year&lt;br&gt;About once a
month&lt;br&gt;Several times a month&lt;br&gt;Several times a week
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
12317&lt;br&gt;12141&lt;br&gt;10314&lt;br&gt;15645&lt;br&gt;15165
&lt;/td&gt;
&lt;td style="padding:0.2cm; text-align:left; vertical-align:top;"&gt;
18.78&lt;br&gt;18.51&lt;br&gt;15.73&lt;br&gt;23.86&lt;br&gt;23.12
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_likert(d) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-12-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h1 id="plot-model-results"&gt;Plot model results&lt;/h1&gt;
&lt;p&gt;Visualizing data is quite, but let‚Äôs get to the really cool
visualization stuff!&lt;/p&gt;
&lt;h2 id="plot-predictions"&gt;Plot predictions&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;plot_model&lt;/code&gt; function is the actual reason I love {sjPlot}
package. &lt;strong&gt;I literally use it everyday!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;For example if I want to know how education influences salary, I‚Äôll
plot predictions from a simple linear model. Plotting prediction
immediately tells me the story. Namely, people who did not even finish a
high school, have the lowest salary compared to any other education
level. Moreover, we can see that increasing education level means
increasing salaries. &lt;strong&gt;So, education matters!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m &amp;lt;- lm(wage ~ education, data = Wage)
plot_model(m, type = &amp;quot;pred&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$education&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-13-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="plot-coefficients"&gt;Plot coefficients&lt;/h2&gt;
&lt;p&gt;The only thing we can‚Äôt see from this plot is whether this increase
is significant or not. We could use a well known &lt;code&gt;summary&lt;/code&gt;
table for that, but the output, although useful, is not really pleasing
to the human eye and is not suitable for publication.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;summary(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lm(formula = wage ~ education, data = Wage)

Residuals:
    Min      1Q  Median      3Q     Max 
-112.31  -19.94   -3.09   15.33  222.56 

Coefficients:
                            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)                   84.104      2.231  37.695  &amp;lt; 2e-16 ***
education2. HS Grad           11.679      2.520   4.634 3.74e-06 ***
education3. Some College      23.651      2.652   8.920  &amp;lt; 2e-16 ***
education4. College Grad      40.323      2.632  15.322  &amp;lt; 2e-16 ***
education5. Advanced Degree   66.813      2.848  23.462  &amp;lt; 2e-16 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 36.53 on 2995 degrees of freedom
Multiple R-squared:  0.2348,    Adjusted R-squared:  0.2338 
F-statistic: 229.8 on 4 and 2995 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Luckily for us, &lt;code&gt;plot_model()&lt;/code&gt; with the argument
&lt;code&gt;show.values = TRUE&lt;/code&gt; transforms a boring summary table into
this informative picture, which shows the increase in &lt;em&gt;salary&lt;/em&gt; in
thousands of dollars as compared to no &lt;em&gt;education&lt;/em&gt; (Intercept,
not shown) with 95% confidence intervals and significance stars which
indicate that those increases in &lt;em&gt;salary&lt;/em&gt; are significant.&lt;/p&gt;
&lt;p&gt;(not in the video) Where vertical 0 indicates no effect (x-axis
position 1 for most glm‚Äôs and position 0 for most linear models)&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(m, show.values = TRUE, width = 0.1)+
  ylab(&amp;quot;Increase in salary as compared to no education&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-15-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;plot_model1.jpg&amp;quot;, device = jpeg, plot = last_plot(), width = 5, height = 4)&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="table-with-coeffitients-95-cis-p-values-more"&gt;Table with
coeffitients, 95% CIs, p-values &amp;amp; more&lt;/h2&gt;
&lt;p&gt;However, sometimes we still need to report the summary table, but we
need to make it look better. And that‚Äôs where &lt;code&gt;tab_model&lt;/code&gt;
command comes into play. Within &lt;code&gt;tab_model&lt;/code&gt; we can show the
reference level, hide the intercept and change the style of
p-values.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_model(m, 
          show.reflvl = T, 
          show.intercept = F, 
          p.style = &amp;quot;numeric_stars&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
wage
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
CI
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&amp;lt; HS Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;em&gt;Reference&lt;/em&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="2" style="list-style-type: decimal"&gt;
&lt;li&gt;HS Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
11.68 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
6.74¬†‚Äì¬†16.62
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="3" style="list-style-type: decimal"&gt;
&lt;li&gt;Some College
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
23.65 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
18.45¬†‚Äì¬†28.85
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="4" style="list-style-type: decimal"&gt;
&lt;li&gt;College Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
40.32 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
35.16¬†‚Äì¬†45.48
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="5" style="list-style-type: decimal"&gt;
&lt;li&gt;Advanced Degree
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
66.81 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
61.23¬†‚Äì¬†72.40
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;
3000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;
0.235 / 0.234
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan="4" style="font-style:italic; border-top:double black; text-align:right;"&gt;
&lt;ul&gt;
&lt;li&gt;p&amp;lt;0.05¬†¬†¬†** p&amp;lt;0.01¬†¬†¬†*** p&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/table&gt;
&lt;h2 id="plot-fancy-models"&gt;Plot fancy models üòâüí™ü§ì&lt;/h2&gt;
&lt;p&gt;But the most amazing thing about &lt;code&gt;plot_model&lt;/code&gt; and
&lt;code&gt;tab_model&lt;/code&gt; functions is that they work with almost any type
of model you can imagine! I successfully used it for mixed-effects
models, Bayesian models or negative-binomial models, to name a few. And
the authors of the package constantly improve the functionality, so
that, at the moment you read this blog-post, {sjPlot} package is most
likely improved.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-08-01-sjplot/sjPlot.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here is an example of how ease we can visualize a very fancy model,
namely a &lt;strong&gt;generalized linear mixed-effects regression for
negative-binomial distribution of age with 3 way interaction term and a
random effect of education&lt;/strong&gt;.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m.nb &amp;lt;- glmer.nb(age ~ wage * jobclass * health + (1|education), data = Wage)

plot_model(m.nb, type = &amp;quot;int&amp;quot;)[[4]]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-17-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggsave(&amp;quot;plot_model2.jpg&amp;quot;, device = jpeg, plot = last_plot(), width = 5, height = 3)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This interactions show that industrial workers with a very good
health earn 50 thousand dollars already at the age of 31, while IT crowd
gets the same salary ca. 8 years later, however at the age of 45 the IT
crowd catches on and even starts to slowly overtake the factory workers,
and finally, while IT folks get to the salary of 300 thousand dollars
already at the age of 50, factory workers might reach this kind of
wealth only at the end of their carrier, at around 63 years old. And the
non-overlapping confidence intervals indicate that such difference in
salaries is significant.&lt;/p&gt;
&lt;p&gt;Besides, you can easily change the appearance of your results by
changing the default order of predictors and even choose particular
values from the numeric predictor. For instance, let‚Äôs take three salary
values 50, 150 &amp;amp; 300 as we just talked about them and display our
results in a different way.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(m.nb, type = &amp;quot;pred&amp;quot;, terms = c(&amp;quot;health&amp;quot;, &amp;quot;jobclass&amp;quot;, &amp;quot;wage [50, 150, 300]&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-18-1.png" width="1056" /&gt;&lt;/p&gt;
&lt;p&gt;Moreover, &lt;code&gt;type&lt;/code&gt; argument allows to create various plot
types. For example, we can easily visualize random effects if we want
to.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(m.nb, 
           type  = &amp;quot;re&amp;quot;, 
           width = .5, 
           show.values = T) + ylim(0.9,1.1)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-19-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="plot-multiple-models"&gt;Plot multiple models&lt;/h2&gt;
&lt;p&gt;It only gets better from now. If we want to explore several dependent
variables with the same predictors, we can use &lt;code&gt;plot_models&lt;/code&gt;
function to plot several models at once. In the first code example we‚Äôll
use already familiar argument - &lt;code&gt;show.values&lt;/code&gt; - and a new one
- &lt;code&gt;grid&lt;/code&gt; - which plots models in separate fields to avoid
congestion and overload of information on the picture.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# fit two models
fit1 &amp;lt;- lm(age ~ education + jobclass + health_ins, data = Wage)
fit2 &amp;lt;- lm(wage ~ education + jobclass + health_ins, data = Wage)

# plot multiple models
plot_models(fit1, fit2, show.values = T, grid = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-20-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;In the second example we avoid clutter by simply not using
&lt;code&gt;show.values&lt;/code&gt;, since we can kind of read them from the
x-axes, and we‚Äôll use &lt;code&gt;p.shape = TRUE&lt;/code&gt; argument instead, in
order to display p-values as shapes instead of significance stars.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_models(fit1, fit2, p.shape = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c65c812a9_files/figure-html/unnamed-chunk-21-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="more-than-one-model"&gt;More than one model&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;tab_model&lt;/code&gt; can also easily display multiple models. Here,
&lt;code&gt;collapse.ci = TRUE&lt;/code&gt; argument conveniently puts confidence
intervals below the estimates, so that we can report several models near
each other.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_model(fit1, fit2, 
          collapse.ci = TRUE, 
          p.style     = &amp;quot;numeric_stars&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
age
&lt;/th&gt;
&lt;th colspan="2" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
wage
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
43.15 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(41.68¬†‚Äì¬†44.63)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
93.72 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(89.14¬†‚Äì¬†98.31)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
education [2. HS Grad]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-0.21 &lt;sup&gt;&lt;/sup&gt;&lt;br&gt;(-1.75¬†‚Äì¬†1.34)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.794
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
8.15 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(3.34¬†‚Äì¬†12.95)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
education [3. Some&lt;br&gt;College]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-2.01 &lt;sup&gt;*&lt;/sup&gt;&lt;br&gt;(-3.65¬†‚Äì¬†-0.37)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;0.016&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
17.89 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(12.79¬†‚Äì¬†22.99)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
education [4. College&lt;br&gt;Grad]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-0.48 &lt;sup&gt;&lt;/sup&gt;&lt;br&gt;(-2.13¬†‚Äì¬†1.17)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.568
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
33.03 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(27.91¬†‚Äì¬†38.15)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
education [5. Advanced&lt;br&gt;Degree]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
1.35 &lt;sup&gt;&lt;/sup&gt;&lt;br&gt;(-0.45¬†‚Äì¬†3.16)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.142
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
57.90 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(52.28¬†‚Äì¬†63.52)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
jobclass [2. Information]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
1.42 &lt;sup&gt;**&lt;/sup&gt;&lt;br&gt;(0.56¬†‚Äì¬†2.28)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
3.67 &lt;sup&gt;**&lt;/sup&gt;&lt;br&gt;(1.00¬†‚Äì¬†6.35)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;0.007&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
health ins [2. No]
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-3.29 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(-4.20¬†‚Äì¬†-2.39)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
-19.89 &lt;sup&gt;***&lt;/sup&gt;&lt;br&gt;(-22.72¬†‚Äì¬†-17.07)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2"&gt;
3000
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="2"&gt;
3000
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2"&gt;
0.033 / 0.031
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="2"&gt;
0.284 / 0.283
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan="5" style="font-style:italic; border-top:double black; text-align:right;"&gt;
&lt;ul&gt;
&lt;li&gt;p&amp;lt;0.05¬†¬†¬†** p&amp;lt;0.01¬†¬†¬†*** p&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/table&gt;
&lt;h1 id="whats-next"&gt;What‚Äôs next&lt;/h1&gt;
&lt;p&gt;By the way, if you want to visualize and test &lt;strong&gt;ALL the
assumptions of ANY model with a SINGLE function&lt;/strong&gt;, check out this
video about another amazing package created by the same author - &lt;a
href="https://github.com/strengejacke"&gt;Daniel L√ºdecke&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="further-readings-and-references"&gt;Further readings and
references&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://strengejacke.github.io/sjPlot/"
class="uri"&gt;https://strengejacke.github.io/sjPlot/&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a
href="https://cran.r-project.org/web/packages/sjPlot/index.html"
class="uri"&gt;https://cran.r-project.org/web/packages/sjPlot/index.html&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>084e31b0d01e136a5b84f497228763ce</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot</guid>
      <pubDate>Fri, 12 Aug 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot/thumbnail_sjPlot.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {report} How To Report Statistical Results!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-06-18-report</link>
      <description>If you ever wandered how to correctly describe the results of statistical tests and models, this blog is for you. In a few minutes you'll learn how to report the results of correlations, t-tests, Generalised Linear Models, Mixed-Effects models, Bayesian Models and even more üòâ So, let's start with a simple t-test.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-06-18-report</guid>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-06-18-report/thumbnail_report.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {glmulti} find the best model!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</link>
      <description>


&lt;h2 id="this-post-as-a-video"&gt;This post as a video&lt;/h2&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It‚Äôs less then 14 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/Im293ClFen4" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="why-do-we-need-glmulti"&gt;Why do we need {glmulti}?&lt;/h2&gt;
&lt;p&gt;The goal of ANY model is to explain a dependent variable by several
independent variables, sometimes called predictors. But which predictors
are useful(?) and how many should we include into our model(?), is
usually unknown. These questions are important, because if we take to
many predictors, we‚Äôll overfit the model and explain the noise in the
data instead of uncovering true relationships. While, if we include only
a few predictors into our model, we‚Äôll underfit the model and probably
miss some potentially important relationships. Thus, we need to find
&lt;strong&gt;THE BEST&lt;/strong&gt; model, with an &lt;strong&gt;optimal set of
predictors which explains maximum of our dependent variable, without
explaining the noise&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/fit.png" /&gt;&lt;/p&gt;
&lt;h2 id="stepwise-variable-selection-approach"&gt;Stepwise variable
selection approach&lt;/h2&gt;
&lt;p&gt;One of the most common solutions for finding &lt;strong&gt;THE
BEST&lt;/strong&gt; model is &lt;strong&gt;a stepwise variable selection.&lt;/strong&gt;
But it‚Äôs not the best solution out there, and here is why. Stepwise
selection applies two main techniques: forwards and backwards selection.
Forwards selection starts with an empty model, adds one predictor,
compares two models, one with and another without this predictor, takes
the best model of the two, adds another predictor etc‚Ä¶ Backwards
selection starts with the most complicated model, which includes all
predictors and interactions, and reduces the number of terms one by one.
But there are two problems with it. First, &lt;strong&gt;forwards and
backwards approaches would often not converge to the same
model&lt;/strong&gt;, like in our example. And secondly, even if they converge
to the same model, this model might not be the optimal one (gray circle
on the picture below). These problems occur simply because stepwise
selection doesn‚Äôt look at &lt;strong&gt;all possible models at the same
time&lt;/strong&gt;. They just remove or add terms one by one, compare two
models, take the best model of the two, remove or add another term
etc..&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/stepwise_problem.png" /&gt;&lt;/p&gt;
&lt;p&gt;Load all needed packages at once, to avoid interruptions.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(car)        # extracts model results
library(MASS)       # provides &amp;quot;birthwt&amp;quot; dataset
library(ISLR)       # provides &amp;quot;Wage&amp;quot; dataset
library(tictoc)     # checks running time
library(sjPlot)     # visualizes model results
library(glmulti)    # finds the BEST model
library(flextable)  # beautifies tables
library(tidyverse)  # provides a lot of useful stuff !!! 
library(performance)# checks and compares quality of models

theme_set(theme_light(base_size = 12)) # beautifies plots
theme_update(panel.grid.minor = element_blank())&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# prepare selection
full_model &amp;lt;- glm(mpg ~ (hp + drat + wt + qsec + gear)^2, 
                 data = mtcars, family = gaussian)

null_model &amp;lt;- glm(mpg ~ 1, data = mtcars, family = gaussian)

# run stepwise selection
optimal_model_backward &amp;lt;- step(full_model, direction = &amp;quot;backward&amp;quot;,
                        scope = list(upper = full_model, lower = null_model))

optimal_model_forward &amp;lt;- step(null_model, direction = &amp;quot;forward&amp;quot;,
                        scope = list(upper = full_model, lower = null_model))&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# compare two final models
anova(optimal_model_backward, optimal_model_forward, test = &amp;quot;Chisq&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Analysis of Deviance Table

Model 1: mpg ~ hp + drat + wt + qsec + gear + hp:drat + hp:wt + hp:qsec + 
    hp:gear + drat:wt + drat:qsec + wt:qsec + wt:gear
Model 2: mpg ~ wt + hp + qsec + gear + wt:hp
  Resid. Df Resid. Dev Df Deviance Pr(&amp;gt;Chi)   
1        18      51.32                        
2        26     112.06 -8  -60.743  0.00638 **
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;compare_performance(optimal_model_backward, optimal_model_forward)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Comparison of Model Performance Indices

Name                   | Model | AIC (weights) | BIC (weights) |    R2 |  RMSE | Sigma
--------------------------------------------------------------------------------------
optimal_model_backward |   glm | 135.9 (0.989) | 157.9 (0.203) | 0.954 | 1.266 | 1.689
optimal_model_forward  |   glm | 144.9 (0.011) | 155.2 (0.797) | 0.900 | 1.871 | 2.076&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="brute-force-approach-with-glmulti"&gt;‚ÄúBrute force‚Äù approach with
{glmulti}&lt;/h2&gt;
&lt;p&gt;In contrast, {glmulti} R package builds &lt;strong&gt;all possible models
with all possible combinations of predictors and, optionally, even their
pairwise interactions&lt;/strong&gt;. Such approach was called ‚Äúbrute
force‚Äù.&lt;/p&gt;
&lt;p&gt;{glmulti} then compares the amount of useful information models
provide. Such model comparison is done with the help of information
criteria (IC), for example Akaike‚Äôs IC (aic) or Bayesian IC (bic).
Information criteria are used instead of other metrics, such as &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;, because they show the ‚Äúfitness‚Äù of
the model, where this fitness is penalized by the number of predictors a
model incorporates. In contrast to information criteria, &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; will always increase with the
increasing number of terms and will eventually overfit the model. And as
mentioned before, an overfitted model is bad, because it describes the
noise rather than genuine relationships between variables. Consequently,
we can‚Äôt trust the coefficients and p-values of overfitted models.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-05-31-glmulti/bic_vs_r_squared.jpeg" style="width:50.0%" /&gt;&lt;/p&gt;
&lt;p&gt;This picture originates from &lt;a
href="https://www.igi-global.com/gateway/chapter/235052"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;But that‚Äôs not all, overfitting produces another problem. Each sample
has its own unique quirks. Consequently, overfitted model that fits the
random quirks of one sample is unlikely to fit the random quirks of
another sample. That makes overfitted model less generalizable outside
the original dataset, and therefore less useful.&lt;/p&gt;
&lt;p&gt;That‚Äôs why we need to create &lt;strong&gt;all possible models&lt;/strong&gt;,
instead of using stepwise selection, and we need to compare models using
&lt;strong&gt;Information Criteria&lt;/strong&gt;, instead of &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;. And while ‚ÄúBrute force‚Äù approach is
great, the number of models to be considered can easily become
exorbitant. However, there are several possibilities to reduce the
number of models and to decrease calculation time. Let‚Äôs get into the
Code and see how to do that.&lt;/p&gt;
&lt;h2 id="how-to-compute-glmulti-to-find-the-best-model"&gt;How to compute
glmulti to find the best model&lt;/h2&gt;
&lt;p&gt;The code is similar to any other model, you use in R:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first you have the &lt;strong&gt;formula&lt;/strong&gt; with the dependent
variable on the left side of the tilde (~), and all possible predictors
on the right side of the tilde. For this example we‚Äôll study the salary
of 3000 american workers with 5 predictors: jobclass, education, age,
health and health-insurance&lt;/li&gt;
&lt;li&gt;then we‚Äôll tell R which &lt;strong&gt;dataset&lt;/strong&gt; to use. In this
case we‚Äôll use the ‚ÄúWage‚Äù dataset from ISLR package&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;crit&lt;/strong&gt; specifies the &lt;strong&gt;Information
Criterion&lt;/strong&gt; to be used. Default is the Akaike IC (aic). Other
options are the Bayesian IC (bic), quasi-AIC for overdispersed or count
data (qaic and qaicc) and the small-sample corrected AIC (aicc), which I
personally prefer, because for big samples it always gets the same
result as Akaike‚Äôs IC, while with small samples it performs better&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;level&lt;/strong&gt; - argument is important! It specifies weather
all possible models supposed to be build without interactions (level =
1) or with interactions (level = 2)&lt;/li&gt;
&lt;li&gt;argument - &lt;strong&gt;method&lt;/strong&gt; - explores the candidate set of
models. Method = ‚Äúd‚Äù counts the number of candidate models without
calculating anything. For our example of 5 predictors we‚Äôll have 32
models without interactions and 1921 models with interactions. If method
= ‚Äúh‚Äù, an &lt;strong&gt;exhaustive screening&lt;/strong&gt; is undertaken, which
means that all possible models will be created. If method = ‚Äúg‚Äù, the
genetic algorithm is employed (recommended for large candidate
sets)&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage   ~ jobclass + education + age + health + health_ins,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 1,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM etc.)
        confsetsize = 100)   # Keep 100 best models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
4 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 32 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 32&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage   ~ jobclass + education + age + health + health_ins,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 2,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
        confsetsize = 100)   # Keep 100 best models&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
4 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 1921 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 1921&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;you then specify the distribution &lt;strong&gt;family&lt;/strong&gt; and
the&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;fitfunction&lt;/strong&gt;, where any function similar to
&lt;strong&gt;lm, glm or glmer&lt;/strong&gt; can be used&lt;/li&gt;
&lt;li&gt;lastly, &lt;strong&gt;confsetsize&lt;/strong&gt; argument allows you to keep a
particular number of the best models, so called - &lt;strong&gt;confident set
of best models&lt;/strong&gt;. One hundred - is a default value.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, now let‚Äôs run the exhaustive algorithm and see how much time it
takes to compute 1921 regressions and to find the BEST model for our 5
predictors with interactions. ‚Äútic()‚Äù and ‚Äútoc()‚Äù functions from
{tictoc} package would record running time for us.&lt;/p&gt;
&lt;p&gt;Fortunately, the exhaustive method took only 19 seconds. Not bad at
all, if you ask me. However, I usually have way more then five
predictors, which could cause performance problems. That‚Äôs why we need
to talk about the‚Ä¶&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tic()

h_model &amp;lt;- glmulti(wage ~ jobclass + education + age + health + health_ins,
          data   = Wage, 
          crit   = aicc,       # AICC corrected AIC for small samples
          level  = 2,          # 2 with interactions, 1 without  
          method = &amp;quot;h&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
          family = gaussian, 
          fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
          confsetsize = 100)   # Keep 100 best models

toc() # 19 sec elapsed: 1921 models &lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="performance-impovement-techniques"&gt;Performance impovement
techniques&lt;/h2&gt;
&lt;h3 id="remove-unnecessary-terms"&gt;1. Remove unnecessary terms&lt;/h3&gt;
&lt;p&gt;And the first one is to remove all unnecessary predictors or
interactions. For example a &lt;em&gt;weight&lt;/em&gt; and &lt;em&gt;body mass index
(BMI)&lt;/em&gt; provide very similar information - the statisticians would
say - they are highly multicollinear. Anyway, if both, &lt;em&gt;weight&lt;/em&gt;
and &lt;em&gt;BMI&lt;/em&gt; are included, they would dramatically increase the
number of models without providing any value. Check this out, adding
only two additional categorical predictors (maritl &amp;amp; region) into
the Wage model above increases the number of models to over 2.5 millions
(2604485 to be exact, see below). And while it‚Äôs unimaginable to run so
many models in our life time, &lt;strong&gt;genetic algorithm&lt;/strong&gt;
provides a solution for it.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmulti(wage ~ jobclass + education + age + health + health_ins + maritl + region,
        data   = Wage, 
        crit   = aicc,       # AICC corrected AIC for small samples
        level  = 2,          # 2 with interactions, 1 without  
        method = &amp;quot;d&amp;quot;,        # &amp;quot;d&amp;quot;, or &amp;quot;h&amp;quot;, or &amp;quot;g&amp;quot;
        family = gaussian, 
        fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.)
        confsetsize = 100,
        plotty=FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Initialization...
TASK: Diagnostic of candidate set.
Sample size: 3000
6 factor(s).
1 covariate(s).
0 f exclusion(s).
0 c exclusion(s).
0 f:f exclusion(s).
0 c:c exclusion(s).
0 f:c exclusion(s).
Size constraints: min =  0 max = -1
Complexity constraints: min =  0 max = -1
Your candidate set contains 2604485 models.&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 2604485&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="use-genetic-algorithm"&gt;2. Use genetic algorithm&lt;/h3&gt;
&lt;p&gt;Particularly, having 6 numeric predictors with interactions, the
‚Äúbrute force‚Äù approach needs almost 3 hours, while genetic algorithm
runs only 40-80 seconds and produces almost identical results (with
sometimes slightly worse IC value).&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tic()

test_h &amp;lt;- glmulti(mpg ~ hp + drat + wt + qsec + gear, 
                 data   = mtcars, 
                 method = &amp;quot;h&amp;quot;,       # Exhaustive approach
                 crit   = aic,      # AICC corrected AIC for small samples
                 level  = 2,         # 2 with interactions, 1 without
                 family = gaussian,
                 fitfunction = glm,  # Type of model (LM, GLM, GLMER etc.)
                 confsetsize = 100)  # Keep 100 best models

toc() # 32768 models &amp;quot;h&amp;quot; takes 104-109 seconds
# 6 numeric predictors with interactions produces 2.097.152 models, and &amp;quot;h&amp;quot; method takes 9715.466 seconds or ca. 2.7 hours

tic()

test_g &amp;lt;- glmulti(mpg ~ hp + drat + wt + qsec + gear, 
                 data   = mtcars, 
                 method = &amp;quot;g&amp;quot;,       # genetic algorithm approach
                 crit   = aic,      # AICC corrected AIC for small samples
                 level  = 2,         # 2 with interactions, 1 without
                 family = gaussian,
                 fitfunction = glm,  # Type of model (LM, GLM, GLMER etc.)
                 confsetsize = 100)  # Keep 100 best models

toc() # 32768 models &amp;quot;g&amp;quot; takes 40-59 seconds
# 6 numeric predictors with interactions produces 2.097.152 models, and &amp;quot;g&amp;quot; method takes 40-80 seconds or ca. 1 minute&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;So, if genetic algorithm is sooo cool, why not use genetic algorithm
all the time? Well, interestingly enough, with categorical predictors,
having a lot of categories, genetic algorithms may perform slower as
compared to the exhaustive one. For instance, our Wage-model, which has
lots of categorical predictors took only 19 second with the exhaustive
screening, while needed 117 seconds till genetic algorithm converged,
so, almost 6 times longer. Moreover, genetic algorithm might have
convergence problem and might run indefinitely long, without you having
any idea of WHEN, or IF it ever stops. And lastly, exhaustive method
almost always delivers better IC values. That‚Äôs why I‚Äôd recommend to
&lt;strong&gt;produce all possible models (aka. using exhaustive screening,
aka. applying ‚Äúbrute force‚Äù approach) whenever possible&lt;/strong&gt; and
only use genetic algorithm for a high number of numeric predictors.&lt;/p&gt;
&lt;h3 id="specify-marginality-and-exclude-arguments-optional"&gt;3. Specify
‚Äúmarginality‚Äù and ‚Äúexclude‚Äù arguments (optional) ‚Äì&amp;gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;marginality = TRUE&lt;/strong&gt;, argument considers only
marginal models. That would reduce the number of model from 2604485 to
2350602. I did not really understand what the martinality exactly does,
that is why I just prefer to leave it out.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Argument &lt;strong&gt;exclude&lt;/strong&gt; excludes (main effects or
interactions) from the candidate models, e.g.¬†c(‚Äúmass:height‚Äù) ‚Ä¶ it
somehow did not work in my code and I could not find out why. I hope it
will work on your machine!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;using multiple cores while computing might help.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="what-the-hell-is-the-best-model-then"&gt;What the hell is THE BEST
model then ???&lt;/h2&gt;
&lt;p&gt;By the way, remember, in the beginning of the video I said, that
stepwise selection is not the best method, implying that {glmulti}
approach is better? Well, let‚Äôs compare the results of exhaustive and
genetic algorithms, to the results of forward and backwards selections
and see which is a &lt;strong&gt;TRULY BEST&lt;/strong&gt; model:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_exhaustive &amp;lt;- test_h@objects[[1]]
optimal_model_glmulti_genetic    &amp;lt;- test_g@objects[[1]]
compare_performance(optimal_model_glmulti_exhaustive, optimal_model_glmulti_genetic, optimal_model_backward, optimal_model_forward)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Comparison of Model Performance Indices

Name                             | Model | AIC (weights) | BIC (weights) |    R2 |  RMSE | Sigma
------------------------------------------------------------------------------------------------
optimal_model_glmulti_exhaustive |   glm | 134.7 (0.474) | 146.5 (0.981) | 0.932 | 1.547 | 1.750
optimal_model_glmulti_genetic    |   glm | 135.9 (0.261) | 157.9 (0.003) | 0.954 | 1.266 | 1.689
optimal_model_backward           |   glm | 135.9 (0.261) | 157.9 (0.003) | 0.954 | 1.266 | 1.689
optimal_model_forward            |   glm | 144.9 (0.003) | 155.2 (0.013) | 0.900 | 1.871 | 2.076&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_exhaustive$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ 1 + wt + qsec + gear + drat:hp + qsec:wt + gear:wt
&amp;lt;environment: 0x7fee8bb37cf0&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_glmulti_genetic$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ 1 + hp + drat + wt + qsec + gear + drat:hp + wt:hp + wt:drat + 
    qsec:hp + qsec:drat + qsec:wt + gear:hp + gear:wt
&amp;lt;environment: 0x7fee2ce0c600&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_backward$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ hp + drat + wt + qsec + gear + hp:drat + hp:wt + hp:qsec + 
    hp:gear + drat:wt + drat:qsec + wt:qsec + wt:gear
&amp;lt;environment: 0x7fee5a7a7d28&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;optimal_model_forward$formula&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mpg ~ wt + hp + qsec + gear + wt:hp
&amp;lt;environment: 0x7fee5a7a7d28&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As you can see {glmulti} approach produced lower AIC and much lower
BIC Information criteria, and interestingly enough, the &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; produced by {glmulti} is right in
between the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;s of forwards and
backwards selections, suggesting that {glmulti} models are neither
underfitted not overfitted. Moreover, in our example both exhaustive and
genetic algorithms have identical result (will not always be the case)
and showed three interactions (drat:hp + qsec:wt + gear:wt) to be
important, while backwards selection found 8 interactions to be
important, which to me sound like overfitting, which is in line with
it‚Äôs highest &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;, and forwards
selection found only one interaction, which looks like underfitting,
which is in line with it‚Äôs lowest &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So, I hope I could convince you that &lt;strong&gt;{glmulti} approach is
superior to the stepwise selection&lt;/strong&gt; approach and produces a
&lt;strong&gt;truly BEST model&lt;/strong&gt;.&lt;/p&gt;
&lt;!-- ```{r eval=FALSE} --&gt;
&lt;!-- tic() --&gt;
&lt;!-- g_model &lt;- glmulti(wage ~ jobclass + education + age + health + health_ins, --&gt;
&lt;!--           data   = Wage,  --&gt;
&lt;!--           crit   = aicc,       # AICC corrected AIC for small samples --&gt;
&lt;!--           level  = 2,          # 2 with interactions, 1 without   --&gt;
&lt;!--           method = "g",        # "d", or "h", or "g" --&gt;
&lt;!--           family = gaussian,  --&gt;
&lt;!--           fitfunction = glm,   # Type of model (LM, GLM, GLMER etc.) --&gt;
&lt;!--           confsetsize = 100)   # Keep 100 best models --&gt;
&lt;!-- toc() # 117 sec elapsed: After 440 generations:  --&gt;
&lt;!-- ``` --&gt;
&lt;h2 id="some-exotic-applications-glmer-or-multinom"&gt;Some exotic
applications: GLMER or multinom&lt;/h2&gt;
&lt;p&gt;And while {glmulti} works fine with the classic functions like LM and
GLM, it can also fit some exotic models, such as ‚Äúmultinomial‚Äù models
via Neural Networks from {nnet} package.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(nnet)

multinom_glmulti &amp;lt;- glmulti(
  education ~ wage + jobclass + health, 
  data   = Wage, 
  level  = 2, 
  method = &amp;quot;h&amp;quot;
  fitfunction = multinom)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here are the predictions of the best multinomial model:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(effects::allEffects(multinom_glmulti@objects[[1]]),
     lines = list(multiline = T),
     confint = list(style = &amp;quot;auto&amp;quot;))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c5fcce390_files/figure-html/unnamed-chunk-14-1.png" width="1344" /&gt;&lt;/p&gt;
&lt;p&gt;And lastly, despite the fact there is no straightforward fitting
function for the mixed-effects models, such as GLMER from {lme4}
package, we can easily write our own wrapper-function and use it inside
of {glmulti}:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;glmer.glmulti&amp;lt;-function(formula, data, random = &amp;quot;&amp;quot;, ...){
   glmer(paste(deparse(formula),random),
         data    = data, REML = F, ...)
}

mixed_model &amp;lt;- glmulti(
  y = response ~ predictor_1 + predictor_2 + predictor_3,
  random  = &amp;quot;+(1|random_effect)&amp;quot;,
  crit    = aicc,
  data    = data,
  family  = binomial,
  method  = &amp;quot;h&amp;quot;,
  fitfunc = glmer.glmulti,
  marginality = F,
  level   = 2 )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, let‚Äôs have a look at the results of our BEST model and interpret
them.&lt;/p&gt;
&lt;h2 id="extract-results"&gt;Extract results&lt;/h2&gt;
&lt;p&gt;The output of a {glmulti} analysis is an object containing the
&lt;strong&gt;confidence set of models (100 best models by default)&lt;/strong&gt;.
Standard R regression functions like ‚Äúsummary()‚Äù, ‚Äúcoef()‚Äù or ‚Äúplot()‚Äù
can all be used to make a multi-model inference. But let‚Äôs start with
the brief summary of the results which can be obtained with via
‚Äúprint()‚Äù command:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;print(h_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;glmulti.analysis
Method: h / Fitting: glm / IC used: aicc
Level: 2 / Marginality: FALSE
From 100 models:
Best IC: 29793.4306133546
Best model:
[1] &amp;quot;wage ~ 1 + jobclass + education + health + health_ins + age + &amp;quot;  
[2] &amp;quot;    education:jobclass + health_ins:education + education:age + &amp;quot;
[3] &amp;quot;    health:age + health_ins:age&amp;quot;                                 
Evidence weight: 0.0786680339413555
Worst IC: 29801.3206286612
6 models within 2 IC units.
74 models to reach 95% of evidence weight.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;‚Ä¶ were we see the most important information, such as fitting
function, the information criteria used to rank the models, the formula
of the best model and even the number of models which as good as the
best model. There are 6 models, which we can also see if we plot our
object:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(h_model)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c5fcce390_files/figure-html/unnamed-chunk-18-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;This plot shows the IC values for all 100 models from the confidence
set. A horizontal line separates 6 best models, that are less than 2 IC
units away from &lt;strong&gt;THE BEST&lt;/strong&gt; model. But what predictors and
interactions do those 6 models contain? Using {weightable} function, we
can easily display them:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;weightable(h_model)[1:6,] %&amp;gt;% 
  regulartable() %&amp;gt;%       # beautifying tables
  autofit()&lt;/code&gt;&lt;/pre&gt;
&lt;template id="38314c0a-60c0-445f-843e-3e021a4ef837"&gt;&lt;style&gt;
.tabwid table{
  border-spacing:0px !important;
  border-collapse:collapse;
  line-height:1;
  margin-left:auto;
  margin-right:auto;
  border-width: 0;
  display: table;
  border-color: transparent;
  caption-side: top;
}
.tabwid-caption-bottom table{
  caption-side: bottom;
}
.tabwid_left table{
  margin-left:0;
}
.tabwid_right table{
  margin-right:0;
}
.tabwid td {
    padding: 0;
}
.tabwid a {
  text-decoration: none;
}
.tabwid thead {
    background-color: transparent;
}
.tabwid tfoot {
    background-color: transparent;
}
.tabwid table tr {
background-color: transparent;
}
.katex-display {
    margin: 0 0 !important;
}
&lt;/style&gt;&lt;div class="tabwid"&gt;&lt;style&gt;.cl-945c3b50{}.cl-9454cd3e{font-family:'Helvetica';font-size:11pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-9457e064{margin:0;text-align:left;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9457e06e{margin:0;text-align:right;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 1;background-color:transparent;}.cl-9457f6ee{width:12.024in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f6f8{width:0.965in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f702{width:1.092in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 2pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f703{width:12.024in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f70c{width:0.965in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f70d{width:1.092in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f70e{width:12.024in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f716{width:0.965in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-9457f717{width:1.092in;background-color:transparent;vertical-align: middle;border-bottom: 2pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}&lt;/style&gt;&lt;table class='cl-945c3b50'&gt;&lt;thead&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f6ee"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;model&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f6f8"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;aicc&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f702"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;weights&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f703"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70c"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,793.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70d"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.07866803&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f703"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + education:age + health:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70c"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,793.68&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70d"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.06952606&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f703"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health_ins + age + education:jobclass + health_ins:education + education:age + health:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70c"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,794.40&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70d"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.04836431&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f703"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health_ins + age + education:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70c"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,794.43&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70d"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.04776916&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f703"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:education + jobclass:age + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70c"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,795.31&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f70d"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.03070167&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr style="overflow-wrap:break-word;"&gt;&lt;td class="cl-9457f70e"&gt;&lt;p class="cl-9457e064"&gt;&lt;span class="cl-9454cd3e"&gt;wage ~ 1 + jobclass + education + health + health_ins + age + education:jobclass + health_ins:jobclass + health_ins:education + education:age + health:age + health_ins:age&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f716"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;29,795.36&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;td class="cl-9457f717"&gt;&lt;p class="cl-9457e06e"&gt;&lt;span class="cl-9454cd3e"&gt;0.02990738&lt;/span&gt;&lt;/p&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/div&gt;&lt;/template&gt;
&lt;div class="flextable-shadow-host" id="f045a0a3-427f-4850-98b4-cde148dc0433"&gt;&lt;/div&gt;
&lt;script&gt;
var dest = document.getElementById("f045a0a3-427f-4850-98b4-cde148dc0433");
var template = document.getElementById("38314c0a-60c0-445f-843e-3e021a4ef837");
var caption = template.content.querySelector("caption");
var fantome = dest.attachShadow({mode: 'open'});
var templateContent = template.content;
fantome.appendChild(templateContent);
&lt;/script&gt;

&lt;p&gt;Here we see the formulas, Information Criteria and the Akaike weights
of our 6 best models. The Akaike weight for a particular model shows the
probability that the model is the best model out of all models
considered. To say it in a simple lingo - the model with the highest
weight minimizes the loss of information. So, while the ‚Äúbest‚Äù model has
the highest weight, its weight in this example is not substantially
larger than that of the second model (and also the third, fourth, and so
on). So, we shouldn‚Äôt be all too certain here that the top model is
really &lt;strong&gt;the best model&lt;/strong&gt; in the set. Several models are
almost equally plausible. So, &lt;strong&gt;which model should we take
then?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;If all 6 models are great, but have different combinations of
predictors and interactions, figuring out which terms are important may
help to choose the best model. Fortunately for us, the
&lt;code&gt;plot()&lt;/code&gt; command with &lt;code&gt;type="s"&lt;/code&gt; argument displays
the relative importance of model terms across all models. The importance
value for a particular predictor or interaction is equal to the sum of
the weights for the models in which the variable appears. So, &lt;strong&gt;a
variable that shows up in lots of models with large weights will receive
a high importance value&lt;/strong&gt;. A vertical line is drawn at 80% (where
terms to the right of the line are part of 80% of the models), which is
sometimes used as a cutoff to differentiate between very important and
less important variables. This threshold is somewhat arbitrary though,
so that we are free to set it at ‚Ä¶ let‚Äôs say 50% and include all the
predictors and interactions with the importance above 50% into the final
model.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot(h_model, type = &amp;quot;s&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c5fcce390_files/figure-html/unnamed-chunk-20-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Interestingly, the very first model contains the
&lt;em&gt;age:health_ins&lt;/em&gt; interaction, which has ca. 50% importance. And
it would be totally fine to go with that. But, since we have so many
terms with the importance around 80%, I am happy to use only those,
including &lt;em&gt;education:health_insurance&lt;/em&gt; interaction and predictor
&lt;em&gt;health&lt;/em&gt;, because they are far enough from the rest. And if I
look at 6 best models, I‚Äôll see that the second model has exactly those
terms. The third model is a bit worse because it does not contain
variable health, but since health is part of the most important
interaction - &lt;em&gt;age:health&lt;/em&gt;, I‚Äôd prefer to include it. So, now we
did not blindly trust the algorithm and took it‚Äôs &lt;strong&gt;BEST
MODEL&lt;/strong&gt;, but examined the results carefully and made a grounded
decision to take the second model as &lt;strong&gt;OUR BEST
MODEL&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Now, we can easily interpret and visualize and check assumptions of
&lt;strong&gt;OUR BEST&lt;/strong&gt; model as we always do:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;best_model &amp;lt;- h_model@objects[[2]]

car::Anova(best_model)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Analysis of Deviance Table (Type II tests)

Response: wage
                     LR Chisq Df Pr(&amp;gt;Chisq)    
jobclass                 4.91  1   0.026764 *  
education              626.21  4  &amp;lt; 2.2e-16 ***
health                  28.16  1  1.117e-07 ***
health_ins             158.79  1  &amp;lt; 2.2e-16 ***
age                     90.94  1  &amp;lt; 2.2e-16 ***
jobclass:education      16.14  4   0.002838 ** 
education:health_ins    10.22  4   0.036890 *  
education:age           12.11  4   0.016572 *  
health:age              10.13  1   0.001459 ** 
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(best_model, type = &amp;quot;int&amp;quot;) %&amp;gt;% 
  plot_grid()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="filef29c5fcce390_files/figure-html/unnamed-chunk-21-1.png" width="1440" /&gt;&lt;/p&gt;
&lt;p&gt;And if you want to learn &lt;strong&gt;how to test ALL model-assumptions
using only one function&lt;/strong&gt;, check out {performance} package:&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/BNTn_f43U04" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="problems"&gt;Problems&lt;/h2&gt;
&lt;p&gt;So, while {glmulti} is an amazing package, but it is not perfect and
here are three things I found challenging:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;rJava package needed. If you can‚Äôt easily install rJava package
from RStudio, chances are your computed does not have Java installed.
Doing this can take some time and nerves.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;some arguments are poorly described (e.g.¬†‚Äúmarginality‚Äù), or
simply do not work (e.g.¬†‚Äúexclude‚Äù). Please, let me know in the comments
below, if you managed to use ‚Äúexclude‚Äù.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;and while the &lt;code&gt;coef()&lt;/code&gt; and &lt;code&gt;predict()&lt;/code&gt;
commands are useful multi-model inference tools for models without
interactions and only with numeric predictors and could provide
multi-model averaged estimates, confidence intervals and predictions, I
find them less intuitive for the models with several interactions and
with many categorical predictors.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="further-readings-and-references"&gt;Further readings and
references&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.jstatsoft.org/article/view/v034i12"
class="uri"&gt;https://www.jstatsoft.org/article/view/v034i12&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a
href="https://cran.r-project.org/web/packages/glmulti/glmulti.pdf"
class="uri"&gt;https://cran.r-project.org/web/packages/glmulti/glmulti.pdf&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;a href="https://www.igi-global.com/gateway/chapter/235052"
class="uri"&gt;https://www.igi-global.com/gateway/chapter/235052&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>e293af68b10d93947ec753cf0794c593</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>machine learning</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</guid>
      <pubDate>Sat, 18 Jun 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti/thumbnail_glmulti.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Tidy Data and Why We Need It!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</link>
      <description>Tidy data are easy to manipulate, visualise and analyse, while messy data always interrupts the analysis and invates mistakes. So, tidying up data before analysis pays off a great deal in the long term. In this post you'll learn how do we tidy up data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</guid>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata/tidydata_2.jpeg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | ANOVA (One-Way ) | Fisher's, Welch's, Bayesian, Robust</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</link>
      <description>How does education influence our salary? ANOVA which is just the abbreviation for Analysis Of Variances you see on the thumbnail answeres this question with Frequentists and Bayesian tests. It also privides two different effect sizes, compares education levels pairwisely and even corrects p-values for multiple comparisons. ALL OF THAT is done by this simple command. So, in this blog-post you'll learn how to produce the statistically rich plot, you'll understand when to conduct Welch's ANOVA and when Fisher's ANOVA and you'll know how to interpret every little detail on this plot. Lets get into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-03-anova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Kruskal-Wallis test | How to conduct, visualize, interpret &amp; more üòâ</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</link>
      <description>If we have ordinal or not-normally distributed data, ANOVA might produce a wrong result. That's why we need Kruskal-Wallis test. Kruskal-Wallis test you see on the screen answers two question (1) whether at least one group is different from other groups and (2) between which groups exactly this difference is. So, let's learn how to get and interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-13-kw/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Repeated Measures ANOVA (One-Way) | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</link>
      <description>Can sport increase our selfesteem? Well, one experiment measured self-esteem of 10 people on three different time points and used Repeated Measures ANOVA to answer this question. So, let's learn how to produce this statistically rich plot using only one simple command and how to interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</guid>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Cochran‚Äôs Q Test + Pairwise McNemar Tests (post-hoc)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</link>
      <description>Cochran test is an extension of the McNemar test for comparing MORE than two PAIRED categorical samples in which the same individuals appear in each sample. If Cochran test is significant, we'd need to compare samples among each other pairwisely with McNemar tests. So, let's do that.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</guid>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-04-cochran/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Mann-Whitney U Test = Wilcoxon Rank Sum Test | How to conduct, visualise &amp; interpret ü•≥ What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</link>
      <description>Comparing two groups with not-normally disctributed or ordinal data is the reason we need Mann-Whitney U Test instead of t-Test. So, today we'll learn (1) how to conduct and visualize Mann-Whitney U Test you saw on the thumbnail with one simple command, (2) how to interpret all statistical results on that plot and (3) why this test is sometimes called Wilcoxon Rank Sum Test and why we shouldn't use this name</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</guid>
      <pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Correlation Matrix | Danger or opportunity?</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</link>
      <description>Having several numeric variables, we often wanna know which of them are correlated and how. Correlation Matrix seems to be a good solution for it. But drawing conclusions from plain correlation coeffitients and p-values is dangerous, if we don't visualize the data. Let's learn a better way to produce a correlation matrix.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</guid>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Two-Samples t-Test | Student's &amp; Welch's | How to conduct, visualise, interpret | What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</link>
      <description>Two-samples t-test can answer useful questions, for example - where can we get more money, working in a factory or in the IT-industry? So, let's learn (1) how to make sure t-test is a CORRECT test for our data, (2) how to get all these results with one simple command, (3) how to interpret all these results and (4) finally see what happens if we choose a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</guid>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples t-Test | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</link>
      <description>Can one week of training significantly improve your number of sit-ups? Well, Paired t-Test can answer this question by comparing your performance Before and After this week. So, let's learn how to produce this statistically rich plot using only one simple command, how to interpret all these results and see what happens if we use a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</guid>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | McNemar Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</link>
      <description>If you need to compare two PAIRED categorical samples, McNemar test is a correct choise for you. Though, people often use Chi-Square test instead. Thus, in this blog-post we'll first conduct, visualize and interpret McNemac test you see on the picture to your right using only one simple command and then see what happens if we use Chi-Square test for paired data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</guid>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Friedman Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</link>
      <description>The Friedman Test is a non-parametric brother of Repeated Measures ANOVA, which does much better job when data is not-normally distributed (which happens pretty often ;). Friedman test is also superior to Repeated Measures ANOVA when our data is ordinal (e.g., scales from 1 to 10). Friedman Test can also be a non-parametric father of the Paired Wilcoxon test, because it can compare more then two groups.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</guid>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-08-friedman/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples Wilcoxon Signed Rank Test</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</link>
      <description>Can a speed-reading exercise make you a faster reader? Well, Wilcoxon Signed Rank Test displayed here is a correct test to answer this question. So, in this video we'll learn how to choose a correct test and what happens if we use a wrong test, why Wilcoxon test is called Signed Rank and how to produce and interpret this statistically rich plot using only one simple command.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</guid>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Correlation Analysis in R | Pearson, Spearman, Robust, Bayesian | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</link>
      <description>Having two numeric variables, we often wanna know whether they are correlated and how. One simple command {ggscatterstats} can answer both questions by visualizing the data and conducting frequentists and bayesian correlation analysis at the same time. So, let's learn how to do that, how to interpret all those results and how to choose the right correlation method in the first place.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</guid>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>One-sample Student‚Äôs t-test and One-sample Wilcoxon test: or how to compare your work to the work of others.</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</link>
      <description>Imagine you get 7 out of 10 to-dos from your list done on average. Are you then more productive then others? One-sample t-test and One-sample Wilcoxon test can answer this question. So, in this blog-post you'll learn how to conduct and visualize these tests with only one simple command, how to interpret all these results and how to choose the right test in the first place. Let's get straight into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</guid>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Chi-Square Test | how to conduct, visualize &amp; interpret | + pairwise post-hoc tests</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</link>
      <description>Chi-Square Test checks the independence between two categorical variables, where variables can have two or more categories. Need to do Chi-Square test? It can actually be done with only one line of code. There is no better way than {ggbarstats} function from {ggstatsplot} package üì¶. In this short blog-post you'll learn how to conduct, visualize and interpret Chi-Square test &amp; pairwise post-hoc tests in R.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</guid>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {dlookr} diagnose, explore and transform your data</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</link>
      <description>Raw data need to be diagnosed for existing problems, explored for new hypotheses and repaired in order to increase data quality and output. The {dlookr} package makes these steps fast and easy. {dlookr} generates automated reports and performs compex operations, like imputing missing values or outliers, with simple functions. Moreover, {dlookr} collaborates perfectly with {tidyverse} packages, like {dplyr} and {ggplot2} to name just a few!</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</guid>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data/dlookr_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Deep Exploratory Data Analysis (EDA) in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</link>
      <description>Exploratory Data Analysis is an important first step on the long way to the final result, be it a statistical inference in a scientific paper or a machine learning algorithm in production. This long way is often bumpy, highly iterative and time consuming. However, EDA might be the most important part of data analysis, because it helps to generate hypothesis, which then determine THE final RESULT. Thus, in this post I'll provide the simplest and most effective ways to explore data in R, which will significantly speed up your work. Moreover, we'll go one step beyond EDA by starting to test our hypotheses with simple statistical tests.</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress/DEDA_thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>How to impute missing values with Machine Learning in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</link>
      <description>Imputation simply means - replacing a missing value with a value that makes sense. But how can we get such values? Well, we'll use Machine Learning algorithms, because they have a high prediction power. So, in this post we'll learn how to impute missing values easily and effectively.</description>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r/thumbnail_missing_values.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Null Hypothesis, Alternative Hypothesis and Hypothesis Testing</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</link>
      <description>Hypothesis testing is one of the most important concepts in (frequentiest) statistics and science. However, most people who test hypotheses are scientists, but not statisticians. That's why scientists often do not test hypotheses properly, without any bad intension—Å. So, in this blog-post we'll break down hypothesis testing in small parts and try to properly understand every of them.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>What is p-value and why we need it</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</link>
      <description>Why do we need p-values? Well, they help to **make decisions** and **answer the question whether we found something new or not**. But despite the fact that **p-values are** actually **useful**, they are **far from perfect**! And while everyone uses p-values, understanding them (and using them correctly) is very hard. The definition of the p-value from the book is often correct but rarely intuitive. Intuitive explanations are often not entirely correct. So, in this blog-post (and video) we‚Äôll start with an intuitive (and not entirely correct) definition and will gradually build up the understanding of the p-value step by step. Thus, I don‚Äôt recommend to skip any part of this blog (or video). We‚Äôll also talk about how to use and interpret p-values correctly in order to **make better decisions and better science**.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {DataExplorer} explore your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</link>
      <description>What is the best way to explore the data quick? I think it's visualization. And what it the best way to visualize the data quick? I think it's - {DataExplorer} package, because it can visualize all your data in seconds using only one function! Check this out...</description>
      <category>R package reviews</category>
      <category>EDA</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data/2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 2: parametric survival models</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</link>
      <description>The non-parametric Kaplan-Meier method (KM) can not describe survival probability by a smooth function, which means it can not predict anything. The parametric models (e.g. Exponential, Weibull etc.) can! Besides, in case where parametric models are appropriate, they are more exact, more effective and more informative than KM or Cox. However, unfortunately, this step is often left out due to the rear use of parametric models. In this post we‚Äôll try to close this gap.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models/thumbnail_survival_2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {performance} check how good your model is! </title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</link>
      <description>There are several indicators of model quality, e.g. $R^2$ or AIC, and several assumption for every model which supposed to be checked, e.g. normality of residuals, multicollinearity etc.. R provides solutions for every indicator or assumption you can imagine. However, they are usually spread around different packages and functions. {performance} package brings all of quality indicators and all of the assumption under one roof. Thus, for me it became the one-stop solution for modelling.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is/14.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 1: a gentle introduction into Kaplan-Meier Curves</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</link>
      <description>Survival time analysis is necessary in any study which investigates the time to a particular outcome of interest. Cancer studies in the medicine and the first failure of the car in the engineering field (failure time analysis) are good examples. The outcome of interest could be death, remission to relapse, progression, or failure. Point in time of reaching that outcome is generally called the event. Thank goodness, not every ‚Äúevent‚Äù is fatal üòÉ, but can sometimes even be a favorable outcome such as discharge from hospital. And thus, survival analysis is also a generic term, because it is not only about survival.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves/thumbnail_survival_1.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {janitor} clean your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</link>
      <description>Data Scientists spend up to 80% of their time cleaning and preparing data for analysis. " Happy families are all alike; every unhappy family is unhappy in its own way" ‚Äî Leo Tolstoy. "Like families, tidy datasets are all alike but every messy dataset is messy in its own way" - Hadley Wickham. Thats when "janitor" helps to clean the mess.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</guid>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data/11.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to visualize models, their assumptions and post-hocs</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</link>
      <description>A picture is worth a thousand words! This article shows how to visualize results of 16 different models in R: from a simple linear model to a multiple-additive-non-linear-mixed-effects model. Among them are logistic, multinomial, additive and survival models with and without interactions. **Goal: minimum R code &amp; maximum output!** We'll also go a bit beyond only model visualization. So, don't miss the bonuses üòâ.</description>
      <category>visualization</category>
      <category>videos</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</guid>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs/thumbnail_visualize_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to create a blog or a website in R with {Distill} package</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</link>
      <description>If you're not online, you don't exist. A personal webpage or a blog became the business card of the digital century. It shows who you are and what you are capable of. Thus: show, don't tell.</description>
      <category>R &amp; the Web</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</guid>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package/images/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
  </channel>
</rss>
