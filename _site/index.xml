<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>yuzaR-Blog</title>
    <link>https://yuzar-blog.netlify.app/</link>
    <atom:link href="https://yuzar-blog.netlify.app/index.xml" rel="self" type="application/rss+xml"/>
    <description>Data Science with R
</description>
    <generator>Distill</generator>
    <lastBuildDate>Tue, 05 Mar 2024 00:00:00 +0000</lastBuildDate>
    <item>
      <title>Simple Linear Regression with Categorical Predictor in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2024-02-28-lmcategorical</link>
      <description>


&lt;h1 id="this-post-as-ca.-minutes-video"&gt;This post as ca. ‚Ä¶ minutes
video&lt;/h1&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="clean-the-data-otherwise-shit-in-shit-out"&gt;Clean the data,
otherwise: shit in shit out!&lt;/h1&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;First of all, it‚Äôs crucial to visualize the data before modeling,
because the real-world data often contains contaminations üí©. For
instance, in Wage dataset from the ISLR package, I would remove the
high-income individuals earning over 250K per year, because they are
outliers, and totally not because I am jealous! üòâ. The data-cleaning
step is vital and often overlooked. Remember the phrase: ‚ÄòGarbage in,
garbage out‚Äô? If we skip data cleaning, our model‚Äôs performance could be
seriously compromised, and we‚Äôll see it in a moment. For now let‚Äôs take
100 random people form the industry and build our linear model around
them.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse)      # laod &amp;amp; thank me later ;)
library(ISLR)           # provides Wage dataset
theme_set(theme_test()) # beautifies plots

set.seed(1)             # for reproducibility
d &amp;lt;- Wage %&amp;gt;% 
  filter(wage &amp;lt; 250) %&amp;gt;% 
  group_by(education) %&amp;gt;% 
  sample_n(100)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="build-linear-equation"&gt;Build linear equation&lt;/h1&gt;
&lt;p&gt;To build our linear model, we‚Äôll use the intuitive ‚Äòlm‚Äô (show pack of
cigarettes ; —Å —Ä–µ–∫–ª–∞–º–æ–π –∏–º–ø–æ—Ç–µ–Ω—Ü–∏–∏ :) function. Within ‚Äòlm‚Äô, we only
need two arguments: the formula and the data. Here‚Äôs how it breaks
down:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On the left side of the formula, we‚Äôll place the variable we‚Äôre
interested in predicting. Unfortunately, this variable goes by several
names: response variable, outcome, dependent variable, target, and more.
It can get confusing!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On the right side, we‚Äôll place the predictor variable. Predictors
also have various synonyms: independent variable, explanatory variable,
regressor or covariate (in linear regression), feature (in Machine
Learning), and even risk factor (in epidemiology).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ugh, so many names for the same thing! Drives me nuts. Makes stats
seem way harder than it actually is.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# build the model
m &amp;lt;- lm(formula = wage ~ education, data = d)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="check-all-model-assumptions-visually"&gt;Check all model
assumptions visually&lt;/h1&gt;
&lt;p&gt;After building the model, we need to make sure the assumptions are
satisfied. Otherwise, we couldn‚Äôt trust our model! The {performance}
package offers intuitive and powerful functions to do that, for
instance&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‚Äúcheck_posterior_predictions()‚Äù model fits the data well&lt;/li&gt;
&lt;li&gt;‚Äúcheck_normality()‚Äù looks whether the residuals are normally
distributed and&lt;/li&gt;
&lt;li&gt;‚Äúcheck_homogeneity()‚Äù compares variances between groups.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# check model assumptions visually
library(performance)   # extra video on my channel
a &amp;lt;- check_posterior_predictions(m) %&amp;gt;% plot()
b &amp;lt;- check_normality(m) %&amp;gt;% plot()
c &amp;lt;- check_homogeneity(m) %&amp;gt;% plot()

library(patchwork)     # extra video on my channel
a + b + c&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-5-1.png" width="1344" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the assumptions, I could say that the model fits the data
pretty well! The residuals are normally distributed since they are
inside the confidence intervals, which means our data is normally
distributed. And finally, the variance is relatively similar.&lt;/p&gt;
&lt;p&gt;By the way: with categorical predictor we don‚Äôt need to check the
linearity and outliers assumptions, and we can relax the independence of
observations assumptions, since we don‚Äôt have repeated measures.&lt;/p&gt;
&lt;p&gt;Now, when we model uncleaned data, the model fit would be far from
reality, because those rich folks I am totally not jealous about ;)
would&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;compromised the model fit&lt;/li&gt;
&lt;li&gt;skew the normality of residuals and&lt;/li&gt;
&lt;li&gt;add huge heterogenety between groups, in other words would make the
groups variance differ,&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚Ä¶ so that I would stop trusting my model. Therefore, it‚Äôs really
important to clean the data before modeling.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m2 &amp;lt;- lm(formula = wage ~ education, data = Wage)

a &amp;lt;- check_posterior_predictions(m2) %&amp;gt;% plot()
b &amp;lt;- check_normality(m2) %&amp;gt;% plot()
c &amp;lt;- check_homogeneity(m2) %&amp;gt;% plot()

a + b + c&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-6-1.png" width="1344" /&gt;&lt;/p&gt;
&lt;p&gt;Oh, and by the way, if you have a lot of data, it‚Äôs important to
check assumptions visually, like we just did, instead of conducting
statistical tests. Because, the tests would often show significant
results, meaning that assumptions seemingly would not be satisfied,
while they are actually satisfied. Here is an example of the
Shapiro-Wilk normality test, which magically finds non-normally
distributed residuals, even though they are totally fine!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# don&amp;#39;t trust statistical tests to much
check_normality(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Non-normality of residuals detected (p = 0.041).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, since the assumptions of our model are satisfied, we can
visualize model results, and by results, I mean visualize model
predictions.&lt;/p&gt;
&lt;h1 id="visualize-predictions"&gt;Visualize predictions&lt;/h1&gt;
&lt;p&gt;For that, we‚Äôll use another very intuitive function called
‚Äúplot_model()‚Äù from the {sjPlot} package and provide three
arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the model name,&lt;/li&gt;
&lt;li&gt;the type of predictions ‚Äî we‚Äôll use ‚Äúeffect‚Äù to get an effect plot,
and&lt;/li&gt;
&lt;li&gt;the name of a predictor we want to visualize.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# visualize predictions
library(sjPlot)    # extra video on my channel

plot_model(m, type = &amp;quot;eff&amp;quot;, terms = &amp;quot;education&amp;quot;) # show.data = T&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-8-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;And voil√†, our plot shows that salaries increase with increasing
levels of education. Nice right? But this plot misses two important
details: it doesn‚Äôt display the differences in salaries between groups,
and it doesn‚Äôt demonstrate whether these differences are
significant.&lt;/p&gt;
&lt;h1 id="visualize-estimates"&gt;Visualize estimates&lt;/h1&gt;
&lt;p&gt;But we can quickly solve both problems, when we use&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;‚Äúshow.values = TRUE‚Äù instead of ‚Äútype =‚Äùeff‚Äù in the ‚Äúplot_model()‚Äù
function and&lt;/li&gt;
&lt;li&gt;width argument instead of predictor name.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# visualize estimates
plot_model(m, show.values = TRUE, width = 0.2)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-9-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Namely, it tells us that we have a 1080$ increase in salary per year,
and this increase is highly significant because the estimate doesn‚Äôt
cross zero. And while the significance stars are often enough, sometimes
we need an exact p-value. To obtain this, we‚Äôll use the ‚Äútab_model()‚Äù
function from the same {sjPlot} package. This function produces a nice,
publication-ready table that not only provides exact p-values but also
reveals the equation of our linear model:&lt;/p&gt;
&lt;h1 id="summary-function"&gt;Summary function&lt;/h1&gt;
&lt;pre class="r"&gt;&lt;code&gt;summary(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lm(formula = wage ~ education, data = d)

Residuals:
   Min     1Q Median     3Q    Max 
-84.46 -16.56  -2.13  16.04  95.09 

Coefficients:
                            Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)                   86.186      2.810  30.674  &amp;lt; 2e-16 ***
education2. HS Grad            9.949      3.974   2.504   0.0126 *  
education3. Some College      18.359      3.974   4.620 4.89e-06 ***
education4. College Grad      29.353      3.974   7.387 6.43e-13 ***
education5. Advanced Degree   46.185      3.974  11.623  &amp;lt; 2e-16 ***
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 28.1 on 495 degrees of freedom
Multiple R-squared:  0.2458,    Adjusted R-squared:  0.2397 
F-statistic: 40.34 on 4 and 495 DF,  p-value: &amp;lt; 2.2e-16&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could use a well known summary table for that, but the output,
although useful, is not really pleasing to the human eye and is not
suitable for publication.&lt;/p&gt;
&lt;p&gt;There are tons of videos about summary function out there. So, I
don‚Äôt explain this in detail here. And I honestly don‚Äôt know why it is
soo famous and soo many videos are made about it. And here is what
summary function misses to deliver:&lt;/p&gt;
&lt;p&gt;Have you ever wondered, why a ‚Äúsummary‚Äù function compares all
categories of a categorical predictor to only the reference category,
without comparing categories to each other?&lt;/p&gt;
&lt;p&gt;And what about those mysterious slopes with standard errors we get as
model coefficients instead of the averages per category with 95% CIs
that we actually want?&lt;/p&gt;
&lt;p&gt;Moreover, ‚Äúsummary‚Äù function doesn‚Äôt adjust p-values for multiple
comparisons, which increases the probability of discovering nonsense by
making too many type-I errors.&lt;/p&gt;
&lt;p&gt;Summary function doesn‚Äôt plot the results of a model and&lt;/p&gt;
&lt;p&gt;makes it almost impossible to interpret interactions!&lt;/p&gt;
&lt;p&gt;So, if you‚Äôve ever been frustrated due to similar issues, you‚Äôre
definitely not alone! The ‚Äúsummary‚Äù function doesn‚Äôt actually provide a
very useful summary, and that‚Äôs why we need {emmeans} package, which
solves all those problems.&lt;/p&gt;
&lt;p&gt;Post-Hoc tests.&lt;/p&gt;
&lt;p&gt;A much better choice is the ‚Äúemmeans‚Äù function from the very powerful
{emmeans} package. It not only provides predictions for any education
you desire, but also reports 95% confidence intervals and offers a wide
range of additional capabilities.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(emmeans)   # extra 2 videos on my channel ;)
results &amp;lt;- emmeans(m, pairwise ~ education, infer = T)
results&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;$emmeans
 education          emmean   SE  df lower.CL upper.CL t.ratio p.value
 1. &amp;lt; HS Grad         86.2 2.81 495     80.7     91.7  30.674  &amp;lt;.0001
 2. HS Grad           96.1 2.81 495     90.6    101.7  34.215  &amp;lt;.0001
 3. Some College     104.5 2.81 495     99.0    110.1  37.208  &amp;lt;.0001
 4. College Grad     115.5 2.81 495    110.0    121.1  41.121  &amp;lt;.0001
 5. Advanced Degree  132.4 2.81 495    126.9    137.9  47.112  &amp;lt;.0001

Confidence level used: 0.95 

$contrasts
 contrast                             estimate   SE  df lower.CL
 1. &amp;lt; HS Grad - 2. HS Grad               -9.95 3.97 495    -20.8
 1. &amp;lt; HS Grad - 3. Some College         -18.36 3.97 495    -29.2
 1. &amp;lt; HS Grad - 4. College Grad         -29.35 3.97 495    -40.2
 1. &amp;lt; HS Grad - 5. Advanced Degree      -46.18 3.97 495    -57.1
 2. HS Grad - 3. Some College            -8.41 3.97 495    -19.3
 2. HS Grad - 4. College Grad           -19.40 3.97 495    -30.3
 2. HS Grad - 5. Advanced Degree        -36.24 3.97 495    -47.1
 3. Some College - 4. College Grad      -10.99 3.97 495    -21.9
 3. Some College - 5. Advanced Degree   -27.83 3.97 495    -38.7
 4. College Grad - 5. Advanced Degree   -16.83 3.97 495    -27.7
 upper.CL t.ratio p.value
    0.930  -2.504  0.0914
   -7.480  -4.620  &amp;lt;.0001
  -18.474  -7.387  &amp;lt;.0001
  -35.306 -11.623  &amp;lt;.0001
    2.469  -2.117  0.2146
   -8.525  -4.883  &amp;lt;.0001
  -25.357  -9.119  &amp;lt;.0001
   -0.114  -2.767  0.0462
  -16.947  -7.003  &amp;lt;.0001
   -5.953  -4.236  0.0003

Confidence level used: 0.95 
Conf-level adjustment: tukey method for comparing a family of 5 estimates 
P value adjustment: tukey method for comparing a family of 5 estimates &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We could even quickly plot contrasts in order to see where the
difference is the biggest. For instance, naturally the biggest
difference is between two lowest categories, HS Grad and below, vs.¬†the
highest categorie, Advanced Degree.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;results$contrasts %&amp;gt;% plot() &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-12-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;But as much as I love {emmeans} package, it is also not perfect.
While it can produce a publication ready with some coding effort, it‚Äôs
not as easy and quick, as with two other options we‚Äôll learn next.&lt;/p&gt;
&lt;h1 id="get-publication-ready-table"&gt;Get publication ready table&lt;/h1&gt;
&lt;p&gt;The first one is ‚Äútab_model‚Äù function from {sjPlot} package. It takes
only three intuitive arguments to produce a basic table, where all
categories are compared to the reference levels.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_model(m, 
          show.reflvl = T, 
          show.intercept = F, 
          p.style = &amp;quot;numeric_stars&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
wage
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
CI
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol style="list-style-type: decimal"&gt;
&lt;li&gt;&amp;lt; HS Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;em&gt;Reference&lt;/em&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="2" style="list-style-type: decimal"&gt;
&lt;li&gt;HS Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
9.95 &lt;sup&gt;*&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
2.14¬†‚Äì¬†17.76
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;0.013&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="3" style="list-style-type: decimal"&gt;
&lt;li&gt;Some College
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
18.36 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
10.55¬†‚Äì¬†26.17
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="4" style="list-style-type: decimal"&gt;
&lt;li&gt;College Grad
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
29.35 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
21.55¬†‚Äì¬†37.16
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
&lt;ol start="5" style="list-style-type: decimal"&gt;
&lt;li&gt;Advanced Degree
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
46.18 &lt;sup&gt;***&lt;/sup&gt;
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
38.38¬†‚Äì¬†53.99
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;
500
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;
0.246 / 0.240
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td colspan="4" style="font-style:italic; border-top:double black; text-align:right;"&gt;
&lt;ul&gt;
&lt;li&gt;p&amp;lt;0.05¬†¬†¬†** p&amp;lt;0.01¬†¬†¬†*** p&amp;lt;0.001
&lt;/td&gt;
&lt;/tr&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/table&gt;
&lt;p&gt;But I never understood, why people avoid more inference by limiting
themselfes to only one reference category, while this inference was
already calculated by the model. What if we want to compare all
categories to each other pairwisely? So, that the second option is to
produce a table with contrasts using the ‚Äútbl_regression‚Äù function from
{gtsummary} package, which also take only few intuitive arguments. Where
Beta is the difference in thousands of dollars.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(gtsummary)
fancy_table &amp;lt;- tbl_regression(m, add_pairwise_contrasts = T) %&amp;gt;% 
   add_significance_stars(hide_p = F, hide_se = T, hide_ci = F)

fancy_table&lt;/code&gt;&lt;/pre&gt;
&lt;div id="cchgeimrdv" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;"&gt;
&lt;style&gt;#cchgeimrdv table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#cchgeimrdv thead, #cchgeimrdv tbody, #cchgeimrdv tfoot, #cchgeimrdv tr, #cchgeimrdv td, #cchgeimrdv th {
  border-style: none;
}

#cchgeimrdv p {
  margin: 0;
  padding: 0;
}

#cchgeimrdv .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#cchgeimrdv .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#cchgeimrdv .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#cchgeimrdv .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#cchgeimrdv .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cchgeimrdv .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cchgeimrdv .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#cchgeimrdv .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#cchgeimrdv .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#cchgeimrdv .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#cchgeimrdv .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#cchgeimrdv .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#cchgeimrdv .gt_spanner_row {
  border-bottom-style: hidden;
}

#cchgeimrdv .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#cchgeimrdv .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#cchgeimrdv .gt_from_md &gt; :first-child {
  margin-top: 0;
}

#cchgeimrdv .gt_from_md &gt; :last-child {
  margin-bottom: 0;
}

#cchgeimrdv .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#cchgeimrdv .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#cchgeimrdv .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#cchgeimrdv .gt_row_group_first td {
  border-top-width: 2px;
}

#cchgeimrdv .gt_row_group_first th {
  border-top-width: 2px;
}

#cchgeimrdv .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cchgeimrdv .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#cchgeimrdv .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#cchgeimrdv .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cchgeimrdv .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#cchgeimrdv .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#cchgeimrdv .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#cchgeimrdv .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#cchgeimrdv .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#cchgeimrdv .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cchgeimrdv .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#cchgeimrdv .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#cchgeimrdv .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#cchgeimrdv .gt_left {
  text-align: left;
}

#cchgeimrdv .gt_center {
  text-align: center;
}

#cchgeimrdv .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#cchgeimrdv .gt_font_normal {
  font-weight: normal;
}

#cchgeimrdv .gt_font_bold {
  font-weight: bold;
}

#cchgeimrdv .gt_font_italic {
  font-style: italic;
}

#cchgeimrdv .gt_super {
  font-size: 65%;
}

#cchgeimrdv .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#cchgeimrdv .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#cchgeimrdv .gt_indent_1 {
  text-indent: 5px;
}

#cchgeimrdv .gt_indent_2 {
  text-indent: 10px;
}

#cchgeimrdv .gt_indent_3 {
  text-indent: 15px;
}

#cchgeimrdv .gt_indent_4 {
  text-indent: 20px;
}

#cchgeimrdv .gt_indent_5 {
  text-indent: 25px;
}
&lt;/style&gt;
&lt;table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false"&gt;
  &lt;thead&gt;
    &lt;tr class="gt_col_headings"&gt;
      &lt;th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&amp;lt;strong&amp;gt;Characteristic&amp;lt;/strong&amp;gt;"&gt;&lt;strong&gt;Characteristic&lt;/strong&gt;&lt;/th&gt;
      &lt;th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&amp;lt;strong&amp;gt;Beta&amp;lt;/strong&amp;gt;&amp;lt;span class=&amp;quot;gt_footnote_marks&amp;quot; style=&amp;quot;white-space:nowrap;font-style:italic;font-weight:normal;&amp;quot;&amp;gt;&amp;lt;sup&amp;gt;1&amp;lt;/sup&amp;gt;&amp;lt;/span&amp;gt;"&gt;&lt;strong&gt;Beta&lt;/strong&gt;&lt;span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;&lt;/th&gt;
      &lt;th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&amp;lt;strong&amp;gt;95% CI&amp;lt;/strong&amp;gt;&amp;lt;span class=&amp;quot;gt_footnote_marks&amp;quot; style=&amp;quot;white-space:nowrap;font-style:italic;font-weight:normal;&amp;quot;&amp;gt;&amp;lt;sup&amp;gt;2&amp;lt;/sup&amp;gt;&amp;lt;/span&amp;gt;"&gt;&lt;strong&gt;95% CI&lt;/strong&gt;&lt;span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt;&lt;/th&gt;
      &lt;th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&amp;lt;strong&amp;gt;p-value&amp;lt;/strong&amp;gt;"&gt;&lt;strong&gt;p-value&lt;/strong&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody class="gt_table_body"&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;education&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;&lt;br /&gt;&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;&lt;br /&gt;&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;br /&gt;&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†2. HS Grad - 1. &amp;lt; HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;10&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;-0.93, 21&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;0.091&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†3. Some College - 1. &amp;lt; HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;18***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;7.5, 29&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†3. Some College - 2. HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;8.4&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;-2.5, 19&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;0.2&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†4. College Grad - 1. &amp;lt; HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;29***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;18, 40&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†4. College Grad - 2. HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;19***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;8.5, 30&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†4. College Grad - 3. Some College&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;11*&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;0.11, 22&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;0.046&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†5. Advanced Degree - 1. &amp;lt; HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;46***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;35, 57&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†5. Advanced Degree - 2. HS Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;36***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;25, 47&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†5. Advanced Degree - 3. Some College&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;28***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;17, 39&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
    &lt;tr&gt;&lt;td headers="label" class="gt_row gt_left"&gt;¬†¬†¬†¬†5. Advanced Degree - 4. College Grad&lt;/td&gt;
&lt;td headers="estimate" class="gt_row gt_center"&gt;17***&lt;/td&gt;
&lt;td headers="ci" class="gt_row gt_center"&gt;6.0, 28&lt;/td&gt;
&lt;td headers="p.value" class="gt_row gt_center"&gt;&lt;0.001&lt;/td&gt;&lt;/tr&gt;
  &lt;/tbody&gt;
  
  &lt;tfoot class="gt_footnotes"&gt;
    &lt;tr&gt;
      &lt;td class="gt_footnote" colspan="4"&gt;&lt;span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt; *p&amp;lt;0.05; **p&amp;lt;0.01; ***p&amp;lt;0.001&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td class="gt_footnote" colspan="4"&gt;&lt;span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/span&gt; CI = Confidence Interval&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tfoot&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(flextable)
fancy_table %&amp;gt;%
  as_flex_table() %&amp;gt;%
  save_as_docx(path = &amp;quot;fancy_table.docx&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When you need to publish the equation of the model, you could
‚Äúextract_eq‚Äù it from the model via ‚Äúextract_eq‚Äù function from
{equatiomatic} package.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(equatiomatic)
extract_eq(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[
\operatorname{wage} = \alpha +
\beta_{1}(\operatorname{education}_{\operatorname{2.\ HS\ Grad}}) +
\beta_{2}(\operatorname{education}_{\operatorname{3.\ Some\ College}}) +
\beta_{3}(\operatorname{education}_{\operatorname{4.\ College\ Grad}}) +
\beta_{4}(\operatorname{education}_{\operatorname{5.\ Advanced\
Degree}}) + \epsilon
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This equation describes the straight-line relationship between the
x-axis and the y-axis:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[ y = Œ± + Œ≤x \]&lt;/span&gt; Or, in our case,
between ‚Äúeducation‚Äù and ‚Äúsalary‚Äù:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[ wage = Estimate_{(Intercept)} +
Estimate_{education} * education \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;‚Ä¶ and it helps us to interpret our model. Specifically, an increase
in education of one year results in an average salary increase of 1080$.
It‚Äôs important to note that this increase can vary ‚Äî sometimes it‚Äôs as
low as 540$, and other times as high as 1620$, depending on people‚Äôs job
roles. The model indicates that there is a 95% chance that the salary
increase falls within this interval. That‚Äôs why it‚Äôs called - the 95%
Confidence Interval.&lt;/p&gt;
&lt;p&gt;If this average annual increase of 1080$ occurs consistently, we
obtain the slope of the line, represented by the beta (Œ≤) coefficient in
the model formula. Put simply, the slope indicates the average change in
‚Äúy‚Äù for every one-unit increase in ‚Äúx‚Äù. As with any slope, it needs a
starting point. And the best start of any slope is usually zero. When
our line crosses the y-axis (zero on the x-axis), we find the intercept
(Œ±) in the model output. In our case, this implies an unrealistic
scenario where our salary would be 57,500$ at birth, which doesn‚Äôt make
any sense, and that‚Äôs why the intercept of a model is often not
interpreted.&lt;/p&gt;
&lt;p&gt;The true value of the formula lies in its ability to predict future
salaries. By plugging any ‚Äúeducation‚Äù value (x) into the model equation,
we can estimate the corresponding ‚Äúsalary‚Äù value (y). This means we can
ask the model to tell us how much we‚Äôll earn when we‚Äôre 40 or 50.&lt;/p&gt;
&lt;h1 id="get-effect-sizes"&gt;Get effect sizes&lt;/h1&gt;
&lt;p&gt;Now, that we understand how to interpret our model, the next crucial
question we need to address is - how good our model is. Your clients or
scientific reviewers will definetely ask this question. What they
typically want to know is - how well our model fits the data, which is
summarized by the coefficient of determination, denoted as &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; quantifies how much variance
in the data our model explains. It ranges from 0 to 1, with a simple
rule: the higher the value, the better the fit. However, interpreting
&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; is context-dependent. For
instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in physics, a model with &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;
near 1 is usually desirable, while&lt;/li&gt;
&lt;li&gt;in biology, even an &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; of 0.2
might indicate a good model fit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite this context sensitivity, some guidelines proposed by smart
individuals (such as Cohen) exist. And we can ask the {effectsize}
package to interpret any value of &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; for us.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get effect sizes
library(effectsize)
?interpret_r2

interpret_r2(0.246, rules = &amp;quot;cohen1988&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;moderate&amp;quot;
(Rules: cohen1988)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# rules = &amp;quot;cohen1988&amp;quot; is a default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case, the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; value of
0.139 indicates a moderate relationship between education and salary.
But why moderate and not strong? Well, that could be because education
is most likely not the most crucial predictor for salary üòâ. I mean,
when I sit on the sofa, do nothing, and just get older, my salary won‚Äôt
grow! So, what is an important predictor? Education is!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(x = education, y = wage, color = jobclass))+
  geom_boxplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file102174077ce71_files/figure-html/unnamed-chunk-17-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Specifically, folks without a High School diploma start at 70,000$ as
early as 18 years old, while those with an ‚ÄúAdvanced Degree‚Äù begin with
a salary of approximately 140,000$ at the education of 25, after
completing their studies. However, I‚Äôll cover it in a separate video in
this series, where I demonstrate how to interpret a model with a
categorical predictor. Until then if you‚Äôre enjoying the video so far,
please, consider hitting the like button!&lt;/p&gt;
&lt;h1 id="report-model-results"&gt;Report model results&lt;/h1&gt;
&lt;p&gt;Finally, the last thing I found difficult was &lt;strong&gt;accurately
describing the model with sufficient detail&lt;/strong&gt; for others to
understand and reproduce my results. If you have similar problem, the
{report} package solves it ‚Äî even if you only use one function to
literally ‚Äúreport‚Äù your model.&lt;/p&gt;
&lt;p&gt;Namely, the ‚Äúreport‚Äù function:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identifies the type of model you used,&lt;/li&gt;
&lt;li&gt;shows how well the model fits the data (&lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;),&lt;/li&gt;
&lt;li&gt;interprets effect sizes,&lt;/li&gt;
&lt;li&gt;describes whether predictors are significant and which direction the
slopes go and&lt;/li&gt;
&lt;li&gt;even reports how 95% confidence intervals (CIs) and p-values were
calculated.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I personally found it very useful, but I‚Äôd love to know what you
think? So, feel free to share your thoughts in the comments section
below.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(report)   # extra video on my channel
report(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;We fitted a linear model (estimated using OLS) to predict wage with
education (formula: wage ~ education). The model explains a
statistically significant and moderate proportion of variance (R2 =
0.25, F(4, 495) = 40.34, p &amp;lt; .001, adj. R2 = 0.24). The model&amp;#39;s
intercept, corresponding to education = 1. &amp;lt; HS Grad, is at 86.19
(95% CI [80.67, 91.71], t(495) = 30.67, p &amp;lt; .001). Within this model:

  - The effect of education [2. HS Grad] is statistically significant
and positive (beta = 9.95, 95% CI [2.14, 17.76], t(495) = 2.50, p =
0.013; Std. beta = 0.31, 95% CI [0.07, 0.55])
  - The effect of education [3. Some College] is statistically
significant and positive (beta = 18.36, 95% CI [10.55, 26.17], t(495)
= 4.62, p &amp;lt; .001; Std. beta = 0.57, 95% CI [0.33, 0.81])
  - The effect of education [4. College Grad] is statistically
significant and positive (beta = 29.35, 95% CI [21.55, 37.16], t(495)
= 7.39, p &amp;lt; .001; Std. beta = 0.91, 95% CI [0.67, 1.15])
  - The effect of education [5. Advanced Degree] is statistically
significant and positive (beta = 46.18, 95% CI [38.38, 53.99], t(495)
= 11.62, p &amp;lt; .001; Std. beta = 1.43, 95% CI [1.19, 1.68])

Standardized parameters were obtained by fitting the model on a
standardized version of the dataset. 95% Confidence Intervals (CIs)
and p-values were computed using a Wald t-distribution approximation.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;model_performance(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# Indices of model performance

AIC      |     AICc |      BIC |    R2 | R2 (adj.) |   RMSE |  Sigma
--------------------------------------------------------------------
4761.586 | 4761.756 | 4786.874 | 0.246 |     0.240 | 27.956 | 28.097&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="whats-next"&gt;What‚Äôs next?&lt;/h1&gt;
&lt;p&gt;What do we do, when assumptions are not satisfied? Well, while there
are several options, like robust or bootstrapping regression, I
personally enjoy the quantile regression a lot. So, if you wanna be
equepped for more situations and be statistically robust, make sure to
check out this &lt;a href="https://youtu.be/Gtz8ca_4hVg"&gt;video on quantile
regression&lt;/a&gt;:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;The data contains 500 observations, grouped by education, of the
following 11 variables:

- 1. &amp;lt; HS Grad (n = 100):
  - year: n = 100, Mean = 2006.01, SD = 1.98, Median = 2006.00, MAD =
2.97, range: [2003, 2009], Skewness = 0.02, Kurtosis = -1.32, 0%
missing
  - age: n = 100, Mean = 41.27, SD = 11.56, Median = 41.00, MAD =
10.38, range: [18, 73], Skewness = 0.38, Kurtosis = -7.93e-03, 0%
missing
  - maritl: 5 levels, namely 1. Never Married (n = 21, 21.00%), 2.
Married (n = 64, 64.00%), 3. Widowed (n = 0, 0.00%), 4. Divorced (n =
7, 7.00%) and 5. Separated (n = 8, 8.00%)
  - race: 4 levels, namely 1. White (n = 82, 82.00%), 2. Black (n = 10,
10.00%), 3. Asian (n = 6, 6.00%) and 4. Other (n = 2, 2.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 68, 68.00%) and 2.
Information (n = 32, 32.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 41, 41.00%) and 2. &amp;gt;=Very
Good (n = 59, 59.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 49, 49.00%) and 2. No (n =
51, 51.00%)
  - logwage: n = 100, Mean = 4.42, SD = 0.30, Median = 4.40, MAD =
0.24, range: [3.04, 5.03], Skewness = -1.41, Kurtosis = 5.43, 0%
missing
  - wage: n = 100, Mean = 86.19, SD = 22.70, Median = 81.28, MAD =
18.77, range: [20.93, 152.22], Skewness = 0.25, Kurtosis = 0.70, 0%
missing

- 2. HS Grad (n = 100):
  - year: n = 100, Mean = 2006.00, SD = 2.02, Median = 2006.00, MAD =
2.97, range: [2003, 2009], Skewness = -0.02, Kurtosis = -1.29, 0%
missing
  - age: n = 100, Mean = 42.85, SD = 11.76, Median = 43.00, MAD =
11.86, range: [19, 66], Skewness = -0.05, Kurtosis = -0.85, 0%
missing
  - maritl: 5 levels, namely 1. Never Married (n = 19, 19.00%), 2.
Married (n = 70, 70.00%), 3. Widowed (n = 2, 2.00%), 4. Divorced (n =
8, 8.00%) and 5. Separated (n = 1, 1.00%)
  - race: 4 levels, namely 1. White (n = 88, 88.00%), 2. Black (n = 8,
8.00%), 3. Asian (n = 3, 3.00%) and 4. Other (n = 1, 1.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 62, 62.00%) and 2.
Information (n = 38, 38.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 38, 38.00%) and 2. &amp;gt;=Very
Good (n = 62, 62.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 70, 70.00%) and 2. No (n =
30, 30.00%)
  - logwage: n = 100, Mean = 4.53, SD = 0.26, Median = 4.54, MAD =
0.24, range: [3.90, 5.08], Skewness = -0.15, Kurtosis = -0.44, 0%
missing
  - wage: n = 100, Mean = 96.13, SD = 24.91, Median = 94.00, MAD =
23.72, range: [49.56, 160.64], Skewness = 0.44, Kurtosis = -0.22, 0%
missing

- 3. Some College (n = 100):
  - year: n = 100, Mean = 2005.77, SD = 1.94, Median = 2006.00, MAD =
2.22, range: [2003, 2009], Skewness = 0.09, Kurtosis = -1.09, 0%
missing
  - age: n = 100, Mean = 39.42, SD = 11.40, Median = 39.00, MAD =
13.34, range: [18, 64], Skewness = 0.29, Kurtosis = -0.76, 0% missing
  - maritl: 5 levels, namely 1. Never Married (n = 29, 29.00%), 2.
Married (n = 59, 59.00%), 3. Widowed (n = 0, 0.00%), 4. Divorced (n =
10, 10.00%) and 5. Separated (n = 2, 2.00%)
  - race: 4 levels, namely 1. White (n = 87, 87.00%), 2. Black (n = 11,
11.00%), 3. Asian (n = 1, 1.00%) and 4. Other (n = 1, 1.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 55, 55.00%) and 2.
Information (n = 45, 45.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 22, 22.00%) and 2. &amp;gt;=Very
Good (n = 78, 78.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 67, 67.00%) and 2. No (n =
33, 33.00%)
  - logwage: n = 100, Mean = 4.60, SD = 0.35, Median = 4.62, MAD =
0.23, range: [3, 5.18], Skewness = -2.01, Kurtosis = 6.96, 0% missing
  - wage: n = 100, Mean = 104.55, SD = 29.35, Median = 101.82, MAD =
24.83, range: [20.09, 176.99], Skewness = -0.08, Kurtosis = 0.84, 0%
missing

- 4. College Grad (n = 100):
  - year: n = 100, Mean = 2005.69, SD = 1.99, Median = 2005.50, MAD =
2.22, range: [2003, 2009], Skewness = 0.14, Kurtosis = -1.25, 0%
missing
  - age: n = 100, Mean = 41.88, SD = 10.68, Median = 43.00, MAD =
11.86, range: [22, 64], Skewness = 0.03, Kurtosis = -0.86, 0% missing
  - maritl: 5 levels, namely 1. Never Married (n = 26, 26.00%), 2.
Married (n = 64, 64.00%), 3. Widowed (n = 1, 1.00%), 4. Divorced (n =
9, 9.00%) and 5. Separated (n = 0, 0.00%)
  - race: 4 levels, namely 1. White (n = 84, 84.00%), 2. Black (n = 6,
6.00%), 3. Asian (n = 8, 8.00%) and 4. Other (n = 2, 2.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 34, 34.00%) and 2.
Information (n = 66, 66.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 23, 23.00%) and 2. &amp;gt;=Very
Good (n = 77, 77.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 77, 77.00%) and 2. No (n =
23, 23.00%)
  - logwage: n = 100, Mean = 4.71, SD = 0.29, Median = 4.74, MAD =
0.27, range: [3.90, 5.30], Skewness = -0.70, Kurtosis = 0.33, 0%
missing
  - wage: n = 100, Mean = 115.54, SD = 30.77, Median = 114.48, MAD =
30.12, range: [49.56, 200.54], Skewness = 0.06, Kurtosis = -0.15, 0%
missing

- 5. Advanced Degree (n = 100):
  - year: n = 100, Mean = 2006.02, SD = 2.08, Median = 2006.00, MAD =
2.97, range: [2003, 2009], Skewness = 0.01, Kurtosis = -1.32, 0%
missing
  - age: n = 100, Mean = 43.73, SD = 10.29, Median = 42.50, MAD =
12.60, range: [27, 72], Skewness = 0.27, Kurtosis = -0.74, 0% missing
  - maritl: 5 levels, namely 1. Never Married (n = 21, 21.00%), 2.
Married (n = 72, 72.00%), 3. Widowed (n = 0, 0.00%), 4. Divorced (n =
7, 7.00%) and 5. Separated (n = 0, 0.00%)
  - race: 4 levels, namely 1. White (n = 76, 76.00%), 2. Black (n = 9,
9.00%), 3. Asian (n = 15, 15.00%) and 4. Other (n = 0, 0.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 31, 31.00%) and 2.
Information (n = 69, 69.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 13, 13.00%) and 2. &amp;gt;=Very
Good (n = 87, 87.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 75, 75.00%) and 2. No (n =
25, 25.00%)
  - logwage: n = 100, Mean = 4.86, SD = 0.25, Median = 4.90, MAD =
0.20, range: [4.03, 5.43], Skewness = -0.64, Kurtosis = 0.86, 0%
missing
  - wage: n = 100, Mean = 132.37, SD = 31.67, Median = 133.97, MAD =
24.62, range: [56.45, 227.46], Skewness = 0.21, Kurtosis = 0.32, 0%
missing&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="should-we-categorize-numerical-predictors"&gt;Should we categorize
numerical predictors?&lt;/h1&gt;
&lt;h2 id="advantages"&gt;Advantages&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Increases interpretability: Sometimes it‚Äôs easier to understand
the impact of different predictor levels on the outcome. For instance,
instead of saying ‚Äúfor every 1-unit increase in blood pressure,‚Äù we can
say ‚Äúfor patients with high blood pressure.‚Äù&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Handles nonlinearity: Categorization captures nonlinear
relationships between predictors and outcomes if one exists. By
categorizing based on these smooth functions, we can identify risk
categories (e.g., low, average, high) more effectively. Segmenting the
data into groups can potentially improve model fit and predictive
power.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Decision Support: Categorization simplifies decision-making. For
example, a physician might categorize a patient‚Äôs cholesterol level as
‚Äúnormal,‚Äù ‚Äúborderline,‚Äù or ‚Äúhigh.‚Äù&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Model Stability: Categorization can stabilize model estimates.
Continuous predictors may introduce noise due to small fluctuations. By
grouping similar values together, we reduce the impact of minor
variations and enhance model stability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Outlier Control: Similar to decision trees, categorization can
reduce the impact of outliers in the data. By grouping outliers with
other data points, their influence on the model can be
mitigated.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Relaxes Linearity Assumption&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Handling Missing Values: Categorization allows handling missing
data by creating a separate category.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="disadvantages"&gt;Disadvantages&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Information Loss: The original numeric relationship is replaced
by discrete categories, which may not fully capture the underlying
variability.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Subjective Boundaries (Category Choice): Choosing category
boundaries is subjective and can impact model results. Techniques like
quantile-based methods, k-means clustering, or domain knowledge-based
approaches can be used to create informative categories. However,
choosing different binning schemes can lead to varying results.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Inefficient Use of Data: Binning reduces the effective sample
size within each category. Smaller sample sizes can lead to less precise
estimates.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Increased Model Complexity: Categorization introduces additional
parameters (dummy variables) into the model. More parameters can lead to
overfitting, especially with limited data.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;In summary, while categorization can simplify modeling, it comes
with trade-offs. Consider the context, research question, and data
characteristics before deciding whether to categorize numeric predictors
in your statistical models.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>65d2ebf82466f5bf43bdf9cb8b13d8c3</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2024-02-28-lmcategorical</guid>
      <pubDate>Tue, 05 Mar 2024 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2024-02-28-lmcategorical/lmcategorical_files/figure-html5/unnamed-chunk-2-1.png" medium="image" type="image/png" width="1248" height="768"/>
    </item>
    <item>
      <title>Master Simple Linear Regression with Numeric Predictor in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2024-02-03-lmnumeric</link>
      <description>


&lt;h1 id="this-post-as-ca.-12-minutes-video"&gt;This post as ca. 12 minutes
video&lt;/h1&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/yjdONltFwjM" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h1 id="clean-the-data-otherwise-shit-in-shit-out"&gt;Clean the data,
otherwise: shit in shit out!&lt;/h1&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-2-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;The data in this picture comes from the Wage dataset in the ISLR
package. It clearly shows that real-world data often contains
contaminations üí©. Therefore, it‚Äôs crucial to look at the data first
before rushing into modeling. For instance, in this scenario, I would
clean the data by removing the high-income individuals earning over 200K
per year, because they are outliers, and totally not because I am
jealous! üòâ Additionally, I‚Äôd exclude older individuals who are nearing
retirement, as their salaries tend to decline. The data-cleaning step is
vital and often overlooked. Remember the phrase: ‚ÄòGarbage in, garbage
out‚Äô? If we skip data cleaning, our model‚Äôs performance could be
seriously compromised, and we‚Äôll see it in a moment. For now let‚Äôs take
100 random people form the industry and build our linear model in R.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(tidyverse)      # laod &amp;amp; thank me later ;)
library(ISLR)           # provides Wage dataset
theme_set(theme_test()) # beautifies plots

set.seed(1)             # for reproducibility
d &amp;lt;- Wage %&amp;gt;% 
  filter(wage &amp;lt; 200 &amp;amp; age &amp;lt; 60 &amp;amp; jobclass == &amp;quot;1. Industrial&amp;quot;) %&amp;gt;% 
  sample_n(100)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="build-linear-equation"&gt;Build linear equation&lt;/h1&gt;
&lt;p&gt;To build our linear model, we‚Äôll use the intuitive ‚Äòlm‚Äô (show pack of
cigarettes ; —Å —Ä–µ–∫–ª–∞–º–æ–π –∏–º–ø–æ—Ç–µ–Ω—Ü–∏–∏ :) function. Within ‚Äòlm‚Äô, we only
need two arguments: the formula and the data. Here‚Äôs how it breaks
down:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;On the left side of the formula, we‚Äôll place the variable we‚Äôre
interested in predicting. Unfortunately, this variable goes by several
names: response variable, outcome, dependent variable, target, and more.
It can get confusing!&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On the fright side, we‚Äôll place the predictor variable.
Predictors also have various synonyms: independent variable, explanatory
variable, regressor or covariate (in linear regression), feature (in
Machine Learning), and even risk factor (in epidemiology).&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Ugh, so many names for the same thing! Drives me nuts. Makes stats
seem way harder than it actually is.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# build the model
m &amp;lt;- lm(formula = wage ~ age, data = d)&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="check-all-model-assumptions-visually"&gt;Check all model
assumptions visually&lt;/h1&gt;
&lt;p&gt;After building the model, we need to make sure the assumptions are
satisfied. Otherwise, we couldn‚Äôt trust our model! The ‚Äúcheck_model()‚Äù
function from the {performance} package is so intuitive and powerful
that, once you‚Äôve used it, you cannot unlearn it! Believe me! I use it
&lt;strong&gt;every time&lt;/strong&gt; I model.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# check model assumptions visually
library(performance)   # extra video on my channel
check_model(m)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-5-1.png" width="864" /&gt;&lt;/p&gt;
&lt;p&gt;Looking at the assumptions, I could say that the model fits the data
pretty well! The linearity assumption looks fine; the line is not
completely straight, but there is no dramatic non-linearity to see. The
variance is homogeneous. There are no influential points or outliers.
And finally, the residuals are normally distributed since they are
inside the confidence intervals, which means our data is normally
distributed.&lt;/p&gt;
&lt;p&gt;Now, when we model uncleaned data, the model fit would be far from
reality, and we‚Äôll even get a warning that our model misses the maximum
values ‚Äî you know, those rich folks I am totally not jealous about ;).
Besides, the normality of residuals would also be compromised, so I
would stop trusting my model. Therefore, it‚Äôs really important to clean
the data before modeling.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;m2 &amp;lt;- lm(formula = wage ~ age, data = Wage)
library(patchwork)
check_posterior_predictions(m2)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Maximum value of original data is not included in the
  replicated data.
  Model may not capture the variation of the data.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-6-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;a &amp;lt;- check_posterior_predictions(m2) %&amp;gt;% plot() 
b &amp;lt;- check_normality(m2) %&amp;gt;% plot()

a + b&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-6-2.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Oh, by the way, if you have a lot of data, it‚Äôs important to check
assumptions visually, like we just did, instead of conducting
statistical tests. For a lot of data, the tests would often show
significant results, meaning that assumptions seemingly would not be
satisfied, while they are actually satisfied. Here is an example of the
Shapiro-Wilk normality test, which magically finds non-normally
distributed residuals, even though they are totally fine!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# don&amp;#39;t trust statistical tests to much
check_normality(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Warning: Non-normality of residuals detected (p = 0.019).&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, since the assumptions of our model are satisfied, we can
visualize model results, and by results, I mean visualize model
predictions.&lt;/p&gt;
&lt;h1 id="visualize-predictions"&gt;Visualize predictions&lt;/h1&gt;
&lt;p&gt;For that, we‚Äôll use another very intuitive function called
‚Äúplot_model()‚Äù from the {sjPlot} package and provide three
arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;the model name,&lt;/li&gt;
&lt;li&gt;the type of predictions ‚Äî we‚Äôll use ‚Äúeffect‚Äù to get an effect plot,
and&lt;/li&gt;
&lt;li&gt;the name of a predictor we want to visualize.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# visualize predictions
library(sjPlot)    # extra video on my channel

plot_model(m, type = &amp;quot;eff&amp;quot;, terms = &amp;quot;age&amp;quot;) # show.data = T&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-8-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;And if we really want to, we could easily &lt;strong&gt;show the
data&lt;/strong&gt; on our plot:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;plot_model(m, type = &amp;quot;eff&amp;quot;, terms = &amp;quot;age&amp;quot;,  show.data = TRUE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-9-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;And voil√†, our plot shows that salaries increase with age. This plot
is nice, but it misses two important details: it doesn‚Äôt exactly show
how quickly the salary grows, and it doesn‚Äôt demonstrate whether this
increase is significant.&lt;/p&gt;
&lt;h1 id="visualize-estimates"&gt;Visualize estimates&lt;/h1&gt;
&lt;p&gt;The ‚Äúplot_model()‚Äù function solves both problems, when we use
‚Äúshow.values = TRUE‚Äù instead of ‚Äútype =‚Äùeff‚Äù.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# visualize estimates
plot_model(m, show.values = TRUE, terms = &amp;quot;age&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-10-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Namely, it tells us that we have a 1080$ increase in salary per year,
and this increase is highly significant because the estimate doesn‚Äôt
cross zero. And while the significance stars are often enough, sometimes
we need an exact p-value. To obtain this, we‚Äôll use the ‚Äútab_model()‚Äù
function from the same {sjPlot} package. This function produces a nice,
publication-ready table that not only provides exact p-values but also
reveals the equation of our linear model:&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;tab_model(m)&lt;/code&gt;&lt;/pre&gt;
&lt;table style="border-collapse:collapse; border:none;"&gt;
&lt;tr&gt;
&lt;th style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm;  text-align:left; "&gt;
¬†
&lt;/th&gt;
&lt;th colspan="3" style="border-top: double; text-align:center; font-style:normal; font-weight:bold; padding:0.2cm; "&gt;
wage
&lt;/th&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  text-align:left; "&gt;
Predictors
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
Estimates
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
CI
&lt;/td&gt;
&lt;td style=" text-align:center; border-bottom:1px solid; font-style:italic; font-weight:normal;  "&gt;
p
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
(Intercept)
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
57.50
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
35.24¬†‚Äì¬†79.76
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; "&gt;
age
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
1.08
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
0.54¬†‚Äì¬†1.62
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:center;  "&gt;
&lt;strong&gt;&amp;lt;0.001&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm; border-top:1px solid;"&gt;
Observations
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left; border-top:1px solid;" colspan="3"&gt;
100
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; text-align:left; padding-top:0.1cm; padding-bottom:0.1cm;"&gt;
R&lt;sup&gt;2&lt;/sup&gt; / R&lt;sup&gt;2&lt;/sup&gt; adjusted
&lt;/td&gt;
&lt;td style=" padding:0.2cm; text-align:left; vertical-align:top; padding-top:0.1cm; padding-bottom:0.1cm; text-align:left;" colspan="3"&gt;
0.139 / 0.130
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;p&gt;This equation describes the straight-line relationship between the
x-axis and the y-axis:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[ y = Œ± + Œ≤x \]&lt;/span&gt; Or, in our case,
between ‚Äúage‚Äù and ‚Äúsalary‚Äù:&lt;/p&gt;
&lt;p&gt;&lt;span class="math display"&gt;\[ wage = Estimate_{(Intercept)} +
Estimate_{age} * age \]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;‚Ä¶ and it helps us to interpret our model. Specifically, an increase
in age of one year results in an average salary increase of 1080$. It‚Äôs
important to note that this increase can vary ‚Äî sometimes it‚Äôs as low as
540$, and other times as high as 1620$, depending on people‚Äôs job roles.
The model indicates that there is a 95% chance that the salary increase
falls within this interval. That‚Äôs why it‚Äôs called - the 95% Confidence
Interval.&lt;/p&gt;
&lt;p&gt;If this average annual increase of 1080$ occurs consistently, we
obtain the slope of the line, represented by the beta (Œ≤) coefficient in
the model formula. Put simply, the slope indicates the average change in
‚Äúy‚Äù for every one-unit increase in ‚Äúx‚Äù. As with any slope, it needs a
starting point. And the best start of any slope is usually zero. When
our line crosses the y-axis (zero on the x-axis), we find the intercept
(Œ±) in the model output. In our case, this implies an unrealistic
scenario where our salary would be 57,500$ at birth, which doesn‚Äôt make
any sense, and that‚Äôs why the intercept of a model is often not
interpreted.&lt;/p&gt;
&lt;p&gt;The true value of the formula lies in its ability to predict future
salaries. By plugging any ‚Äúage‚Äù value (x) into the model equation, we
can estimate the corresponding ‚Äúsalary‚Äù value (y). This means we can ask
the model to tell us how much we‚Äôll earn when we‚Äôre 40 or 50.&lt;/p&gt;
&lt;h1 id="make-specific-predictions"&gt;Make specific predictions&lt;/h1&gt;
&lt;p&gt;For that we‚Äôll simply replace our alpha with the value of the
Intercept 57.5 and the age with 40 or 50:&lt;/p&gt;
&lt;p&gt;57.50 + 1.08 * 40 = 100.7&lt;/p&gt;
&lt;p&gt;57.50 + 1.08 * 50 = 111.5&lt;/p&gt;
&lt;p&gt;Assuming our lives remain relatively stable, at 40 years old, we
could be earning over 100,000$, and by 50, our paychecks could exceed
111,000$. Essentially, we‚Äôve just forecast our future salaries based on
the available data. Naturally, R provides several convenient functions
for making such predictions, the most well-known being the ‚Äúpredict‚Äù
function. This function allows you to input your model and a data frame
containing the variable you want predictions for. However, I personally
find this function somewhat unintuitive.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get particular predictions
predict(m, data.frame(age = c(40, 50, 60)) )&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;       1        2        3 
100.8430 111.6785 122.5140 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A much better choice is the ‚Äúemmeans‚Äù function from the very powerful
{emmeans} package. It not only provides predictions for any age you
desire, but also reports 95% confidence intervals and offers a wide
range of additional capabilities.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(emmeans)   # extra 2 videos on my channel ;)
emmeans(m, ~ age, at = list(age = c(40, 50, 60)))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt; age emmean   SE df lower.CL upper.CL
  40    101 2.65 98     95.6      106
  50    112 3.80 98    104.1      119
  60    123 6.06 98    110.5      135

Confidence level used: 0.95 &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Asking for predictions beyond 60 years old isn‚Äôt recommended, as we
intentionally limited our data to include only individuals up to 60.
Here, it‚Äôs crucial to differentiate between interpolation and
extrapolation. Interpolation means - predicting values within existing
data points, and it is very useful. However, extrapolation, which means
going beyond the data range, is risky and unreliable. Predicting salary
at birth (age zero) is a perfect example for a nonsensical
extrapolation, because at the age of zero we can‚Äôt earn anything.&lt;/p&gt;
&lt;h1 id="get-effect-sizes"&gt;Get effect sizes&lt;/h1&gt;
&lt;p&gt;Now, that we understand how to interpret our model, the next crucial
question we need to address is - how good our model is. Your clients or
scientific reviewers will definetely ask this question. What they
typically want to know is - how well our model fits the data, which is
summarized by the coefficient of determination, denoted as &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; quantifies how much variance
in the data our model explains. It ranges from 0 to 1, with a simple
rule: the higher the value, the better the fit. However, interpreting
&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; is context-dependent. For
instance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;in physics, a model with &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;
near 1 is usually desirable, while&lt;/li&gt;
&lt;li&gt;in biology, even an &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; of 0.2
might indicate a good model fit.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Despite this context sensitivity, some guidelines proposed by smart
individuals (such as Cohen) exist. And we can ask the {effectsize}
package to interpret any value of &lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt; for us.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# get effect sizes
library(effectsize)
?interpret_r2

interpret_r2(0.139, rules = &amp;quot;cohen1988&amp;quot;) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;moderate&amp;quot;
(Rules: cohen1988)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# rules = &amp;quot;cohen1988&amp;quot; is a default&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In our case, the &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; value of
0.139 indicates a moderate relationship between age and salary. But why
moderate and not strong? Well, that could be because age is most likely
not the most crucial predictor for salary üòâ. I mean, when I sit on the
sofa, do nothing, and just get older, my salary won‚Äôt grow! So, what is
an important predictor? Education is!&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggplot(Wage, aes(x = age, y = wage, color = education))+
  geom_smooth(method = &amp;quot;lm&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file10217efcff8b_files/figure-html/unnamed-chunk-15-1.png" width="672" /&gt;&lt;/p&gt;
&lt;p&gt;Specifically, folks without a High School diploma start at 70,000$ as
early as 18 years old, while those with an ‚ÄúAdvanced Degree‚Äù begin with
a salary of approximately 140,000$ at the age of 25, after completing
their studies. However, I‚Äôll cover it in a separate video in this
series, where I demonstrate how to interpret a model with a categorical
predictor. Until then if you‚Äôre enjoying the video so far, please,
consider hitting the like button!&lt;/p&gt;
&lt;h1 id="report-model-results"&gt;Report model results&lt;/h1&gt;
&lt;p&gt;Finally, the last thing I found difficult was &lt;strong&gt;accurately
describing the model with sufficient detail&lt;/strong&gt; for others to
understand and reproduce my results. If you have similar problem, the
{report} package solves it ‚Äî even if you only use one function to
literally ‚Äúreport‚Äù your model.&lt;/p&gt;
&lt;p&gt;Namely, the ‚Äúreport‚Äù function:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;identifies the type of model you used,&lt;/li&gt;
&lt;li&gt;shows how well the model fits the data (&lt;span
class="math inline"&gt;\(R^2\)&lt;/span&gt;),&lt;/li&gt;
&lt;li&gt;interprets effect sizes,&lt;/li&gt;
&lt;li&gt;describes whether predictors are significant and which direction the
slopes go and&lt;/li&gt;
&lt;li&gt;even reports how 95% confidence intervals (CIs) and p-values were
calculated.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I personally found it very useful, but I‚Äôd love to know what you
think? So, feel free to share your thoughts in the comments section
below.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;library(report)   # extra video on my channel
report(m)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;We fitted a linear model (estimated using OLS) to predict wage with
age (formula: wage ~ age). The model explains a statistically
significant and moderate proportion of variance (R2 = 0.14, F(1, 98)
= 15.80, p &amp;lt; .001, adj. R2 = 0.13). The model&amp;#39;s intercept,
corresponding to age = 0, is at 57.50 (95% CI [35.24, 79.76], t(98) =
5.13, p &amp;lt; .001). Within this model:

  - The effect of age is statistically significant and positive (beta =
1.08, 95% CI [0.54, 1.62], t(98) = 3.97, p &amp;lt; .001; Std. beta = 0.37,
95% CI [0.19, 0.56])

Standardized parameters were obtained by fitting the model on a
standardized version of the dataset. 95% Confidence Intervals (CIs)
and p-values were computed using a Wald t-distribution approximation.&lt;/code&gt;&lt;/pre&gt;
&lt;h1 id="whats-next"&gt;What‚Äôs next?&lt;/h1&gt;
&lt;p&gt;Moreover, the {report} package can help you correctly describe most
classic statistical tests and models. It can even describe your entire
dataset, so make sure to check it out.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;report(d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;The data contains 100 observations of the following 11 variables:

  - year: n = 100, Mean = 2005.83, SD = 2.02, Median = 2006.00, MAD =
2.97, range: [2003, 2009], Skewness = 0.15, Kurtosis = -1.25, 0%
missing
  - age: n = 100, Mean = 39.99, SD = 9.76, Median = 40.50, MAD = 11.86,
range: [18, 56], Skewness = -0.17, Kurtosis = -0.99, 0% missing
  - maritl: 5 levels, namely 1. Never Married (n = 20, 20.00%), 2.
Married (n = 74, 74.00%), 3. Widowed (n = 2, 2.00%), 4. Divorced (n =
4, 4.00%) and 5. Separated (n = 0, 0.00%)
  - race: 4 levels, namely 1. White (n = 83, 83.00%), 2. Black (n = 4,
4.00%), 3. Asian (n = 11, 11.00%) and 4. Other (n = 2, 2.00%)
  - education: 5 levels, namely 1. &amp;lt; HS Grad (n = 14, 14.00%), 2. HS
Grad (n = 37, 37.00%), 3. Some College (n = 22, 22.00%), 4. College
Grad (n = 22, 22.00%) and 5. Advanced Degree (n = 5, 5.00%)
  - region: 9 levels, namely 1. New England (n = 0, 0.00%), 2. Middle
Atlantic (n = 100, 100.00%), 3. East North Central (n = 0, 0.00%), 4.
West North Central (n = 0, 0.00%), 5. South Atlantic (n = 0, 0.00%),
6. East South Central (n = 0, 0.00%), 7. West South Central (n = 0,
0.00%), 8. Mountain (n = 0, 0.00%) and 9. Pacific (n = 0, 0.00%)
  - jobclass: 2 levels, namely 1. Industrial (n = 100, 100.00%) and 2.
Information (n = 0, 0.00%)
  - health: 2 levels, namely 1. &amp;lt;=Good (n = 30, 30.00%) and 2. &amp;gt;=Very
Good (n = 70, 70.00%)
  - health_ins: 2 levels, namely 1. Yes (n = 61, 61.00%) and 2. No (n =
39, 39.00%)
  - logwage: n = 100, Mean = 4.57, SD = 0.29, Median = 4.57, MAD =
0.31, range: [3.92, 5.18], Skewness = -0.17, Kurtosis = -0.58, 0%
missing
  - wage: n = 100, Mean = 100.83, SD = 28.39, Median = 96.76, MAD =
29.46, range: [50.41, 176.99], Skewness = 0.40, Kurtosis = -0.50, 0%
missing&lt;/code&gt;&lt;/pre&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I‚Äôll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>fe90eb946da98201ebb6d83c3792e8cf</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2024-02-03-lmnumeric</guid>
      <pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2024-02-03-lmnumeric/thumbnail_lmnp.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Unleash Quantile Regression Results</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2024-01-04-qr2</link>
      <description>In the previous episode, I presented four reasons why Quantile Regression (QR) is a better alternative to classic linear regression. However, I discovered that reporting QR results can be quite demanding. To make the process easier, I created better plots for model estimates and predictions, a comprehensive table of model results, including contrasts between groups and p-values. I found this code so useful that I thought you guys might benefit from it too. Besides, I really enjoyed programming it :)</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2024-01-04-qr2</guid>
      <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2024-01-04-qr2/thumbnail_QR2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Make Multiplots Like a Pro with {patchwork} | R package reviews</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-12-16-patchwork</link>
      <description>The Patchwork package makes it incredibly easy to combine separate plots into the same graphic by using the simplest mathematical operators, such as plus (+), slash (/), parentheses and much more.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-12-16-patchwork</guid>
      <pubDate>Fri, 22 Dec 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-12-16-patchwork/thumbnail_patchwork.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>Master Box-Violin Plots in {ggplot2} and Discover 10 Reasons Why They Are Useful</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-11-12-boxplots</link>
      <description>Boxplots display a wealth of useful information about the dataset. Let‚Äôs start with the most basic boxplot, build every part of this notched box-violin plot in {ggplot2} step by step, and understand why every detail matters üòâ</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-11-12-boxplots</guid>
      <pubDate>Fri, 24 Nov 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-11-12-boxplots/thumbnail_boxplot.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>7 Reasons to Master Scatter Plots in {ggplot2} with World Happiness Data</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-10-23-scatterplots</link>
      <description>Today, we'll explore happiness data and uncover seven compelling reasons why scatter plots are indispensable for data analysis. You‚Äôll learn about (1) whether money can actually make you happy, (2) how wealth has changed in the USA, Germany, India, and Venezuela over the past 20 years, (3) whether happy people live longer, and much more. The results might surprise you üòâ</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-10-23-scatterplots</guid>
      <pubDate>Sun, 12 Nov 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-10-23-scatterplots/thumbnail_scatter.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Epic Histograms &amp; Density plots with {ggplot2}</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-08-23-histogramsdensityplots</link>
      <description>Histograms display the shape of the distribution of continuous numeric data. The distribution can be symmetrical, right-skewed, left-skewed, unimodal, or multimodal. Knowing the shape of the distribution helps us decide which statistical test is appropriate. For example, if the distribution is symmetrical, we could use a t-test or linear regression. However, if the distribution is skewed, we'd need to use the Mann-Whitney test or median regression. Moreover, when the data has several peaks, we might need to transform the data before analyzing it. Otherwise, when we calculate central tendencies like the average, we will heavily misrepresent reality. Histograms also help to identify outliers, which is very useful for cleaning the data. So, visualizing the distribution with histograms and density plots helps us avoid these pitfalls.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-08-23-histogramsdensityplots</guid>
      <pubDate>Sun, 01 Oct 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-08-23-histogramsdensityplots/thumbnail_hist_dens.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Epic Bar Plots with {ggplot2}</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-07-10-barplots</link>
      <description>Bar charts are useful for visualizing categorical data, group comparisons, and effective data communication through bar labels. In this video we'll learn the secrets of producing visually stunning bar charts using the {ggplot2} package.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-07-10-barplots</guid>
      <pubDate>Wed, 23 Aug 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-07-10-barplots/thumbnail_barplots.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {sjPlot} How to Easily Visualize Data And Model Results</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot</link>
      <description>One picture is worth a thousand words. That's why visualizing data and model results is a crutial skill for any data scientist. {sjPlot} package became my favorite tool for visualization. That's why I want to share with you some simple but very effective commands which will make you more productive today. So, let's visualize Wage dataset, visualize bunch of models and see what people earn and what factors determine the salary.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot</guid>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-08-01-sjplot/thumbnail_sjPlot.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>{dplyr} on Steroids: Handling Data Bases</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-05-09-datawrangling4</link>
      <description>If you know how to tidy up data within one table, you're already a skilled data scientist! However, as data continues to grow exponentially, taking your skills to the next level involves mastering the art of working with multiple tables within a database, typically done using SQL. In this post, we'll learn three essential techniques using {dplyr} that will allow you to handle databases with ease: merging multiple tables, reducing redundancy through table joins, and effortlessly modifying values within the resulting table.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-05-09-datawrangling4</guid>
      <pubDate>Fri, 14 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-05-09-datawrangling4/dplyr_4_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Quantile Regression as an useful Alternative for Ordinary Linear Regression</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression</link>
      <description>Ordinary linear regression often fails to correctly describe skewed or heteroscedastic data, totally srews up if data has outliers, and describes only the mean of the response variable. Quantile Regression promises to solve all these problems and delivers more results.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression</guid>
      <pubDate>Fri, 07 Jul 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression/thumbnail_quantile_regression.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Transform Your Data Like a Pro with {tidyr} and Say Goodbye to Messy Data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-04-18-datawrangling3</link>
      <description>Every data scientist dreams of creating beautiful visualizations, conducting complex modeling, and diving into machine learning methods. However, most of the time, messy data hinders our ability to do really cool stuff. Thus, tidying up the data is the key to unlocking your full potential. Unfortunately, reshaping data in Excel can be a tedious and error-prone task. Do you remember the time when you needed to quickly transform columns to rows or rows to columns, split or combine columns, or handle missing values? With the {tidyr} package, you'll be able to transform your data quickly, accurately, and efficiently, preparing yourself for the stuff that really matters ;)</description>
      <category>videos</category>
      <category>statistics</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-04-18-datawrangling3</guid>
      <pubDate>Tue, 09 May 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-04-18-datawrangling3/dplyr_3_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Advanced {dplyr}: 50+ Data Wrangling Techniques!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-02-07-datawrangling2</link>
      <description>Have you ever been frustrated with messy data that seems impossible to analyze? Or have you ever spend hours cleaning and transforming data before you could even start producing results? Well, no worries! In this blog-post, I'll show you &gt;50 Data Wrangling techniques, which will allow you to solve the most of your daily data manipulation challenges like a pro.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>data wrangling</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-02-07-datawrangling2</guid>
      <pubDate>Sun, 23 Apr 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-02-07-datawrangling2/dplyr_2_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Top 10 Must-Know {dplyr} Commands for Data Wrangling in R!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2023-01-31-datawrangling1</link>
      <description>The {dplyr} is one of the most useful R packages outthere. For me R is {dplyr} and {tidyverse}. So, here we'll use the most frequently used command.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>data wrangling</category>
      <guid>https://yuzar-blog.netlify.app/posts/2023-01-31-datawrangling1</guid>
      <pubDate>Sun, 05 Feb 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2023-01-31-datawrangling1/dplyr_1_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>{emmeans} Game-Changing R-package Squeezes Hidden Knowledge out of Models!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-11-29-emmeans</link>
      <description>{emmeans} is one of the most capable, but at the same time one of the most mysterious and therefore underrated R packages. Let's demistify {emmeans} and uncover it's power!</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-11-29-emmeans</guid>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-11-29-emmeans/thumbnail_emmeans_1.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Don't Ignore Interactions - Unleash the Full Power of Models with {emmeans} R-package</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-12-29-emmeans2interactions</link>
      <description>Analysing interactions is both (1) very challenging, that's why it's rarely executed, and (2) very rewording if done well, that's why it's still sometimes attempted. {emmeans} is one of the few packages which demistify interactions and extract the most knowledge out of statistical models!</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-12-29-emmeans2interactions</guid>
      <pubDate>Tue, 31 Jan 2023 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-12-29-emmeans2interactions/thumbnail_emmeans_2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {gtsummary} Publication-Ready Tables of Data, Stat-Tests and Models!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-10-31-gtsummary</link>
      <description>{gtsummary} package helps to easily produce publication-ready &amp; beautifully formatted summary tables of Data, Statistical Tests and Models! It calculates tons of statistics and has a beautiful design by default, but you can customize every aspect of your table and export it as a picture or MS Word format.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-10-31-gtsummary</guid>
      <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-10-31-gtsummary/thumbnail_gtsummary.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Publication-Ready Tables of Particular Statistical Tests and Models with {gtsummary}</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-11-25-gtsummary2</link>
      <description>Find a review of incredibly useful {gtsummary} package in a separate blog-post. Here I'll just collect all the possible Statsitcal Tests and Models, {gtsummary} can help with.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-11-25-gtsummary2</guid>
      <pubDate>Tue, 29 Nov 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-11-25-gtsummary2/thumbnail_gtsummary2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {rsample} Effective Resampling for Machine Learning!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-10-27-rsample</link>
      <description>Let's learn how to use three most important resampling techniques: train-test split, cross-validation and bootstrapping. We'll start with the question...</description>
      <category>videos</category>
      <category>statistics</category>
      <category>models</category>
      <category>machine learning</category>
      <category>tidymodels</category>
      <category>R package reviews</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-10-27-rsample</guid>
      <pubDate>Sun, 06 Nov 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-10-27-rsample/thumbnail_rsample.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>4 Reasons Non-Parametric Bootstrapped Regression (with tidymodels) is Better th–∞n Ordinary Regression</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions</link>
      <description>If the assumptions of parametric models can be satisfied, parametric models are the way to go. However, there are often many assumptions and to satisfy them all is rarely possible. Data transformation or using non-parametric methods are two solutions for that. In this post we'll learn the Non-Parametric Bootstrapped Regression as an alternative for the Ordinary Linear Regression in case when assumptions are violated.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions</guid>
      <pubDate>Fri, 07 Oct 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-08-31-bootstrappingregressions/thumbnail_bootstrapped_regression.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Repeated Measures ANOVA (One-Way) | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</link>
      <description>Can sport increase our selfesteem? Well, one experiment measured self-esteem of 10 people on three different time points and used Repeated Measures ANOVA to answer this question. So, let's learn how to produce this statistically rich plot using only one simple command and how to interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</guid>
      <pubDate>Wed, 05 Oct 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo| Many Models with Nested (Grouped) Data Easily</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels</link>
      <description>In this blog-post, we'll learn how to produce grouped / nested models, with an amazing "map()" function from {purrr} package in R. We'll use linear models in this example for the sake of simplicity, but you can apply any model you want (robust, logistic, poisson etc.). We'll see, how to effectively store and use the information from multiple models. And while in this blog-post we'll produce "only" 10 models, you can produce any number of models you want.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels</guid>
      <pubDate>Thu, 22 Sep 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-09-12-manymodels/thumbnail_many_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Robust Regression (don't depend on influential data!)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression</link>
      <description>Linear regression can be very sensitive to unusual data, like outliers, high leverage observations or a combination of both. A robust regression suppose to provide a solution for that. So, let's build both an ordinary and a robust regressions, compare them to find out whether outliers are a serious problem and see whether robust model performs better then usual linear model.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>visualization</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression</guid>
      <pubDate>Sun, 11 Sep 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-09-02-robustregression/thumbnail_robust.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {report} How To Report Statistical Results!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-06-18-report</link>
      <description>If you ever wandered how to correctly describe the results of statistical tests and models, this blog is for you. In a few minutes you'll learn how to report the results of correlations, t-tests, Generalised Linear Models, Mixed-Effects models, Bayesian Models and even more üòâ So, let's start with a simple t-test.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-06-18-report</guid>
      <pubDate>Mon, 11 Jul 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-06-18-report/thumbnail_report.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {glmulti} find the best model!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</link>
      <description>‚ÄúAll models are wrong, some are useful‚Äù - said a statistician George Box. And he was right. Thus, in this post we'll find the set of very useful models from the set of all possible models and will be able to choose THE MOST USEFUL model which adressed all our questions.</description>
      <category>videos</category>
      <category>statistics</category>
      <category>machine learning</category>
      <category>R package reviews</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti</guid>
      <pubDate>Thu, 09 Jun 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-05-31-glmulti/thumbnail_glmulti.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Tidy Data and Why We Need It!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</link>
      <description>Tidy data are easy to manipulate, visualise and analyse, while messy data always interrupts the analysis and invates mistakes. So, tidying up data before analysis pays off a great deal in the long term. In this post you'll learn how do we tidy up data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</guid>
      <pubDate>Mon, 23 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata/tidydata_2.jpeg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | ANOVA (One-Way ) | Fisher's, Welch's, Bayesian, Robust</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</link>
      <description>How does education influence our salary? ANOVA which is just the abbreviation for Analysis Of Variances you see on the thumbnail answeres this question with Frequentists and Bayesian tests. It also privides two different effect sizes, compares education levels pairwisely and even corrects p-values for multiple comparisons. ALL OF THAT is done by this simple command. So, in this blog-post you'll learn how to produce the statistically rich plot, you'll understand when to conduct Welch's ANOVA and when Fisher's ANOVA and you'll know how to interpret every little detail on this plot. Lets get into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-03-anova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Kruskal-Wallis test | How to conduct, visualize, interpret &amp; more üòâ</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</link>
      <description>If we have ordinal or not-normally distributed data, ANOVA might produce a wrong result. That's why we need Kruskal-Wallis test. Kruskal-Wallis test you see on the screen answers two question (1) whether at least one group is different from other groups and (2) between which groups exactly this difference is. So, let's learn how to get and interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</guid>
      <pubDate>Mon, 16 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-13-kw/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Cochran‚Äôs Q Test + Pairwise McNemar Tests (post-hoc)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</link>
      <description>Cochran test is an extension of the McNemar test for comparing MORE than two PAIRED categorical samples in which the same individuals appear in each sample. If Cochran test is significant, we'd need to compare samples among each other pairwisely with McNemar tests. So, let's do that.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</guid>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-04-cochran/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Mann-Whitney U Test = Wilcoxon Rank Sum Test | How to conduct, visualise &amp; interpret ü•≥ What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</link>
      <description>Comparing two groups with not-normally disctributed or ordinal data is the reason we need Mann-Whitney U Test instead of t-Test. So, today we'll learn (1) how to conduct and visualize Mann-Whitney U Test you saw on the thumbnail with one simple command, (2) how to interpret all statistical results on that plot and (3) why this test is sometimes called Wilcoxon Rank Sum Test and why we shouldn't use this name</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</guid>
      <pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Correlation Matrix | Danger or opportunity?</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</link>
      <description>Having several numeric variables, we often wanna know which of them are correlated and how. Correlation Matrix seems to be a good solution for it. But drawing conclusions from plain correlation coeffitients and p-values is dangerous, if we don't visualize the data. Let's learn a better way to produce a correlation matrix.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</guid>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Two-Samples t-Test | Student's &amp; Welch's | How to conduct, visualise, interpret | What happens if we use a wrong test üò±</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</link>
      <description>Two-samples t-test can answer useful questions, for example - where can we get more money, working in a factory or in the IT-industry? So, let's learn (1) how to make sure t-test is a CORRECT test for our data, (2) how to get all these results with one simple command, (3) how to interpret all these results and (4) finally see what happens if we choose a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</guid>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples t-Test | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</link>
      <description>Can one week of training significantly improve your number of sit-ups? Well, Paired t-Test can answer this question by comparing your performance Before and After this week. So, let's learn how to produce this statistically rich plot using only one simple command, how to interpret all these results and see what happens if we use a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</guid>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | McNemar Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</link>
      <description>If you need to compare two PAIRED categorical samples, McNemar test is a correct choise for you. Though, people often use Chi-Square test instead. Thus, in this blog-post we'll first conduct, visualize and interpret McNemac test you see on the picture to your right using only one simple command and then see what happens if we use Chi-Square test for paired data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</guid>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Friedman Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</link>
      <description>The Friedman Test is a non-parametric brother of Repeated Measures ANOVA, which does much better job when data is not-normally distributed (which happens pretty often ;). Friedman test is also superior to Repeated Measures ANOVA when our data is ordinal (e.g., scales from 1 to 10). Friedman Test can also be a non-parametric father of the Paired Wilcoxon test, because it can compare more then two groups.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</guid>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-08-friedman/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples Wilcoxon Signed Rank Test</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</link>
      <description>Can a speed-reading exercise make you a faster reader? Well, Wilcoxon Signed Rank Test displayed here is a correct test to answer this question. So, in this video we'll learn how to choose a correct test and what happens if we use a wrong test, why Wilcoxon test is called Signed Rank and how to produce and interpret this statistically rich plot using only one simple command.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</guid>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Correlation Analysis in R | Pearson, Spearman, Robust, Bayesian | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</link>
      <description>Having two numeric variables, we often wanna know whether they are correlated and how. One simple command {ggscatterstats} can answer both questions by visualizing the data and conducting frequentists and bayesian correlation analysis at the same time. So, let's learn how to do that, how to interpret all those results and how to choose the right correlation method in the first place.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</guid>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>One-sample Student‚Äôs t-test and One-sample Wilcoxon test: or how to compare your work to the work of others.</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</link>
      <description>Imagine you get 7 out of 10 to-dos from your list done on average. Are you then more productive then others? One-sample t-test and One-sample Wilcoxon test can answer this question. So, in this blog-post you'll learn how to conduct and visualize these tests with only one simple command, how to interpret all these results and how to choose the right test in the first place. Let's get straight into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</guid>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Chi-Square Test | how to conduct, visualize &amp; interpret | + pairwise post-hoc tests</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</link>
      <description>Chi-Square Test checks the independence between two categorical variables, where variables can have two or more categories. Need to do Chi-Square test? It can actually be done with only one line of code. There is no better way than {ggbarstats} function from {ggstatsplot} package üì¶. In this short blog-post you'll learn how to conduct, visualize and interpret Chi-Square test &amp; pairwise post-hoc tests in R.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</guid>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {dlookr} diagnose, explore and transform your data</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</link>
      <description>Raw data need to be diagnosed for existing problems, explored for new hypotheses and repaired in order to increase data quality and output. The {dlookr} package makes these steps fast and easy. {dlookr} generates automated reports and performs compex operations, like imputing missing values or outliers, with simple functions. Moreover, {dlookr} collaborates perfectly with {tidyverse} packages, like {dplyr} and {ggplot2} to name just a few!</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</guid>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data/dlookr_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Deep Exploratory Data Analysis (EDA) in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</link>
      <description>Exploratory Data Analysis is an important first step on the long way to the final result, be it a statistical inference in a scientific paper or a machine learning algorithm in production. This long way is often bumpy, highly iterative and time consuming. However, EDA might be the most important part of data analysis, because it helps to generate hypothesis, which then determine THE final RESULT. Thus, in this post I'll provide the simplest and most effective ways to explore data in R, which will significantly speed up your work. Moreover, we'll go one step beyond EDA by starting to test our hypotheses with simple statistical tests.</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress/DEDA_thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>How to impute missing values with Machine Learning in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</link>
      <description>Imputation simply means - replacing a missing value with a value that makes sense. But how can we get such values? Well, we'll use Machine Learning algorithms, because they have a high prediction power. So, in this post we'll learn how to impute missing values easily and effectively.</description>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r/thumbnail_missing_values.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Null Hypothesis, Alternative Hypothesis and Hypothesis Testing</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</link>
      <description>Hypothesis testing is one of the most important concepts in (frequentiest) statistics and science. However, most people who test hypotheses are scientists, but not statisticians. That's why scientists often do not test hypotheses properly, without any bad intension—Å. So, in this blog-post we'll break down hypothesis testing in small parts and try to properly understand every of them.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>What is p-value and why we need it</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</link>
      <description>Why do we need p-values? Well, they help to **make decisions** and **answer the question whether we found something new or not**. But despite the fact that **p-values are** actually **useful**, they are **far from perfect**! And while everyone uses p-values, understanding them (and using them correctly) is very hard. The definition of the p-value from the book is often correct but rarely intuitive. Intuitive explanations are often not entirely correct. So, in this blog-post (and video) we‚Äôll start with an intuitive (and not entirely correct) definition and will gradually build up the understanding of the p-value step by step. Thus, I don‚Äôt recommend to skip any part of this blog (or video). We‚Äôll also talk about how to use and interpret p-values correctly in order to **make better decisions and better science**.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {DataExplorer} explore your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</link>
      <description>What is the best way to explore the data quick? I think it's visualization. And what it the best way to visualize the data quick? I think it's - {DataExplorer} package, because it can visualize all your data in seconds using only one function! Check this out...</description>
      <category>R package reviews</category>
      <category>EDA</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data/2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 2: parametric survival models</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</link>
      <description>The non-parametric Kaplan-Meier method (KM) can not describe survival probability by a smooth function, which means it can not predict anything. The parametric models (e.g. Exponential, Weibull etc.) can! Besides, in case where parametric models are appropriate, they are more exact, more effective and more informative than KM or Cox. However, unfortunately, this step is often left out due to the rear use of parametric models. In this post we‚Äôll try to close this gap.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models/thumbnail_survival_2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {performance} check how good your model is! </title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</link>
      <description>There are several indicators of model quality, e.g. $R^2$ or AIC, and several assumption for every model which supposed to be checked, e.g. normality of residuals, multicollinearity etc.. R provides solutions for every indicator or assumption you can imagine. However, they are usually spread around different packages and functions. {performance} package brings all of quality indicators and all of the assumption under one roof. Thus, for me it became the one-stop solution for modelling.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is/14.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 1: a gentle introduction into Kaplan-Meier Curves</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</link>
      <description>Survival time analysis is necessary in any study which investigates the time to a particular outcome of interest. Cancer studies in the medicine and the first failure of the car in the engineering field (failure time analysis) are good examples. The outcome of interest could be death, remission to relapse, progression, or failure. Point in time of reaching that outcome is generally called the event. Thank goodness, not every ‚Äúevent‚Äù is fatal üòÉ, but can sometimes even be a favorable outcome such as discharge from hospital. And thus, survival analysis is also a generic term, because it is not only about survival.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves/thumbnail_survival_1.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {janitor} clean your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</link>
      <description>Data Scientists spend up to 80% of their time cleaning and preparing data for analysis. " Happy families are all alike; every unhappy family is unhappy in its own way" ‚Äî Leo Tolstoy. "Like families, tidy datasets are all alike but every messy dataset is messy in its own way" - Hadley Wickham. Thats when "janitor" helps to clean the mess.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</guid>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data/11.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to visualize models, their assumptions and post-hocs</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</link>
      <description>A picture is worth a thousand words! This article shows how to visualize results of 16 different models in R: from a simple linear model to a multiple-additive-non-linear-mixed-effects model. Among them are logistic, multinomial, additive and survival models with and without interactions. **Goal: minimum R code &amp; maximum output!** We'll also go a bit beyond only model visualization. So, don't miss the bonuses üòâ.</description>
      <category>visualization</category>
      <category>videos</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</guid>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs/thumbnail_visualize_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to create a blog or a website in R with {Distill} package</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</link>
      <description>If you're not online, you don't exist. A personal webpage or a blog became the business card of the digital century. It shows who you are and what you are capable of. Thus: show, don't tell.</description>
      <category>R &amp; the Web</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</guid>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package/images/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
  </channel>
</rss>
