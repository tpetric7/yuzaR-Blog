<?xml version="1.0" encoding="UTF-8"?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:distill="https://distill.pub/journal/" version="2.0">
  <channel>
    <title>yuzaR-Blog</title>
    <link>https://yuzar-blog.netlify.app/</link>
    <atom:link href="https://yuzar-blog.netlify.app/index.xml" rel="self" type="application/rss+xml"/>
    <description>Data Science with R
</description>
    <generator>Distill</generator>
    <lastBuildDate>Thu, 05 May 2022 00:00:00 +0000</lastBuildDate>
    <item>
      <title>R demo | Kruskal-Wallis test | How to conduct, visualize, interpret &amp; more 😉</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</link>
      <description>If we have ordinal or not-normally distributed data, ANOVA might produce a wrong result. That's why we need Kruskal-Wallis test. Kruskal-Wallis test you see on the screen answers two question (1) whether at least one group is different from other groups and (2) between which groups exactly this difference is. So, let's learn how to get and interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-13-kw</guid>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-13-kw/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Tidy data (in progress, but really in progress mate ;)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</link>
      <description>Tidy datasets are easy to manipulate, visualise, analyse and they don't interrapt the process. It's like not cooking three dished upfront for the dinner, but preparing one, eating it then needing to get up and cook again, before you continue eating. So, tidying up your data requires some upfront work, but that work pays off in the long term.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-22-tidydata</guid>
      <pubDate>Thu, 05 May 2022 00:00:00 +0000</pubDate>
    </item>
    <item>
      <title>R demo | ANOVA (One-Way ) | Fisher's, Welch's, Bayesian, Robust</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</link>
      <description>


&lt;h2 id="this-post-as-a-video"&gt;This post as a video&lt;/h2&gt;
&lt;p&gt;I recommend to watch a video first, because I highlight things I talk
about. It’s ca. 8 minutes long.&lt;/p&gt;
&lt;div class="vembedr"&gt;
&lt;div&gt;
&lt;iframe src="https://www.youtube.com/embed/JDGtLG0Tceo" width="533" height="300" frameborder="0" allowfullscreen="" data-external="1"&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;h2 id="previous-topics"&gt;Previous topics&lt;/h2&gt;
&lt;p&gt;&lt;a
href="https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/"&gt;Two-Samples
t-Test&lt;/a&gt; would help.&lt;/p&gt;
&lt;h2 id="get-the-data"&gt;Get the data&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;# install.packages(&amp;quot;tidyverse&amp;quot;)  # for everything ;)
library(tidyverse)

#install.packages(&amp;quot;ISLR&amp;quot;)
library(ISLR)

set.seed(4)  # for reproducibility
d &amp;lt;- Wage %&amp;gt;% 
  group_by(education) %&amp;gt;% 
  sample_n(30)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;{ISLR} package provides a {Wage} dataset, with salaries for 5
different educational groups, starting with people who did not finish a
high school and ending with people having university or doctoral degree.
We’ll sample 30 random people from every group and compare their AVERAGE
salaries. But wait, &lt;strong&gt;is average&lt;/strong&gt; actually a good choice?
That question is very important, because comparing averages only makes
sense if the data is normally distributed. While if data is not-normally
distributed, an average would not represent our data well and ANOVA
would be a wrong test - producing wrong result. Kruskal-Wallis test
would be better for not normally distributed data, but that’s a topic
for another blog-post.&lt;/p&gt;
&lt;h2 id="check-normality"&gt;Check normality&lt;/h2&gt;
&lt;p&gt;For now, it’s obvious that we NEED to check for normality. For that
we’ll use the {normality} function from {dlookr} package, which conducts
Shapiro-Wilk normality tests with every educational group. High p-values
in all groups indicate that our data IS normally distributed, so now we
are sure that using &lt;strong&gt;ANOVA&lt;/strong&gt; is a right choice.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/not_normal.png" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# install.packages(&amp;quot;dlookr&amp;quot;)
library(dlookr)
d %&amp;gt;% 
  group_by(education) %&amp;gt;% 
  normality(wage) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 5 × 5
  variable education          statistic p_value sample
  &amp;lt;chr&amp;gt;    &amp;lt;fct&amp;gt;                  &amp;lt;dbl&amp;gt;   &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt;
1 wage     1. &amp;lt; HS Grad           0.966  0.427      30
2 wage     2. HS Grad             0.972  0.606      30
3 wage     3. Some College        0.980  0.814      30
4 wage     4. College Grad        0.965  0.412      30
5 wage     5. Advanced Degree     0.941  0.0942     30&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="check-homogeneity-of-variances-homoscedasticity"&gt;Check
Homogeneity of Variances (Homoscedasticity)&lt;/h2&gt;
&lt;p&gt;However, the normality alone is not enough to make a right decision,
because there are two different ANOVAs: &lt;strong&gt;Fisher’s ANOVA&lt;/strong&gt;
for similar variances across groups and &lt;strong&gt;Welch’s ANOVA&lt;/strong&gt;
for different variances across groups. In fact, the variance is sooo
important that it’s even part of the name, were &lt;strong&gt;Analysis Of
Variances&lt;/strong&gt; compares the &lt;strong&gt;variances between the
groups&lt;/strong&gt; to the &lt;strong&gt;variances within the groups&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;It’s also important, because (1) even very different means with huge
variance (samples a and b) may not be significantly different (p = 0.1)
while (2) even very similar means with small variance (samples c and d)
can be significantly different (p = 0.04). And a classic - Fisher’s
ANOVA can only be applied when variances are similar! While groups with
different variances (samples b and c) should be analyzed with Welch’s
ANOVA.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/huge_variance.jpg" style="width:45.0%" /&gt; &lt;img
src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/small_variance.jpg" style="width:45.0%" /&gt;&lt;/p&gt;
&lt;p&gt;Levene’s Test for Homogeneity of Variance helps to decide which ANOVA
to use. A small p-value of Levene’s Test tells us that our variances
differ and that we need to use Welch’s ANOVA.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;#install.packages(&amp;quot;car&amp;quot;)
library(car)
leveneTest(wage ~ education, d)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Levene&amp;#39;s Test for Homogeneity of Variance (center = median)
       Df F value    Pr(&amp;gt;F)    
group   4  8.4462 3.737e-06 ***
      145                      
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, having checked both, Normality and Homogeneity of Variance
assumptions, we are ready to compute Welch’s ANOVA.&lt;/p&gt;
&lt;h2 id="compute-anova"&gt;Compute ANOVA&lt;/h2&gt;
&lt;p&gt;And the best way to compute ANOVA is the {ggbetweenstats} function
from {ggstatsplot} package, which needs only 5 arguments:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;first, &lt;strong&gt;our data&lt;/strong&gt; - d, with&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;x-axes&lt;/strong&gt; - having grouping variable - education,
and&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;y-axes&lt;/strong&gt; - having salaries&lt;/li&gt;
&lt;li&gt;then, since our data is normally distributed, we’ll choose a
&lt;strong&gt;parametric type&lt;/strong&gt; of statistical approach,&lt;/li&gt;
&lt;li&gt;and since our education groups have different variances, we set
&lt;strong&gt;var.equal&lt;/strong&gt; argument to &lt;strong&gt;FALSE&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# install.packages(&amp;quot;ggstatsplot&amp;quot;)
library(ggstatsplot)

set.seed(4)   # for Bayesian reproducibility of 95% CIs
ggbetweenstats(
  data = d,
  x    = education, 
  y    = wage, 
  type = &amp;quot;parametric&amp;quot;, 
  var.equal = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file8801eca1ba8_files/figure-html/unnamed-chunk-5-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# you can save the picture in the format and size of your choice
ggsave(filename = &amp;quot;anova.jpg&amp;quot;, plot = last_plot(), width = 8, height = 7)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Such simple command results in this statistically rich and
publication ready plot! Now, let’s interpret the results.&lt;/p&gt;
&lt;h2 id="interpret-the-result"&gt;Interpret the result&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;strong&gt;Welch’s F-statistics&lt;/strong&gt; is the reason ANOVA is
called Analysis of Variances, because F is a ratio of the
&lt;strong&gt;variance between groups&lt;/strong&gt; to the &lt;strong&gt;variance withing
groups&lt;/strong&gt;. If that ratio is close to one, samples are similar, and
the further &lt;em&gt;F-value&lt;/em&gt; is from one, the more different are the
samples. But &lt;strong&gt;F-value&lt;/strong&gt; by itself can not say how far from
one is far enough, to conclude that this difference is significant.
That’s why &lt;strong&gt;F-value&lt;/strong&gt; and the degrees of freedom were
previously used to get a &lt;strong&gt;p-value&lt;/strong&gt;. But nowadays every
software delivers both F and p-values by default. That is why nowadays
nobody calculates F values anymore, but if you wanna know how to
calculate it, check out the chapter on that below.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;our very small &lt;strong&gt;P-value&lt;/strong&gt; shows a very strong
evidence against the null hypothesis (H&lt;sub&gt;0&lt;/sub&gt;), that mean salaries
are similar, in favor of the alternative hypothesis (H&lt;sub&gt;Alt&lt;/sub&gt;),
that mean salaries differ. However, a significant P-value only tells you
that a difference between groups definitely exists and did not happen
just by chance, but a p-value can not tell how large this difference
is.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/p_value_interpretation.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fortunately, {ggbetweenstats} provides &lt;strong&gt;partial omega
squared&lt;/strong&gt; with 95% Confidence Intervals as the measure of the
&lt;strong&gt;Effect Size&lt;/strong&gt; for ANOVA. The {interpret_omega_squared}
function from {effectsize} package helps to interpret this effect size
and even provides a reference. Our effect size of 0.34 indicates that
the &lt;strong&gt;effect of education on salaries is large&lt;/strong&gt;. For
example a person who invested a lot of years and effort into studying
earns twice as much on average, as the person who did not even finish a
high school. So, the effect size makes total sense to me.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;# install.packages(&amp;quot;effectsize&amp;quot;)
library(effectsize)

interpret_omega_squared(0.34)&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;large&amp;quot;
(Rules: field2013)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# ?interpret_omega_squared&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/interpret_omega_squared.png" style="width:50.0%" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;But that’s not all, {ggbetweenstats} also provides a
&lt;strong&gt;Bayesian Effect Size&lt;/strong&gt;, namely the &lt;strong&gt;coefficient of
determination&lt;/strong&gt; - &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; with
95% Highest Density Intervals. &lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt;
shows the &lt;strong&gt;explanatory power&lt;/strong&gt; of our ANOVA model and
&lt;span class="math inline"&gt;\(R^2\)&lt;/span&gt; of 27% is substantial, which
means - we can totally trust these results.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;interpret_r2(0.27)
# ?interpret_r2&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/interpret_r_squared.png" style="width:50.0%" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Moreover, the &lt;strong&gt;Bayes Factor&lt;/strong&gt;, which is conceptually
similar to the &lt;strong&gt;p-value&lt;/strong&gt; indicates an &lt;strong&gt;extreme
evidence for the alternative hypothesis&lt;/strong&gt; - that education does
affect wages … which IS in line with a p-value on the top of the
plot.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="r"&gt;&lt;code&gt;interpret_bf(exp(-17.13))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] &amp;quot;extreme evidence against&amp;quot;
(Rules: jeffreys1961)&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;# ?interpret_bf&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/bf_interpretation.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;now, both, &lt;strong&gt;Bayes Factor&lt;/strong&gt; and
&lt;strong&gt;p-value&lt;/strong&gt; tell us that a difference between groups
exists, however, they don’t show between which groups exactly. That’s
why we need to compare every education category to every other education
category pairwisely.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;and luckily for us {ggbetweenstats} &lt;strong&gt;automatically knows
that we need Games-Howell pairwise Tests for a significant Welch’s
ANOVA, conducts those tests, displays p-values and even corrects these
p-values for multiple comparisons without any additional code&lt;/strong&gt;.
How cool is that!&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://yuzar-blog.netlify.app//posts/2022-04-03-anova/what-dog.gif" style="width:50.0%" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;by the way, our two global tests are often called with a strange
name - &lt;strong&gt;omnibus test&lt;/strong&gt;, while the pairwise tests between
time-points, are sometimes described in a dead Latin language as -
&lt;strong&gt;post-hoc&lt;/strong&gt; - which in English means - &lt;strong&gt;after the
event&lt;/strong&gt;. So many unnecessary names just confuse people and I hate
that. A test we are learning about right now is called &lt;strong&gt;ONE-WAY
ANOVA&lt;/strong&gt; simply because these is only one categorical variable -
education. But there is no one-way regression, or one-way t-test …&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="customise-the-result"&gt;Customise the result&lt;/h2&gt;
&lt;p&gt;However, if we want to, we can easily customize the results by using
either additional code within the function, or code from {ggplot2}
package outside of it. For example,&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;if you found outliers in your data, you can display them on the plot
and&lt;/li&gt;
&lt;li&gt;use a &lt;strong&gt;robust ANOVA&lt;/strong&gt; to minimize the effect of
outliers,&lt;/li&gt;
&lt;li&gt;here again, the function automatically uses correct &lt;strong&gt;Yuen’s
trimmed means pairwise tests&lt;/strong&gt; for this &lt;strong&gt;robust
ANOVA&lt;/strong&gt; and corrects p-values for multiple comparisons with a
Holm method,&lt;/li&gt;
&lt;li&gt;which you can easily change to a more famous &lt;strong&gt;Bonferroni
correction&lt;/strong&gt; … but I wouldn’t recommend it, because Bonferroni
correction is too conservative and miss an important discovery. And
that’s exactly what happens with our robust ANOVA, the bonferroni
correction finds only 6 instead of 8 significant pairwise
comparisons.&lt;/li&gt;
&lt;li&gt;then, if you want to display &lt;strong&gt;not only significant&lt;/strong&gt;,
but &lt;strong&gt;all comparisons&lt;/strong&gt;,&lt;/li&gt;
&lt;li&gt;if you want to hide either Frequentists or Bayesian statistics, or
both…&lt;/li&gt;
&lt;li&gt;or change the appearance of your plot&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;… you can easily do that and much more. Just ask R about
{ggbetweenstats} by writing a question mark in front of the function and
try some things out, I am sure you’ll enjoy it.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggbetweenstats(
  data = d,
  x    = education, 
  y    = wage, 
  outlier.tagging = T,
  type = &amp;quot;robust&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file8801eca1ba8_files/figure-html/unnamed-chunk-9-1.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;ggbetweenstats(
  data = d,
  x    = education, 
  y    = wage, 
  outlier.tagging = T,
  type = &amp;quot;robust&amp;quot;, 
  p.adjust.method = &amp;quot;bonferroni&amp;quot;, 
  pairwise.display = &amp;quot;all&amp;quot;,
  results.subtitle = F,
  bf.message = F
) + 
  ylab(&amp;quot;pay check&amp;quot;)+
  theme_classic()+
  theme(legend.position = &amp;quot;top&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file8801eca1ba8_files/figure-html/unnamed-chunk-9-2.png" width="672" /&gt;&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;?ggbetweenstats&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But what you could enjoy even more is the &lt;strong&gt;Repeated Measures
ANOVA&lt;/strong&gt;, which you would use if you followed a destiny of the
same 30 people throughout their life and see whether their wage increase
every time they step up their education.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;set.seed(1)   # for Bayesian reproducibility of 95% CIs
ggwithinstats(
    data = d,
    x    = education, 
    y    = wage, 
    type = &amp;quot;parametric&amp;quot;, 
    var.equal = FALSE)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src="file8801eca1ba8_files/figure-html/unnamed-chunk-10-1.png" width="672" /&gt;&lt;/p&gt;
&lt;h2 id="a-little-bit-of-theory-about-anova"&gt;A little bit of theory about
ANOVA&lt;/h2&gt;
&lt;p&gt;The variance between groups can be easily calculated by the variance
of the group means multiplied by the number of observations per group.
The within group variance is also called &lt;strong&gt;residual
variance&lt;/strong&gt; (or “error”), because it is what is left when the
group effect is removed. That can be confusing, because there is nothing
erroneous about within group variance (real biological variance among
individuals).&lt;/p&gt;
&lt;p&gt;For unequal group sized or unequal variances (Welch’s ANOVA) the
calculation get more complex, but there is no need to get there, if you
understood the “classic” case below, because all of those calculations
are done by computer.&lt;/p&gt;
&lt;p&gt;The among-group degrees of freedom is the number of groups minus one.
The within-groups degrees of freedom is the total number of
observations, minus the number of groups.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;# overall sums of squares
d %&amp;gt;% 
  ungroup() %&amp;gt;% 
  mutate(squares = (wage - mean(d$wage))^2) %&amp;gt;% 
  summarise(overall_ss   = sum(squares))&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 1 × 1
  overall_ss
       &amp;lt;dbl&amp;gt;
1    287217.&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;means &amp;lt;- d %&amp;gt;% 
  group_by(education) %&amp;gt;% 
  summarise(n = n(), 
            means = mean(wage))

d &amp;lt;- left_join(d, means)

# wgss - within groups sum of squares
wgvar &amp;lt;- d %&amp;gt;% 
  mutate(squares = (wage - means)^2) %&amp;gt;% 
  #group_by(education) %&amp;gt;% # already grouped before
  summarise(wgss   = sum(squares)) %&amp;gt;%    # wgss - within groups sum of squares
  summarise(ss_total = sum(wgss)) %&amp;gt;% 
  mutate(df = dim(d)[1] - length(unique(d$education))) %&amp;gt;% 
  mutate(var = ss_total / df ) %&amp;gt;% 
  mutate(variance_type = &amp;quot;withing groups variance&amp;quot;) # wgvar - within group or residual variance

## between groups sums of squares
bgvar &amp;lt;- means %&amp;gt;% 
  mutate(sample_mean = mean(d$wage)) %&amp;gt;% 
  mutate(ss = n*(sample_mean - means)^2) %&amp;gt;% 
  summarise(ss_total = sum(ss)) %&amp;gt;% 
  mutate(df = length(unique(d$education))-1) %&amp;gt;% 
  mutate(var = ss_total / df ) %&amp;gt;% 
  mutate(variance_type = &amp;quot;between groups variance&amp;quot;)
  

# actually it goes easies
var(means$means)*30&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[1] 20741.91&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;rbind(bgvar, wgvar) %&amp;gt;% 
  mutate(F_value = var[1]/var[2])&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;# A tibble: 2 × 5
  ss_total    df    var variance_type           F_value
     &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;  &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;                     &amp;lt;dbl&amp;gt;
1   82968.     4 20742. between groups variance    14.7
2  204249.   145  1409. withing groups variance    14.7&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="old-way-to-conduct-anova-in-r"&gt;Old way to conduct anova in
R&lt;/h2&gt;
&lt;pre class="r"&gt;&lt;code&gt;aov(wage ~ education, d) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;             Df Sum Sq Mean Sq F value   Pr(&amp;gt;F)    
education     4  82968   20742   14.72 4.05e-10 ***
Residuals   145 204249    1409                     
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;oneway.test(wage ~ education, d, var.equal = FALSE) &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    One-way analysis of means (not assuming equal variances)

data:  wage and education
F = 10.78, num df = 4.000, denom df = 71.237, p-value =
6.877e-07&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="anova-t-test-linear-regression-check-this-out"&gt;ANOVA = t-test =
Linear Regression! Check this out…&lt;/h2&gt;
&lt;p&gt;For only two groups, ANOVA is exactly the same as the Student’s
t-test and, moreover, exactly the same as linear regression ;). Just
square the t-value from the t-test and you’ll get the F value from ANOVA
and regression.&lt;/p&gt;
&lt;pre class="r"&gt;&lt;code&gt;t.test(wage ~ jobclass, d) # square t-value to get F value&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
    Welch Two Sample t-test

data:  wage by jobclass
t = -2.1403, df = 127.16, p-value = 0.03424
alternative hypothesis: true difference in means between group 1. Industrial and group 2. Information is not equal to 0
95 percent confidence interval:
 -29.949638  -1.174623
sample estimates:
 mean in group 1. Industrial mean in group 2. Information 
                    107.2967                     122.8588 &lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;aov(wage ~ jobclass, d) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;             Df Sum Sq Mean Sq F value Pr(&amp;gt;F)  
jobclass      1   8978    8978   4.776 0.0304 *
Residuals   148 278238    1880                 
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1&lt;/code&gt;&lt;/pre&gt;
&lt;pre class="r"&gt;&lt;code&gt;lm(wage ~ jobclass, d) %&amp;gt;% summary()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;
Call:
lm(formula = wage ~ jobclass, data = d)

Residuals:
    Min      1Q  Median      3Q     Max 
-84.635 -26.013  -6.122  23.335 170.503 

Coefficients:
                       Estimate Std. Error t value Pr(&amp;gt;|t|)    
(Intercept)             107.297      4.759  22.545   &amp;lt;2e-16 ***
jobclass2. Information   15.562      7.121   2.185   0.0304 *  
---
Signif. codes:  0 &amp;#39;***&amp;#39; 0.001 &amp;#39;**&amp;#39; 0.01 &amp;#39;*&amp;#39; 0.05 &amp;#39;.&amp;#39; 0.1 &amp;#39; &amp;#39; 1

Residual standard error: 43.36 on 148 degrees of freedom
Multiple R-squared:  0.03126,   Adjusted R-squared:  0.02471 
F-statistic: 4.776 on 1 and 148 DF,  p-value: 0.03044&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="whats-next-or-when-not-to-use-repeated-measures-anova"&gt;What’s
next, or when not to use Repeated Measures ANOVA&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Repeated-Measures ANOVA&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Kruskal-Wallis if data is not-normally distributed&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr /&gt;
&lt;p&gt;If you think, I missed something, please comment on it, and I’ll
improve this tutorial.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Thank you for learning!&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="r distill-force-highlighting-css"&gt;&lt;code&gt;&lt;/code&gt;&lt;/pre&gt;</description>
      <distill:md5>c0858130391b7441e2b358654ae1a7c2</distill:md5>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-04-03-anova</guid>
      <pubDate>Wed, 04 May 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-04-03-anova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Repeated Measures ANOVA (One-Way) | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</link>
      <description>Can sport increase our selfesteem? Well, one experiment measured self-esteem of 10 people on three different time points and used Repeated Measures ANOVA to answer this question. So, let's learn how to produce this statistically rich plot using only one simple command and how to interpret all these results.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova</guid>
      <pubDate>Thu, 21 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-30-rmanova/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Cochran’s Q Test + Pairwise McNemar Tests (post-hoc)</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</link>
      <description>Cochran test is an extension of the McNemar test for comparing MORE than two PAIRED categorical samples in which the same individuals appear in each sample. If Cochran test is significant, we'd need to compare samples among each other pairwisely with McNemar tests. So, let's do that.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-04-cochran</guid>
      <pubDate>Wed, 20 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-04-cochran/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Mann-Whitney U Test = Wilcoxon Rank Sum Test | How to conduct, visualise &amp; interpret 🥳 What happens if we use a wrong test 😱</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</link>
      <description>Comparing two groups with not-normally disctributed or ordinal data is the reason we need Mann-Whitney U Test instead of t-Test. So, today we'll learn (1) how to conduct and visualize Mann-Whitney U Test you saw on the thumbnail with one simple command, (2) how to interpret all statistical results on that plot and (3) why this test is sometimes called Wilcoxon Rank Sum Test and why we shouldn't use this name</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest</guid>
      <pubDate>Sat, 16 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-16-mwutest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Correlation Matrix | Danger or opportunity?</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</link>
      <description>Having several numeric variables, we often wanna know which of them are correlated and how. Correlation Matrix seems to be a good solution for it. But drawing conclusions from plain correlation coeffitients and p-values is dangerous, if we don't visualize the data. Let's learn a better way to produce a correlation matrix.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr</guid>
      <pubDate>Fri, 01 Apr 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-05-correlationmatrixinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Two-Samples t-Test | Student's &amp; Welch's | How to conduct, visualise, interpret | What happens if we use a wrong test 😱</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</link>
      <description>Two-samples t-test can answer useful questions, for example - where can we get more money, working in a factory or in the IT-industry? So, let's learn (1) how to make sure t-test is a CORRECT test for our data, (2) how to get all these results with one simple command, (3) how to interpret all these results and (4) finally see what happens if we choose a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-03-11-ttest</guid>
      <pubDate>Tue, 22 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-03-11-ttest/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples t-Test | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</link>
      <description>Can one week of training significantly improve your number of sit-ups? Well, Paired t-Test can answer this question by comparing your performance Before and After this week. So, let's learn how to produce this statistically rich plot using only one simple command, how to interpret all these results and see what happens if we use a wrong test.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr</guid>
      <pubDate>Fri, 11 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-22-pairedsamplesttestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | McNemar Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</link>
      <description>If you need to compare two PAIRED categorical samples, McNemar test is a correct choise for you. Though, people often use Chi-Square test instead. Thus, in this blog-post we'll first conduct, visualize and interpret McNemac test you see on the picture to your right using only one simple command and then see what happens if we use Chi-Square test for paired data.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar</guid>
      <pubDate>Sat, 05 Mar 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-20-mcnemar/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Friedman Test | How to Conduct, Visualise and Interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</link>
      <description>The Friedman Test is a non-parametric brother of Repeated Measures ANOVA, which does much better job when data is not-normally distributed (which happens pretty often ;). Friedman test is also superior to Repeated Measures ANOVA when our data is ordinal (e.g., scales from 1 to 10). Friedman Test can also be a non-parametric father of the Paired Wilcoxon test, because it can compare more then two groups.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-02-08-friedman</guid>
      <pubDate>Sun, 20 Feb 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-02-08-friedman/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R demo | Paired Samples Wilcoxon Signed Rank Test</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</link>
      <description>Can a speed-reading exercise make you a faster reader? Well, Wilcoxon Signed Rank Test displayed here is a correct test to answer this question. So, in this video we'll learn how to choose a correct test and what happens if we use a wrong test, why Wilcoxon test is called Signed Rank and how to produce and interpret this statistically rich plot using only one simple command.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr</guid>
      <pubDate>Wed, 26 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2022-01-13-pairedsampleswilcoxonsigned-ranktestinr/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Correlation Analysis in R | Pearson, Spearman, Robust, Bayesian | How to conduct, visualise and interpret</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</link>
      <description>Having two numeric variables, we often wanna know whether they are correlated and how. One simple command {ggscatterstats} can answer both questions by visualizing the data and conducting frequentists and bayesian correlation analysis at the same time. So, let's learn how to do that, how to interpret all those results and how to choose the right correlation method in the first place.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr</guid>
      <pubDate>Mon, 03 Jan 2022 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-29-correlationinr/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>One-sample Student’s t-test and One-sample Wilcoxon test: or how to compare your work to the work of others.</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</link>
      <description>Imagine you get 7 out of 10 to-dos from your list done on average. Are you then more productive then others? One-sample t-test and One-sample Wilcoxon test can answer this question. So, in this blog-post you'll learn how to conduct and visualize these tests with only one simple command, how to interpret all these results and how to choose the right test in the first place. Let's get straight into it.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others</guid>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-20-one-sample-t-test-do-your-results-make-sense-or-how-to-compare-your-work-to-the-work-of-others/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R demo | Chi-Square Test | how to conduct, visualize &amp; interpret | + pairwise post-hoc tests</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</link>
      <description>Chi-Square Test checks the independence between two categorical variables, where variables can have two or more categories. Need to do Chi-Square test? It can actually be done with only one line of code. There is no better way than {ggbarstats} function from {ggstatsplot} package 📦. In this short blog-post you'll learn how to conduct, visualize and interpret Chi-Square test &amp; pairwise post-hoc tests in R.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r</guid>
      <pubDate>Mon, 20 Dec 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-12-14-how-to-conduct-chi-square-test-in-r/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {dlookr} diagnose, explore and transform your data</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</link>
      <description>Raw data need to be diagnosed for existing problems, explored for new hypotheses and repaired in order to increase data quality and output. The {dlookr} package makes these steps fast and easy. {dlookr} generates automated reports and performs compex operations, like imputing missing values or outliers, with simple functions. Moreover, {dlookr} collaborates perfectly with {tidyverse} packages, like {dplyr} and {ggplot2} to name just a few!</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>R package reviews</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data</guid>
      <pubDate>Sat, 30 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-30-r-package-reviews-dlookr-diagnose-explore-and-transform-your-data/dlookr_thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Deep Exploratory Data Analysis (EDA) in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</link>
      <description>Exploratory Data Analysis is an important first step on the long way to the final result, be it a statistical inference in a scientific paper or a machine learning algorithm in production. This long way is often bumpy, highly iterative and time consuming. However, EDA might be the most important part of data analysis, because it helps to generate hypothesis, which then determine THE final RESULT. Thus, in this post I'll provide the simplest and most effective ways to explore data in R, which will significantly speed up your work. Moreover, we'll go one step beyond EDA by starting to test our hypotheses with simple statistical tests.</description>
      <category>EDA</category>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-09-exploratory-data-analysis-and-beyond-in-r-in-progress/DEDA_thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>How to impute missing values with Machine Learning in R</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</link>
      <description>Imputation simply means - replacing a missing value with a value that makes sense. But how can we get such values? Well, we'll use Machine Learning algorithms, because they have a high prediction power. So, in this post we'll learn how to impute missing values easily and effectively.</description>
      <category>videos</category>
      <category>data wrangling</category>
      <category>visualization</category>
      <category>machine learning</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-03-04-how-to-impute-missing-values-in-r/thumbnail_missing_values.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Null Hypothesis, Alternative Hypothesis and Hypothesis Testing</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</link>
      <description>Hypothesis testing is one of the most important concepts in (frequentiest) statistics and science. However, most people who test hypotheses are scientists, but not statisticians. That's why scientists often do not test hypotheses properly, without any bad intensionс. So, in this blog-post we'll break down hypothesis testing in small parts and try to properly understand every of them.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-06-04-my-second-blog-postthis-one-will-be-really-good/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>What is p-value and why we need it</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</link>
      <description>Why do we need p-values? Well, they help to **make decisions** and **answer the question whether we found something new or not**. But despite the fact that **p-values are** actually **useful**, they are **far from perfect**! And while everyone uses p-values, understanding them (and using them correctly) is very hard. The definition of the p-value from the book is often correct but rarely intuitive. Intuitive explanations are often not entirely correct. So, in this blog-post (and video) we’ll start with an intuitive (and not entirely correct) definition and will gradually build up the understanding of the p-value step by step. Thus, I don’t recommend to skip any part of this blog (or video). We’ll also talk about how to use and interpret p-values correctly in order to **make better decisions and better science**.</description>
      <category>videos</category>
      <category>statistics</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation</guid>
      <pubDate>Sat, 09 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-07-31-p-value-intuitive-explanation/thumbnail.jpg" medium="image" type="image/jpeg"/>
    </item>
    <item>
      <title>R package reviews {DataExplorer} explore your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</link>
      <description>What is the best way to explore the data quick? I think it's visualization. And what it the best way to visualize the data quick? I think it's - {DataExplorer} package, because it can visualize all your data in seconds using only one function! Check this out...</description>
      <category>R package reviews</category>
      <category>EDA</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data/2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 2: parametric survival models</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</link>
      <description>The non-parametric Kaplan-Meier method (KM) can not describe survival probability by a smooth function, which means it can not predict anything. The parametric models (e.g. Exponential, Weibull etc.) can! Besides, in case where parametric models are appropriate, they are more exact, more effective and more informative than KM or Cox. However, unfortunately, this step is often left out due to the rear use of parametric models. In this post we’ll try to close this gap.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models</guid>
      <pubDate>Wed, 06 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-06-survival-analysis-2-parametric-survival-models/thumbnail_survival_2.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {performance} check how good your model is! </title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</link>
      <description>There are several indicators of model quality, e.g. $R^2$ or AIC, and several assumption for every model which supposed to be checked, e.g. normality of residuals, multicollinearity etc.. R provides solutions for every indicator or assumption you can imagine. However, they are usually spread around different packages and functions. {performance} package brings all of quality indicators and all of the assumption under one roof. Thus, for me it became the one-stop solution for modelling.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <category>visualization</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-r-package-reviews-performance-check-how-good-your-model-is/14.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>Survival analysis 1: a gentle introduction into Kaplan-Meier Curves</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</link>
      <description>Survival time analysis is necessary in any study which investigates the time to a particular outcome of interest. Cancer studies in the medicine and the first failure of the car in the engineering field (failure time analysis) are good examples. The outcome of interest could be death, remission to relapse, progression, or failure. Point in time of reaching that outcome is generally called the event. Thank goodness, not every “event” is fatal 😃, but can sometimes even be a favorable outcome such as discharge from hospital. And thus, survival analysis is also a generic term, because it is not only about survival.</description>
      <category>survival analysis</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves</guid>
      <pubDate>Sun, 03 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-03-survival-analysis-1-a-gentle-introduction-into-kaplan-meier-curves/thumbnail_survival_1.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>R package reviews {janitor} clean your data!</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</link>
      <description>Data Scientists spend up to 80% of their time cleaning and preparing data for analysis. " Happy families are all alike; every unhappy family is unhappy in its own way" — Leo Tolstoy. "Like families, tidy datasets are all alike but every messy dataset is messy in its own way" - Hadley Wickham. Thats when "janitor" helps to clean the mess.</description>
      <category>R package reviews</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data</guid>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-02-r-package-reviews-janitor-clean-your-data/11.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to visualize models, their assumptions and post-hocs</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</link>
      <description>A picture is worth a thousand words! This article shows how to visualize results of 16 different models in R: from a simple linear model to a multiple-additive-non-linear-mixed-effects model. Among them are logistic, multinomial, additive and survival models with and without interactions. **Goal: minimum R code &amp; maximum output!** We'll also go a bit beyond only model visualization. So, don't miss the bonuses 😉.</description>
      <category>visualization</category>
      <category>videos</category>
      <category>models</category>
      <guid>https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs</guid>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2021-01-01-how-to-visualize-models-their-assumptions-and-post-hocs/thumbnail_visualize_models.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
    <item>
      <title>How to create a blog or a website in R with {Distill} package</title>
      <dc:creator>Yury Zablotski</dc:creator>
      <link>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</link>
      <description>If you're not online, you don't exist. A personal webpage or a blog became the business card of the digital century. It shows who you are and what you are capable of. Thus: show, don't tell.</description>
      <category>R &amp; the Web</category>
      <category>videos</category>
      <guid>https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package</guid>
      <pubDate>Sat, 26 Dec 2020 00:00:00 +0000</pubDate>
      <media:content url="https://yuzar-blog.netlify.app/posts/2020-12-26-how-to-create-a-blog-or-a-website-in-r-with-distill-package/images/thumbnail.png" medium="image" type="image/png" width="1920" height="1080"/>
    </item>
  </channel>
</rss>
