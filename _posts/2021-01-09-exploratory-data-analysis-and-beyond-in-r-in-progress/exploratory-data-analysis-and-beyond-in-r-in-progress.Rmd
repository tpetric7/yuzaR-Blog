---
title: "Exploratory Data Analysis (EDA) and BEYOND in R: or one-stop solution for EDA in R (in progress)"
description: |
  Exploratory Data Analysis (EDA) is an important first step on the long way to the final result, be it statistical inference in a published scientific paper or a machine learning algorithm in production. This way between EDA and final result is often rocky, bumpy, annoying and highly iterative. However, EDA is sometimes the most important part of data analysis, because it helps to generate hypothesis, which then determine the final result. Unfortunatly EDA often remains unreported, simply because everyone focuses on the final result. So that we often don't know how EDA was conducted. Thus, in this article I'll provide the best (to my knowledge) ways to explore the data in R and go one step beyond the EDA towards generating hypotheses.
author:
  - name: Yury Zablotski
    url: https://yury-zablotski.netlify.app/
date: 01-09-2021
categories:
  - EDA
  - videos
preview: 1.png
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    code_download: true
---


```{r setup, include=FALSE, warning=F, message=F}
knitr::opts_chunk$set(echo = T)
```


```{r}
# install.packages("tidyverse")
# install.packages("DataExplorer")

library(tidyverse)        # for data wrangling and visualization
library(datasets)         # for getting the data 
library(ISLR)
library(DataExplorer)     # for exploratory data analysis
library(SmartEDA)         # for exploratory data analysis
library(skimr)            # for descriptive stats
library(PerformanceAnalytics)
library(ggstatsplot)
library(performance)
library(pastecs)
library(dlookr)
```
I love R, because it is reach and having ca. 17000 packages allows me to concur almost any data science problem. However, such abundance can be overwhelming, especially because one task can be accomplished by different functions from different packages with different levels of effectiveness. Looking for the most effective way can be very time consuming! So, I hope this collection will save you some time. And if you know better functions or packages for EDA, than those provided here, please let me know in the comments below and let us together create a one-stop solution for EDA in R.

## Creating visualised reports of the whole dataset with only one function!

The most effective way to explore the data fast is a creation of automated reports. [DataExplorer package](https://yuzar-blog.netlify.app/posts/2021-01-06-r-package-reviews-dataexplorer-explore-your-data/) creates the best reports in my opinion. [SmartEDA](https://daya6489.github.io/SmartEDA/) package is another good choice. 

### DataExplorer

```{r eval=F}
airquality <- airquality %>% 
  mutate(Month = factor(Month))

# report without a response variable
create_report(airquality)

# report with a response variable
create_report(diamonds, y = "price")
```

### SmartEDA

```{r eval=F}
ExpReport(airquality, op_dir  = 'other_docs/', op_file = 'smarteda.html')
```

### dlookr

```{r eval=F}
eda_report(airquality)

diamonds %>% 
  eda_report(price)
```


## Big Picture of your data, or some quick descriptive stats

Instead of running *create_report()*, you may also run each function individually for your analysis, e.g. view basic description for *airquality* data.

### DataExplorer

```{r}
introduce(airquality)

plot_intro(airquality)
```

### SmartEDA

```{r}
ExpData(data=diamonds,type=1)
ExpData(data=diamonds,type=2)
```



### skimr

```{r}
skim(diamonds)
```

### pastecs

```{r}
stat.desc(airquality)
```


### summarytools

```{r}
library(summarytools)
dfSummary(diamonds)
```

### psych

```{r}
library(psych)
describeBy(diamonds,
           diamonds$cut) # grouping variable
```

### dlookr

```{r}
dlookr::describe(airquality)

diamonds %>% 
  dplyr::select(price, cut, carat) %>% 
  group_by(cut) %>% 
  dlookr::describe() %>% 
  dplyr::select(variable, cut, n, na, mean, sd, IQR)
```

### Hmisc

```{r}
Hmisc::describe(mpg)
```



### gtsummary

```{r}
library(gtsummary)
diamonds %>%
  tbl_summary(by = cut) %>% 
  bold_labels() %>% 
  add_p()
```


## View missing value distribution for airquality data

### DataExplorer

```{r}
plot_missing(airquality)
```

### dlookr

```{r}
plot_na_pareto(airquality)
```

### visdat

```{r}
visdat::vis_dat(airquality)
```





## Visualise distribution of categorical (discrete) variables

### DataExplorer

```{r}
plot_bar(diamonds)

plot_bar(diamonds, with = "price")

## View frequency distribution by a discrete variable
plot_bar(diamonds, by = "cut")
```

### SmartEDA

```{r}
ExpCatViz(diamonds)

## Stacked bar graph
ExpCatViz(diamonds,target="cut",fname=NULL,clim=10,col=NULL,margin=2,Page = c(2,1),sample=2)

## Frequency or custom tables for categorical variables
ExpCTable(diamonds, Target = "price")

## Summary statistics of categorical variables
ExpCatStat(diamonds, Target="price",result = "Stat")

## Inforamtion value and Odds value
ExpCatStat(diamonds, Target="price",result = "IV")

## Variable importance graph using information values
ExpCatStat(Carseats, Target="Urban", result = "Stat", clim=10, nlim=5, bins=10, Pclass="Yes", plot=TRUE, top=10, Round=2)
```

### ggstatsplot

```{r}
ggbarstats(data = diamonds, x = cut, y = clarity)
```


## Visualise distribution of numeric variables

### DataExplorer

```{r}
## View histogram of all continuous variables
plot_histogram(airquality)

## View estimated density distribution of all continuous variables
plot_density(airquality)

## View quantile-quantile plot of all continuous variables
plot_qq(airquality)

## View quantile-quantile plot of all continuous variables by feature `cut`
plot_qq(airquality, by = "Month")
```

### SmartEDA

```{r}
## View estimated density distribution of all continuous variables
ExpNumViz(airquality)

## View quantile-quantile plot of all continuous variables
ExpOutQQ(airquality)
```


### ggpubr

```{r}
library(ggpubr)
ggqqplot(airquality$Temp)
ggqqplot(airquality$Temp[airquality$Month == 5])
```

### car

```{r}
car::qqPlot(mtcars$mpg, groups = mtcars$cyl)
```

### dlookr

Shapiro-Wilk normality test is performed.

```{r}
normality(airquality)

# amazingly it supports dplyr and therefore group_by
mtcars %>%
  group_by(am, cyl) %>%
  normality(mpg, wt) %>% 
  arrange(desc(p_value)) 

plot_normality(airquality, Ozone, Wind)

airquality %>% 
  group_by(Month) %>%
  plot_normality(Ozone)
```


## Visualize correlation

### DataExplorer

```{r}
## View overall correlation heatmap
plot_correlation(na.omit(airquality), type = "c")
```

### PerformanceAnalytics

Correlation coeffitients and correlation color are amazing, they give us an idea about where there is a potentias for further exploration. However, they are quite limited though. Firstly, we don't really know whether these correlations are significant, so there are no tests behind it. Secondly, we don't even know what correlation method produced these coeffitients in the first place, was it the Pearson correaltion, or Spearman. Finally we don't see how data are scattered, so that some relationships might be very non-linear and correlation analysis would be not appropriate at all. The solution for all three problems is provided by the *PerformanceAnalytics* package, which offers a *chart.Correlation()* function. It produces histograms for every particular numeric variable and the scatterplots for every combination of numeric variables. I found the significance stars particularly helpful. Besides, we can easily choose the method we measure the correlation by, for instance, in the example below we use a robust non-parametric *kendall* correlation which is more appropriate for non-normally and non-too-linearly distributed values with some outliers. If we do not specify the methos, we'll produce a parametric (usual) Pearson correlation which is only appropriate for perfect data, which ... rarely happens.



```{r}
PerformanceAnalytics::chart.Correlation(airquality %>% select(-Month)) 
# method = "kendall" or "spearman"
PerformanceAnalytics::chart.Correlation(airquality %>% select(-Month), method = "kendall") 
```
### dlookr

```{r}
correlate(airquality, Ozone)

plot_correlate(airquality)

diamonds %>%
  filter(cut %in% c("Premium", "Ideal")) %>% 
  group_by(cut) %>%
  plot_correlate()
```


## Visualize box plots

### DataExplorer

```{r}
## View bivariate continuous distribution based on `cut`
plot_boxplot(airquality, by = "Month")
```

### SmartEDA

```{r}
ExpNumViz(airquality, target = "Month")
```

### ggstatsplot

```{r}
ggstatsplot::ggbetweenstats(data = airquality, x = Month, y = Ozone, type = "np")
## I did 3 videos about these fancy box plots with statistics

```

## Visualize outlier

The *performance* package provide an easy way to visualize outliers.

```{r}
check_outliers(airquality$Ozone, method = "iqr")
plot(check_outliers(airquality$Ozone, method = "iqr"))
```
## Scatter plots

```{r}
plot(iris)
```

### SmartEDA

```{r}
airquality %>% 
  select(1:3) %>% 
ExpNumViz(scatter=TRUE)
```


## Exploratory modelling

```{r}
ggplot(airquality, aes(Solar.R, Temp))+
  geom_point()+
  geom_smooth()+
  facet_wrap(~Month)
  

ggplot(diamonds, aes(price, carat))+
  geom_point()+
  geom_smooth()+
  facet_grid(cut ~ clarity)
```


--------------------------------

If you think, I missed something, please comment on it, and I'll improve this tutorial.

**Thank you for learning!**

## Further readings and references

- One of the best places to learn R is R-Bloggers platform: http://www.R-bloggers.com 

- https://www.groundai.com/project/the-landscape-of-r-packages-for-automated-exploratory-data-analysis/1