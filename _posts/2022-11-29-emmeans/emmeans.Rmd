---
title: "R package reviews {emmeans} squizze all the knowledge out of the models!"
description: |
  {emmeans} is one of the most capable, but at the same time one of the most mysterious and therefore underrated R packages. Let's demistify {emmeans} and uncover it's power!
author:
  - name: Yury Zablotski
    url: https://yuzar-blog.netlify.app/
date: "`r format(Sys.time(), '%B %d, %Y')`"
categories:
  - videos
  - statistics
  - models
preview: thumbnail_gtsummary.png
output:
  distill::distill_article:
    self_contained: false
    toc: true
    toc_float: true
    toc_depth: 6
    code_download: true
bibliography: /Users/zablotski/Documents/library.bib
#csl: american-political-science-association.csl
biblio-style: apalike
link-citations: yes
linkcolor: blue
draft: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


Rewrite: "There are statistical effects, marginal effects, marginal means, marginal slopes, conditional effects, conditional marginal effects, marginal effects at the mean, and many other similarly-named ideas. There are also regression coefficients and estimates, which have marginal effects vibes, but may or may not actually be marginal effects depending on the complexity of the model."


```{r}
# Load packages
# ---------------
library(tidyverse)        # dplyr, ggplot2, and friends
library(broom)            # Convert models to data frames
library(marginaleffects)  # Marginal effects stuff
library(emmeans)          # Marginal effects stuff

# Visualization-related packages
library(ggtext)           # Add markdown/HTML support to text in plots
library(glue)             # Python-esque string interpolation
library(scales)           # Functions to format numbers nicely
library(gganimate)        # Make animated plots
library(patchwork)        # Combine ggplots
library(ggrepel)          # Make labels that don't overlap
library(MetBrewer)        # Artsy color palettes
# library(sjPlot)

# Data-related packages
library(palmerpenguins)   # Penguin data
library(WDI)              # Get data from the World Bank's API
library(countrycode)      # Map country codes to different systems
library(vdemdata)         # Use data from the Varieties of Democracy
library(gtsummary)
# (V-Dem) project
# Install vdemdata from GitHub, not CRAN
# devtools::install_github("vdeminstitute/vdemdata")

theme_set(theme_test())
```


```{r}
# Helpful functions
# -------------------
# Format numbers in pretty ways
nice_number <- label_number(style_negative = "minus", accuracy = 0.01)
nice_p <- label_pvalue(prefix = c("p < ", "p = ", "p > "))

# Point-slope formula: (y - y1) = m(x - x1)
find_intercept <- function(x1, y1, slope) {
  intercept <- slope * (-x1) + y1
  return(intercept)
}

# Visualization settings
# ------------------------

# Custom ggplot theme to make pretty plots
# Get IBM Plex Sans Condensed at https://fonts.google.com/specimen/IBM+Plex+Sans+Condensed
theme_mfx <- function() {
  theme_minimal(base_family = "IBM Plex Sans Condensed") +
    theme(panel.grid.minor = element_blank(),
          plot.background = element_rect(fill = "white", color = NA),
          plot.title = element_text(face = "bold"),
          axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold"),
          strip.background = element_rect(fill = "grey80", color = NA),
          legend.title = element_text(face = "bold"))
}

# Make labels use IBM Plex Sans by default
update_geom_defaults("label", 
                     list(family = "IBM Plex Sans Condensed"))
update_geom_defaults(ggtext::GeomRichText, 
                     list(family = "IBM Plex Sans Condensed"))
update_geom_defaults("label_repel", 
                     list(family = "IBM Plex Sans Condensed"))

# Use the Johnson color palette
clrs <- met.brewer("Johnson")
```



rewrite: "Put as simply as possible, in the world of statistics, “marginal” means “additional,” or what happens to outcome variable  when explanatory variable  changes a little."


rewrite: Importantly, the slope shows the relationship between  and . If  increases by 1 unit,  increases by 2: when  is 1,  is 1; when  is 2,  is 3, and so on. We can call this the marginal effect, or the change in  that results from one additional .

rewrte: In the calculus world, the term “marginal” isn’t used all that often. Instead they talk about derivatives. But in the end, all these marginal/derivative things are just slopes. My first exposure to the word “marginal” meaning “changes in things” wasn’t actually in the world of statistics, but in economics. My first exposure to the word “marginal” meaning “changes in things” wasn’t actually in the world of statistics, but in economics.

At its core, regression modeling in statistics is all about fancy ways of finding averages and fancy ways of drawing lines. Even if you’re doing non-regression things like t-tests, those are technically still just regression behind the scenes. Statistics is all about lines, and lines have slopes, or derivatives. These slopes represent the marginal changes in an outcome. As you move an independent/explanatory variable , what happens to the dependent/outcome variable ?


```{r}
penguins <- penguins |> drop_na()

model_slider <- lm(body_mass_g ~ flipper_length_mm, data = penguins)
tbl_regression(model_slider)
library(sjPlot)
plot_model(model_slider, type = "pred")

model_switch <- lm(body_mass_g ~ species, data = penguins)
tbl_regression(model_switch)
plot_model(model_switch, type = "pred")
```

```{r}
model_mixer <- lm(body_mass_g ~ flipper_length_mm + bill_depth_mm + species + sex,
                  data = penguins)
tbl_regression(model_mixer)
```

rewrite: Interpreting these coefficients is a little different now, since we’re working with multiple moving parts. In regular stats class, you’ve probably learned to say something like “Holding all other variables constant, a 1 mm increase in flipper length is associated with a 17.5 gram increase in body mass, on average” (slider) or “Holding all other variables constant, Chinstrap penguins are 79 grams lighter than Adelie penguins, on average” (switch).

rewrite: This idea of “holding everything constant” though can be tricky to wrap your head around. Imagining this model like a mixer board can help, though. Pretend that you set the bill depth slider to some value (0, the average, whatever), you flip the Chinstrap and Gentoo switches off, you flip the male switch off, and then you slide only the flipper length switch up and down. You’d be looking at **the marginal effect of flipper length for female Adelie penguins with an average (or 0 or whatever) length of bill depth.** Stop moving the flipper length slider and start moving the bill depth slider and you’ll see the marginal effect of bill depth for female Adelie penguins. Flip on the male switch and you’ll see the marginal effect of bill depth for male Adelie penguins. Flip on the Gentoo switch and you’ll see the marginal effect of bill depth for male Gentoo penguins. And so on.


# What are marginal effects?

...but we haven’t officially defined it in the statistics world yet. It’s tricky to do that, though, because there are so many synonyms and near synonyms for the idea of a statistical effect, like marginal effect, marginal mean, marginal slope, conditional effect, conditional marginal effect, and so on.

- Marginal effect: the statistical effect for continuous explanatory variables; the partial derivative of a variable in a regression model; the effect of a single slider
- Conditional effect or group contrast: the statistical effect for categorical explanatory variables; the difference in means when a condition is on vs. when it is off; the effect of a single switch

# Slopes and marginal effects

```{r}
# Get data from the World Bank's API
wdi_raw <- WDI(country = "all", 
               indicator = c(population = "SP.POP.TOTL",
                             gdp_percapita = "NY.GDP.PCAP.KD"), 
               start = 2000, end = 2020, extra = TRUE)

# Clean up the World Bank data
wdi_2020 <- wdi_raw |> 
  filter(region != "Aggregates") |> 
  filter(year == 2020) |> 
  mutate(log_gdp_percapita = log(gdp_percapita)) |> 
  select(-region, -status, -year, -country, -lastupdated, -lending)

# Get data from V-Dem and clean it up
vdem_2020 <- vdem %>% 
  select(country_name, country_text_id, year, region = e_regionpol_6C,
         disclose_donations_ord = v2eldonate_ord, 
         public_sector_corruption = v2x_pubcorr,
         polyarchy = v2x_polyarchy, civil_liberties = v2x_civlib) %>% 
  filter(year == 2020) %>% 
  mutate(disclose_donations = disclose_donations_ord >= 3,
         disclose_donations = ifelse(is.na(disclose_donations), FALSE, disclose_donations)) %>% 
  # Scale these up so it's easier to talk about 1-unit changes
  mutate(across(c(public_sector_corruption, polyarchy, civil_liberties), ~ . * 100)) |> 
  mutate(region = factor(region, 
                         labels = c("Eastern Europe and Central Asia",
                                    "Latin America and the Caribbean",
                                    "Middle East and North Africa",
                                    "Sub-Saharan Africa",
                                    "Western Europe and North America",
                                    "Asia and Pacific")))

# Combine World Bank and V-Dem data into a single dataset
corruption <- vdem_2020 |> 
  left_join(wdi_2020, by = c("country_text_id" = "iso3c")) |> 
  drop_na(gdp_percapita)

glimpse(corruption)
```
```{r}
model_simple <- lm(public_sector_corruption ~ civil_liberties,
                   data = corruption)

plot_model(model_simple, type = "pred", show.data = T)

tbl_regression(model_simple)
emtrends(model_simple, 
         var = "civil_liberties")
```


rewrite: The  coefficient by itself is thus enough to tell us what the effect of moving civil liberties around is—it is the marginal effect of civil liberties on public sector corruption. Slide the civil liberties index up by 1 point and public sector corruption will be −0.81 points lower, on average.


```{r}
model_sq <- lm(public_sector_corruption ~ civil_liberties + I(civil_liberties^2),
               data = corruption)

tbl_regression(model_sq)

model_sq |> 
  emtrends(~ civil_liberties, var = "civil_liberties",
           at = list(civil_liberties = c(25, 55, 80)),
           delta.var = 0.001) |> 
  test()
```

# marginaleffects’s and emmeans’s philosophies of averaging

We deal with the uncertainty of these marginal effects by taking averages, which is why we talk about “average marginal effects” when interpreting these effects. So far, marginaleffects::marginaleffects() and emmeans::emtrends() have given identical results. But behind the scenes, these packages take two different approaches to calculating these marginal averages. The difference is very subtle, but incredibly important.


```{r}
mfx_sq <- marginaleffects(model_sq)
head(mfx_sq)

mfx_sq |> 
  group_by(term) |> 
  summarize(avg_dydx = mean(dydx))

summary(mfx_sq)
```

# Marginal effects at the mean (the default in emmeans)

The emmeans package actually calculates two average things: “marginal effects at the means” (MEM), or average slopes using emtrends(), and “estimated marginal means” (EMM), or average predictions using emmeans().

```{r}
avg_civ_lib <- mean(corruption$civil_liberties)
avg_civ_lib


model_sq |> 
  emtrends(~ civil_liberties, var = "civil_liberties", delta.var = 0.001)

model_sq |> 
  marginaleffects(newdata = "mean") |> 
  summary()
```
The disadvantage of this approach is that no actual country has a civil_liberties score of exactly 70.16. If we had other covariates in the model, no country would have exactly the average of every variable. The marginal effect is thus calculated based on a hypothetical country that might not possibly exist in real life.


# Marginal effects in logistic regression

Disclosure laws is a binary outcome, so we’ll use logistic regression to constrain the fitted values and predictions to between 0 and 1.

```{r}
model_logit <- glm(
  disclose_donations ~ public_sector_corruption,
  family = binomial(link = "logit"),
  data = corruption
)

tbl_regression(model_logit)
```

Each row contains actual observed data, so the predictions arguably reflect variation in reality. marginaleffects() helpfully converts the AME into percentage points (note that it says “Prediction type: response”), so we can interpret the value directly.


```{r}
model_logit |> 
  marginaleffects() |> 
  summary()
```




```{r}
emmeans(model_logit, ~public_sector_corruption, type = "response")

model_logit |> 
  emtrends(~ public_sector_corruption, 
           var = "public_sector_corruption", 
           regrid = "response")

```
For fun, let’s make a super fancy logistic regression model with a quadratic term and an interaction. We’ll compare the AME and MEM for public sector corruption again. This is where either marginaleffects() or emtrends() is incredibly helpful—correctly combining all the necessary coefficients, given that corruption is both squared and interacted, and given that there are other variables to worry about, would be really hard.

```{r}
model_logit_fancy <- glm(
  disclose_donations ~ public_sector_corruption + I(public_sector_corruption^2) + 
    polyarchy + log_gdp_percapita + public_sector_corruption * region,
  family = binomial(link = "logit"),
  data = corruption
)
```


```{r}
model_logit_fancy |> 
  marginaleffects() |> 
  summary()
```

ich: er sagt also, dass marginaleffects package is viel besser. 
er: We can use emtrends() to get region-specific slopes, but we’ll get different results because of the order of averaging. emmeans creates averages and then plugs them in; marginaleffects plugs all the values in and then creates averages:

```{r}
mfx_logit_fancy <- model_logit_fancy |> 
  marginaleffects(variables = "public_sector_corruption")

# Original data frame + estimated dydx for each row
head(mfx_logit_fancy)

mfx_logit_fancy |> 
  group_by(region) |> 
  summarize(region_ame = mean(dydx))
```

```{r}
model_logit_fancy |> 
  emtrends(~ public_sector_corruption + region,
           var = "public_sector_corruption", regrid = "response")
```

We can replicate the results from emtrends() with marginaleffects() if we plug in average or representative values (more on that in the next section), since that follows the same averaging order as emmeans (i.e. plugging averages into the model)

```{r}
model_logit_fancy |> 
  marginaleffects(variables = "public_sector_corruption",
                  by = "region",
                  newdata = datagrid(region = levels(corruption$region))) 
```



```{r}
regions_to_use <- c("Western Europe and North America", 
                    "Latin America and the Caribbean",
                    "Middle East and North Africa")

expand_grid(public_sector_corruption = c(20, 80),
            region = regions_to_use,
            polyarchy = mean(corruption$polyarchy),
            log_gdp_percapita = mean(corruption$log_gdp_percapita))

modelr::data_grid(corruption,
                  public_sector_corruption = c(20, 80),
                  region = regions_to_use,
                  .model = model_logit_fancy) 

datagrid(model = model_logit_fancy,
         public_sector_corruption = c(20, 80),
         region = regions_to_use)

ref_grid(model_logit_fancy,
         at = list(public_sector_corruption = c(20, 80),
                   region = regions_to_use))
```
```{r}
model_logit_fancy |> 
  marginaleffects(variables = "public_sector_corruption",
                  newdata = datagrid(public_sector_corruption = c(20, 80),
                                     region = regions_to_use))

model_logit_fancy |> 
  emtrends(~ public_sector_corruption + region, var = "public_sector_corruption",
           at = list(public_sector_corruption = c(20, 80),
                     region = regions_to_use),
           regrid = "response", delta.var = 0.001) 
```


```{r}
model_logit_fancy |> 
  emmeans(~ public_sector_corruption + region, var = "public_sector_corruption",
          at = list(public_sector_corruption = c(20, 80),
                    region = regions_to_use),
          regrid = "response") 
```


```{r}
logit_predictions <- model_logit_fancy |> 
  emmeans(~ public_sector_corruption + region, var = "public_sector_corruption",
          at = list(public_sector_corruption = seq(0, 90, 1)),
          regrid = "response") |> 
  as_tibble()

ggplot(logit_predictions, aes(x = public_sector_corruption, y = prob, color = region)) +
  geom_line(size = 1) +
  labs(x = "Public sector corruption", y = "Predicted probability of having\na campaign finance disclosure law", color = NULL) +
  scale_y_continuous(labels = percent_format()) +
  scale_color_manual(values = c(clrs, "grey30")) +
  theme(legend.position = "bottom")
```

(Alternatively, you can use marginaleffects’s built-in plot_cap() to make this plot with one line of code):


```{r}
plot_cap(model_logit_fancy, condition = c("public_sector_corruption", "region"))

```

# Categorical contrasts as statistical/marginal effects

Confusingly, people sometimes also use the term “marginal effect” to talk about group averages or predicted values (I myself am guilty of this!). Technically speaking, a marginal effect is only a partial derivative, or a slope—not a predicted value or a difference in group means.


The main takeaway from this whole post is this: If you take the average before plugging values into the model, you compute average marginal effects for a combination of covariates that might not actually exist in reality. If you take the average after plugging values into the model, each original observation reflects combinations of covariates that definitely exist in reality, so the average marginal effect reflects that reality.

# conclusion

To remember all these differences, here’s a table summarizing all their different approaches:





# Refernces and further readings

- https://www.andrewheiss.com/blog/2022/05/20/marginalia/